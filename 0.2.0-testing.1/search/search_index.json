{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Mathesar Documentation \u00b6 Help us get our beta out sooner \u2013 send us feedback! You\u2019re looking at the documentation for our \u2728 new test build \u2728 , see release notes here . For a timely and stable beta release, we need feedback from as many users as possible about how this new version of Mathesar is working for you. Let us know on this GitHub discussion or drop us a line at hello@mathesar.org . Welcome! \u00b6 Mathesar is a self-hostable open source project that provides a spreadsheet-like interface to a PostgreSQL database. Our web-based interface helps you and your collaborators set up data models, edit data, and build custom reports \u2014 no technical skills needed. You can create a new PostgreSQL database while setting up Mathesar or use our UI to interact with an existing database (or do both). Try Mathesar \u00b6 Live demo \u00b6 See our live demo site to try Mathesar without installing anything. Try locally \u00b6 This is a quick way to play with Mathesar locally, but is not appropriate for saving data that you care about or setting up a long-term installation. With Docker installed, run: docker run -it --name mathesar -p 8000:8000 mathesar/mathesar-testing:latest Visit http://localhost:8000/ to set up an admin user account and create a database connection. Tips when trying Mathesar locally To open a psql shell within the container, run: docker exec -it mathesar sudo -u postgres psql To stop Mathesar, press Ctrl + C in the shell where it is running. To start again, run docker start mathesar . To remove the Docker container, run docker rm mathesar . \u26a0\ufe0f This will also delete the data that you\u2019ve saved within Mathesar! Install Mathesar \u00b6 You can self-host Mathesar by following one of the guides below: Install using Docker compose \u2014 a production setup with separate reverse-proxy and database containers. Install from scratch \u2014 an advanced setup that doesn\u2019t rely on Docker. More installation methods coming soon We\u2019re working on supporting additional installation methods, and we\u2019d appreciate feedback on which ones to prioritize. Please comment on this issue if you have thoughts. Use Mathesar \u00b6 See our Using Mathesar section for documentation on Mathesar\u2019s features. Contribute to Mathesar \u00b6 As an open source project, we actively encourage contribution! Get started by reading our Contributor Guide . Donate \u00b6 We\u2019re a non-profit and your donations help sustain our core team. You can donate via GitHub or Open Collective .","title":"Welcome"},{"location":"#mathesar-documentation","text":"Help us get our beta out sooner \u2013 send us feedback! You\u2019re looking at the documentation for our \u2728 new test build \u2728 , see release notes here . For a timely and stable beta release, we need feedback from as many users as possible about how this new version of Mathesar is working for you. Let us know on this GitHub discussion or drop us a line at hello@mathesar.org .","title":"Mathesar Documentation"},{"location":"#welcome","text":"Mathesar is a self-hostable open source project that provides a spreadsheet-like interface to a PostgreSQL database. Our web-based interface helps you and your collaborators set up data models, edit data, and build custom reports \u2014 no technical skills needed. You can create a new PostgreSQL database while setting up Mathesar or use our UI to interact with an existing database (or do both).","title":"Welcome!"},{"location":"#try-mathesar","text":"","title":"Try Mathesar"},{"location":"#live-demo","text":"See our live demo site to try Mathesar without installing anything.","title":"Live demo"},{"location":"#try-locally","text":"This is a quick way to play with Mathesar locally, but is not appropriate for saving data that you care about or setting up a long-term installation. With Docker installed, run: docker run -it --name mathesar -p 8000:8000 mathesar/mathesar-testing:latest Visit http://localhost:8000/ to set up an admin user account and create a database connection. Tips when trying Mathesar locally To open a psql shell within the container, run: docker exec -it mathesar sudo -u postgres psql To stop Mathesar, press Ctrl + C in the shell where it is running. To start again, run docker start mathesar . To remove the Docker container, run docker rm mathesar . \u26a0\ufe0f This will also delete the data that you\u2019ve saved within Mathesar!","title":"Try locally"},{"location":"#install-mathesar","text":"You can self-host Mathesar by following one of the guides below: Install using Docker compose \u2014 a production setup with separate reverse-proxy and database containers. Install from scratch \u2014 an advanced setup that doesn\u2019t rely on Docker. More installation methods coming soon We\u2019re working on supporting additional installation methods, and we\u2019d appreciate feedback on which ones to prioritize. Please comment on this issue if you have thoughts.","title":"Install Mathesar"},{"location":"#use-mathesar","text":"See our Using Mathesar section for documentation on Mathesar\u2019s features.","title":"Use Mathesar"},{"location":"#contribute-to-mathesar","text":"As an open source project, we actively encourage contribution! Get started by reading our Contributor Guide .","title":"Contribute to Mathesar"},{"location":"#donate","text":"We\u2019re a non-profit and your donations help sustain our core team. You can donate via GitHub or Open Collective .","title":"Donate"},{"location":"administration/debug/","text":"Debug Mathesar \u00b6 For now, we only support turning on Debugging by using our special docker image. More methods will follow in future releases. Use the debugging Mathesar docker image \u00b6 There is a debugging-enabled Mathesar docker image available at mathesar/mathesar-debug that is the same as the mathesar/mathesar-prod image, except that it has more debugging output available in the console where it\u2019s run, and it also produces more verbose errors in the browser when something goes wrong. You can use this image to figure out (or to help the Mathesar team figure out) what\u2019s wrong if your Mathesar installation isn\u2019t working as expected. The procedure is to Run Mathesar with the mathesar/mathesar-debug image, and then Observe and report any additional output or clues to the Mathesar team. Docker Compose \u00b6 Just replace the line image: mathesar/mathesar-prod:latest with image: mathesar/mathesar-debug:latest Basic Mathesar docker image \u00b6 If you are just trying the Mathesar Docker image directly as instructed in the introduction , replace the command docker run -it --name mathesar -p 8000:8000 mathesar/mathesar-prod:latest with docker run -it --name mathesar -p 8000:8000 mathesar/mathesar-debug:latest Other setups \u00b6 The debugging docker image should work anywhere the production image works. This means you can just replace any pull or run of the image mathesar/mathesar-prod:latest with mathesar/mathesar-debug:latest .","title":"Debug Mathesar"},{"location":"administration/debug/#debug-mathesar","text":"For now, we only support turning on Debugging by using our special docker image. More methods will follow in future releases.","title":"Debug Mathesar"},{"location":"administration/debug/#use-the-debugging-mathesar-docker-image","text":"There is a debugging-enabled Mathesar docker image available at mathesar/mathesar-debug that is the same as the mathesar/mathesar-prod image, except that it has more debugging output available in the console where it\u2019s run, and it also produces more verbose errors in the browser when something goes wrong. You can use this image to figure out (or to help the Mathesar team figure out) what\u2019s wrong if your Mathesar installation isn\u2019t working as expected. The procedure is to Run Mathesar with the mathesar/mathesar-debug image, and then Observe and report any additional output or clues to the Mathesar team.","title":"Use the debugging Mathesar docker image"},{"location":"administration/debug/#docker-compose","text":"Just replace the line image: mathesar/mathesar-prod:latest with image: mathesar/mathesar-debug:latest","title":"Docker Compose"},{"location":"administration/debug/#basic-mathesar-docker-image","text":"If you are just trying the Mathesar Docker image directly as instructed in the introduction , replace the command docker run -it --name mathesar -p 8000:8000 mathesar/mathesar-prod:latest with docker run -it --name mathesar -p 8000:8000 mathesar/mathesar-debug:latest","title":"Basic Mathesar docker image"},{"location":"administration/debug/#other-setups","text":"The debugging docker image should work anywhere the production image works. This means you can just replace any pull or run of the image mathesar/mathesar-prod:latest with mathesar/mathesar-debug:latest .","title":"Other setups"},{"location":"administration/uninstall/","text":"Uninstall Mathesar \u00b6 The uninstall instructions vary depending on the installation method you chose. Select your installation method below to proceed. Uninstall a Docker installation of Mathesar \u00b6 Note Depending on your Docker setup, you may need to run docker commands with sudo . Remove the Mathesar container. docker rm -v mathesar_service Remove the Mathesar Image docker rmi mathesar_service Remove volumes related to Mathesar docker volume rm static && docker volume rm media Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ; Uninstall a Guided script or Docker compose installation of Mathesar \u00b6 Remove all Mathesar Docker images and containers. docker compose -f docker-compose.yml down --rmi all -v Remove configuration files. rm -rf xMATHESAR_INSTALLATION_DIRx # may need sudo, depending on location Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ; Uninstall a source installation of Mathesar \u00b6 Stop Caddy service systemctl disable caddy.service && systemctl stop caddy.service Remove Caddy service file and Caddyfile (requires sudo ) sudo rm /lib/systemd/system/caddy.service sudo rm /etc/caddy/Caddyfile Stop Gunicorn systemctl disable gunicorn.service systemctl stop gunicorn.service Remove Gunicorn service file sudo rm /lib/systemd/system/gunicorn.service Remove your Mathesar installation directory rm -r xMATHESAR_INSTALLATION_DIRx # May need sudo, depending on location Your installation directory might be customized It\u2019s possible that Mathesar could have been installed into a different directory than shown above. Use caution when deleting this directory. Remove Django database Connect to the psql terminal. sudo -u postgres psql Drop the Django database. DROP DATABASE mathesar_django ; Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ;","title":"Uninstall Mathesar"},{"location":"administration/uninstall/#uninstall-mathesar","text":"The uninstall instructions vary depending on the installation method you chose. Select your installation method below to proceed.","title":"Uninstall Mathesar"},{"location":"administration/uninstall/#uninstall-a-docker-installation-of-mathesar","text":"Note Depending on your Docker setup, you may need to run docker commands with sudo . Remove the Mathesar container. docker rm -v mathesar_service Remove the Mathesar Image docker rmi mathesar_service Remove volumes related to Mathesar docker volume rm static && docker volume rm media Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ;","title":"Uninstall a Docker installation of Mathesar"},{"location":"administration/uninstall/#uninstall-a-guided-script-or-docker-compose-installation-of-mathesar","text":"Remove all Mathesar Docker images and containers. docker compose -f docker-compose.yml down --rmi all -v Remove configuration files. rm -rf xMATHESAR_INSTALLATION_DIRx # may need sudo, depending on location Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ;","title":"Uninstall a Guided script or Docker compose installation of Mathesar"},{"location":"administration/uninstall/#uninstall-a-source-installation-of-mathesar","text":"Stop Caddy service systemctl disable caddy.service && systemctl stop caddy.service Remove Caddy service file and Caddyfile (requires sudo ) sudo rm /lib/systemd/system/caddy.service sudo rm /etc/caddy/Caddyfile Stop Gunicorn systemctl disable gunicorn.service systemctl stop gunicorn.service Remove Gunicorn service file sudo rm /lib/systemd/system/gunicorn.service Remove your Mathesar installation directory rm -r xMATHESAR_INSTALLATION_DIRx # May need sudo, depending on location Your installation directory might be customized It\u2019s possible that Mathesar could have been installed into a different directory than shown above. Use caution when deleting this directory. Remove Django database Connect to the psql terminal. sudo -u postgres psql Drop the Django database. DROP DATABASE mathesar_django ; Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ;","title":"Uninstall a source installation of Mathesar"},{"location":"administration/upgrade/0.1.4/","text":"Upgrade Mathesar to 0.1.4 \u00b6 The 0.1.4 release requires more upgrade steps than we hope to have for future releases! If you run into any trouble, we encourage you to open an issue or contact us for help. For installations using Docker Compose \u00b6 If you followed our Docker Compose installation instructions , then use these steps to upgrade your installation to 0.1.4. Note Depending on your setup, you may need to run some commands with sudo . Find needed parts Find your .env and docker-compose.yml files. Run docker inspect mathesar_service and look for the value of the \"com.docker.compose.project.config_files\" key in the resulting JSON to find the path to the docker-compose.yml file. The .env file should be in the same directory. If you have jq installed, you can run docker inspect mathesar_service \\ | jq '.[0].Config.Labels.\"com.docker.compose.project.config_files\"' and get the path directly. The .env file should be in the same directory. Copy the path of the directory containing docker-compose.yml and .env into the box below. Do not include a trailing slash. Then press Enter to customize this guide with the configuration directory. If you are using a Docker container for your PostgreSQL database, Run docker volume inspect mathesar_postgresql_data and look for the \"Mountpoint\" in the resulting JSON. Copy the path of the directory into the box below. Do not include a trailing slash. Then press Enter to customize this guide with the PostgreSQL data directory. Stop Mathesar, remove old images docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml down --rmi all Set up new configuration Warning MATHESAR_DATABASES has been deprecated as of v0.1.4 and will be removed entirely in future releases of Mathesar. If you end up deleting the variable from your .env file before starting up Mathesar after the upgrade, you can still add the connections manually through Mathesar\u2019s UI. Back up the old configuration files: mv xMATHESAR_INSTALLATION_DIRx/docker-compose.yml xMATHESAR_INSTALLATION_DIRx/docker-compose.yml.backup cp xMATHESAR_INSTALLATION_DIRx/.env xMATHESAR_INSTALLATION_DIRx/env.backup (We\u2019ll modify the old file, so we copy instead of moving it.) Download the new docker compose file: curl -sfL -o xMATHESAR_INSTALLATION_DIRx/docker-compose.yml https://raw.githubusercontent.com/mathesar-foundation/mathesar/0.1.4/docker-compose.yml Edit the xMATHESAR_INSTALLATION_DIRx/.env file to break the DJANGO_DATABASE_URL variable into its parts. This variable should have the form: DJANGO_DATABASE_URL=postgres://<username>:<password>@<host>:<port>/<database> You should edit the .env file to have the variables: POSTGRES_USER=<username> POSTGRES_PASSWORD=<password> POSTGRES_HOST=<host> POSTGRES_PORT=<port> POSTGRES_DB=<database> If you don\u2019t want to set those environment variables (e.g., if they\u2019re otherwise used), you can instead edit the docker-compose.yml file directly to add those variables. Double-check the rest of the configuration: You should have your SECRET_KEY variable defined. If hosting on the internet, you should have a DOMAIN_NAME variable defined. Initialize new Mathesar installation docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml up -d This will pull new images, and start the Mathesar containers. Wait a few minutes, then run docker ps to verify that you have mathesar_service , mathesar-caddy-reverse-proxy-1 , and mathesar_db running and that the service is healthy. The services should not be reporting errors. If you were not using Docker volumes for your Mathesar PostgreSQL data, you\u2019re done, and you can login to Mathesar via your usual method. If you\u2019re not sure, try to login to Mathesar. If you\u2019re presented with a screen instructing you to create an Admin user, you likely need to proceed to the next step. Move your PostgreSQL directory Bring down the services: docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml down Remove scaffold database data, copy your old PostgreSQL volume to the new location: rm -r xMATHESAR_INSTALLATION_DIRx/msar/pgdata cp -r xMATHESAR_PG_DIRx xMATHESAR_INSTALLATION_DIRx/msar/pgdata Bring the services back up: docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml up -d If things look good, then you can try to login at the usual address using your normal username and password, and you should see your data. For installations done via our guided script \u00b6 If you installed Mathesar with our (now deprecated) guided script, then you have a Docker Compose installation. See the Docker Compose upgrade steps . For installations done from scratch \u00b6 If you installed Mathesar from scratch , then use these steps to upgrade your installation to 0.1.4. Warning These steps have not yet been tested extensively. If you run into any trouble, we encourage you to open an issue or submit a PR proposing changes to this file . Go to your Mathesar installation directory. cd xMATHESAR_INSTALLATION_DIRx Note Your installation directory may be different from above if you used a different directory when installing Mathesar. Pull version 0.1.4 from the repository git pull https://github.com/mathesar-foundation/mathesar.git git checkout 0.1.4 Update Python dependencies pip install -r requirements.txt Next we will activate our virtual environment: source ./mathesar-venv/bin/activate Update your environment variables according to the the new configuration specification . In particular, you must put the connection info for the internal DB into new POSTGRES_* variables. The DJANGO_DATABASE_URL variable is no longer supported. Add the environment variables to the shell before running Django commands export $(sudo cat .env) Run the latest Django migrations python manage.py migrate Install the frontend dependencies npm ci --prefix mathesar_ui Build the Mathesar frontend app npm run --prefix mathesar_ui build --max_old_space_size=4096 Update Mathesar functions on the database: python mathesar/install.py --skip-confirm >> /tmp/install.py.log Restart the gunicorn server systemctl restart gunicorn","title":"To 0.1.4"},{"location":"administration/upgrade/0.1.4/#upgrade-mathesar-to-014","text":"The 0.1.4 release requires more upgrade steps than we hope to have for future releases! If you run into any trouble, we encourage you to open an issue or contact us for help.","title":"Upgrade Mathesar to 0.1.4"},{"location":"administration/upgrade/0.1.4/#docker-compose","text":"If you followed our Docker Compose installation instructions , then use these steps to upgrade your installation to 0.1.4. Note Depending on your setup, you may need to run some commands with sudo . Find needed parts Find your .env and docker-compose.yml files. Run docker inspect mathesar_service and look for the value of the \"com.docker.compose.project.config_files\" key in the resulting JSON to find the path to the docker-compose.yml file. The .env file should be in the same directory. If you have jq installed, you can run docker inspect mathesar_service \\ | jq '.[0].Config.Labels.\"com.docker.compose.project.config_files\"' and get the path directly. The .env file should be in the same directory. Copy the path of the directory containing docker-compose.yml and .env into the box below. Do not include a trailing slash. Then press Enter to customize this guide with the configuration directory. If you are using a Docker container for your PostgreSQL database, Run docker volume inspect mathesar_postgresql_data and look for the \"Mountpoint\" in the resulting JSON. Copy the path of the directory into the box below. Do not include a trailing slash. Then press Enter to customize this guide with the PostgreSQL data directory. Stop Mathesar, remove old images docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml down --rmi all Set up new configuration Warning MATHESAR_DATABASES has been deprecated as of v0.1.4 and will be removed entirely in future releases of Mathesar. If you end up deleting the variable from your .env file before starting up Mathesar after the upgrade, you can still add the connections manually through Mathesar\u2019s UI. Back up the old configuration files: mv xMATHESAR_INSTALLATION_DIRx/docker-compose.yml xMATHESAR_INSTALLATION_DIRx/docker-compose.yml.backup cp xMATHESAR_INSTALLATION_DIRx/.env xMATHESAR_INSTALLATION_DIRx/env.backup (We\u2019ll modify the old file, so we copy instead of moving it.) Download the new docker compose file: curl -sfL -o xMATHESAR_INSTALLATION_DIRx/docker-compose.yml https://raw.githubusercontent.com/mathesar-foundation/mathesar/0.1.4/docker-compose.yml Edit the xMATHESAR_INSTALLATION_DIRx/.env file to break the DJANGO_DATABASE_URL variable into its parts. This variable should have the form: DJANGO_DATABASE_URL=postgres://<username>:<password>@<host>:<port>/<database> You should edit the .env file to have the variables: POSTGRES_USER=<username> POSTGRES_PASSWORD=<password> POSTGRES_HOST=<host> POSTGRES_PORT=<port> POSTGRES_DB=<database> If you don\u2019t want to set those environment variables (e.g., if they\u2019re otherwise used), you can instead edit the docker-compose.yml file directly to add those variables. Double-check the rest of the configuration: You should have your SECRET_KEY variable defined. If hosting on the internet, you should have a DOMAIN_NAME variable defined. Initialize new Mathesar installation docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml up -d This will pull new images, and start the Mathesar containers. Wait a few minutes, then run docker ps to verify that you have mathesar_service , mathesar-caddy-reverse-proxy-1 , and mathesar_db running and that the service is healthy. The services should not be reporting errors. If you were not using Docker volumes for your Mathesar PostgreSQL data, you\u2019re done, and you can login to Mathesar via your usual method. If you\u2019re not sure, try to login to Mathesar. If you\u2019re presented with a screen instructing you to create an Admin user, you likely need to proceed to the next step. Move your PostgreSQL directory Bring down the services: docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml down Remove scaffold database data, copy your old PostgreSQL volume to the new location: rm -r xMATHESAR_INSTALLATION_DIRx/msar/pgdata cp -r xMATHESAR_PG_DIRx xMATHESAR_INSTALLATION_DIRx/msar/pgdata Bring the services back up: docker compose -f xMATHESAR_INSTALLATION_DIRx/docker-compose.yml up -d If things look good, then you can try to login at the usual address using your normal username and password, and you should see your data.","title":"For installations using Docker Compose"},{"location":"administration/upgrade/0.1.4/#guided","text":"If you installed Mathesar with our (now deprecated) guided script, then you have a Docker Compose installation. See the Docker Compose upgrade steps .","title":"For installations done via our guided script"},{"location":"administration/upgrade/0.1.4/#scratch","text":"If you installed Mathesar from scratch , then use these steps to upgrade your installation to 0.1.4. Warning These steps have not yet been tested extensively. If you run into any trouble, we encourage you to open an issue or submit a PR proposing changes to this file . Go to your Mathesar installation directory. cd xMATHESAR_INSTALLATION_DIRx Note Your installation directory may be different from above if you used a different directory when installing Mathesar. Pull version 0.1.4 from the repository git pull https://github.com/mathesar-foundation/mathesar.git git checkout 0.1.4 Update Python dependencies pip install -r requirements.txt Next we will activate our virtual environment: source ./mathesar-venv/bin/activate Update your environment variables according to the the new configuration specification . In particular, you must put the connection info for the internal DB into new POSTGRES_* variables. The DJANGO_DATABASE_URL variable is no longer supported. Add the environment variables to the shell before running Django commands export $(sudo cat .env) Run the latest Django migrations python manage.py migrate Install the frontend dependencies npm ci --prefix mathesar_ui Build the Mathesar frontend app npm run --prefix mathesar_ui build --max_old_space_size=4096 Update Mathesar functions on the database: python mathesar/install.py --skip-confirm >> /tmp/install.py.log Restart the gunicorn server systemctl restart gunicorn","title":"For installations done from scratch"},{"location":"administration/upgrade/0.1.5/","text":"Upgrade Mathesar to 0.1.5 \u00b6 For installations using Docker Compose \u00b6 If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory. For installations done from scratch \u00b6 If you installed from scratch, the upgrade instructions are the same as for 0.1.4 , except that you\u2019ll need to specify version 0.1.5 when pulling code from the repository in Step 2. You should also skip Step 5 \u2013 you do not need to change the environment variables.","title":"To 0.1.5"},{"location":"administration/upgrade/0.1.5/#upgrade-mathesar-to-015","text":"","title":"Upgrade Mathesar to 0.1.5"},{"location":"administration/upgrade/0.1.5/#for-installations-using-docker-compose","text":"If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory.","title":"For installations using Docker Compose"},{"location":"administration/upgrade/0.1.5/#for-installations-done-from-scratch","text":"If you installed from scratch, the upgrade instructions are the same as for 0.1.4 , except that you\u2019ll need to specify version 0.1.5 when pulling code from the repository in Step 2. You should also skip Step 5 \u2013 you do not need to change the environment variables.","title":"For installations done from scratch"},{"location":"administration/upgrade/0.1.6/","text":"Upgrade Mathesar to 0.1.6 \u00b6 For installations using Docker Compose \u00b6 If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory. For installations done from scratch \u00b6 If you installed Mathesar from scratch , then use these steps to upgrade your installation to 0.1.6. Go to your Mathesar installation directory cd xMATHESAR_INSTALLATION_DIRx Note Your installation directory may be different from above if you used a different directory when installing Mathesar. Pull version 0.1.6 from the repository git pull https://github.com/mathesar-foundation/mathesar.git git checkout 0.1.6 Update Python dependencies pip install -r requirements-prod.txt Activate our virtual environment source ./mathesar-venv/bin/activate You can skip the following if you\u2019re upgrading from versions 0.1.4 and above. If you\u2019re upgrading from versions <= 0.1.3, update your environment variables according to the the new configuration specification . In particular, you must put the connection info for the internal DB into new POSTGRES_* variables. The DJANGO_DATABASE_URL variable is no longer supported. Add the environment variables to the shell before running Django commands export $(sudo cat .env) Run Django migrations python manage.py migrate Download and extract frontend assets wget https://github.com/mathesar-foundation/mathesar/releases/download/0.1.6/static_files.zip unzip static_files.zip && mv static_files mathesar/static/mathesar && rm static_files.zip Compile Mathesar translation files python manage.py compilemessages Update Mathesar functions on the database: python -m mathesar.install --skip-confirm | tee /tmp/install.py.log Restart the gunicorn server systemctl restart gunicorn","title":"To 0.1.6"},{"location":"administration/upgrade/0.1.6/#upgrade-mathesar-to-016","text":"","title":"Upgrade Mathesar to 0.1.6"},{"location":"administration/upgrade/0.1.6/#for-installations-using-docker-compose","text":"If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory.","title":"For installations using Docker Compose"},{"location":"administration/upgrade/0.1.6/#for-installations-done-from-scratch","text":"If you installed Mathesar from scratch , then use these steps to upgrade your installation to 0.1.6. Go to your Mathesar installation directory cd xMATHESAR_INSTALLATION_DIRx Note Your installation directory may be different from above if you used a different directory when installing Mathesar. Pull version 0.1.6 from the repository git pull https://github.com/mathesar-foundation/mathesar.git git checkout 0.1.6 Update Python dependencies pip install -r requirements-prod.txt Activate our virtual environment source ./mathesar-venv/bin/activate You can skip the following if you\u2019re upgrading from versions 0.1.4 and above. If you\u2019re upgrading from versions <= 0.1.3, update your environment variables according to the the new configuration specification . In particular, you must put the connection info for the internal DB into new POSTGRES_* variables. The DJANGO_DATABASE_URL variable is no longer supported. Add the environment variables to the shell before running Django commands export $(sudo cat .env) Run Django migrations python manage.py migrate Download and extract frontend assets wget https://github.com/mathesar-foundation/mathesar/releases/download/0.1.6/static_files.zip unzip static_files.zip && mv static_files mathesar/static/mathesar && rm static_files.zip Compile Mathesar translation files python manage.py compilemessages Update Mathesar functions on the database: python -m mathesar.install --skip-confirm | tee /tmp/install.py.log Restart the gunicorn server systemctl restart gunicorn","title":"For installations done from scratch"},{"location":"administration/upgrade/0.1.7/","text":"Upgrade Mathesar to 0.1.7 \u00b6 For installations using Docker Compose \u00b6 If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory. For installations done from scratch \u00b6 If you installed Mathesar from scratch , then use these steps to upgrade your installation to 0.1.7. Go to your Mathesar installation directory cd xMATHESAR_INSTALLATION_DIRx Note Your installation directory may be different from above if you used a different directory when installing Mathesar. Pull version 0.1.7 from the repository git pull https://github.com/mathesar-foundation/mathesar.git git checkout 0.1.7 Update Python dependencies pip install -r requirements-prod.txt Activate our virtual environment source ./mathesar-venv/bin/activate You can skip the following if you\u2019re upgrading from versions 0.1.4 and above. If you\u2019re upgrading from versions <= 0.1.3, update your environment variables according to the the new configuration specification . In particular, you must put the connection info for the internal DB into new POSTGRES_* variables. The DJANGO_DATABASE_URL variable is no longer supported. Add the environment variables to the shell before running Django commands export $(sudo cat .env) Run Django migrations python manage.py migrate Download and extract frontend assets wget https://github.com/mathesar-foundation/mathesar/releases/download/0.1.7/static_files.zip unzip static_files.zip && mv static_files mathesar/static/mathesar && rm static_files.zip Compile Mathesar translation files python manage.py compilemessages Update Mathesar functions on the database: python -m mathesar.install --skip-confirm | tee /tmp/install.py.log Restart the gunicorn server systemctl restart gunicorn","title":"To 0.1.7"},{"location":"administration/upgrade/0.1.7/#upgrade-mathesar-to-017","text":"","title":"Upgrade Mathesar to 0.1.7"},{"location":"administration/upgrade/0.1.7/#for-installations-using-docker-compose","text":"If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory.","title":"For installations using Docker Compose"},{"location":"administration/upgrade/0.1.7/#for-installations-done-from-scratch","text":"If you installed Mathesar from scratch , then use these steps to upgrade your installation to 0.1.7. Go to your Mathesar installation directory cd xMATHESAR_INSTALLATION_DIRx Note Your installation directory may be different from above if you used a different directory when installing Mathesar. Pull version 0.1.7 from the repository git pull https://github.com/mathesar-foundation/mathesar.git git checkout 0.1.7 Update Python dependencies pip install -r requirements-prod.txt Activate our virtual environment source ./mathesar-venv/bin/activate You can skip the following if you\u2019re upgrading from versions 0.1.4 and above. If you\u2019re upgrading from versions <= 0.1.3, update your environment variables according to the the new configuration specification . In particular, you must put the connection info for the internal DB into new POSTGRES_* variables. The DJANGO_DATABASE_URL variable is no longer supported. Add the environment variables to the shell before running Django commands export $(sudo cat .env) Run Django migrations python manage.py migrate Download and extract frontend assets wget https://github.com/mathesar-foundation/mathesar/releases/download/0.1.7/static_files.zip unzip static_files.zip && mv static_files mathesar/static/mathesar && rm static_files.zip Compile Mathesar translation files python manage.py compilemessages Update Mathesar functions on the database: python -m mathesar.install --skip-confirm | tee /tmp/install.py.log Restart the gunicorn server systemctl restart gunicorn","title":"For installations done from scratch"},{"location":"administration/upgrade/older/","text":"Upgrading Mathesar to older versions \u00b6 For installations using Docker Compose \u00b6 If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory. For installations done from scratch \u00b6 If you installed from scratch, the upgrade instructions are the same as for 0.1.4 , but you do not need to change the environment variables.","title":"To older versions"},{"location":"administration/upgrade/older/#upgrading-mathesar-to-older-versions","text":"","title":"Upgrading Mathesar to older versions"},{"location":"administration/upgrade/older/#docker-compose","text":"If you have a Docker compose installation (including one from the guided script), run the command below: docker compose -f /etc/mathesar/docker-compose.yml up --pull always -d Your installation directory may be different You may need to change /etc/mathesar/ in the command above if you chose to install Mathesar to a different directory.","title":"For installations using Docker Compose"},{"location":"administration/upgrade/older/#scratch","text":"If you installed from scratch, the upgrade instructions are the same as for 0.1.4 , but you do not need to change the environment variables.","title":"For installations done from scratch"},{"location":"api/rest/","text":"REST API \u00b6 Mathesar has a REST API that the front end uses to interact with the backend. For Mathesar\u2019s beta release, we are actively transitioning to a new RPC-style API and will soon be phasing out the REST API entirely. The REST API is not documented and is not intended to be used by third-party developers.","title":"REST"},{"location":"api/rest/#rest-api","text":"Mathesar has a REST API that the front end uses to interact with the backend. For Mathesar\u2019s beta release, we are actively transitioning to a new RPC-style API and will soon be phasing out the REST API entirely. The REST API is not documented and is not intended to be used by third-party developers.","title":"REST API"},{"location":"api/rpc/","text":"RPC API \u00b6 Mathesar has an API available at /api/rpc/v0/ which follows the JSON-RPC spec version 2.0. Not yet stable The RPC API is not yet stable and may change in the future. If you build logic that depends on this API, be mindful that it may change in the future without warning or notice. Usage \u00b6 Requests \u00b6 To use an RPC function: Call it with a dot path starting from its root path. Always use named parameters. Ensure that your request includes HTTP headers for valid session IDs, as well as CSRF cookies and tokens. Example To call function add_from_known_connection from the connections section of this page, you\u2019d send something like: POST /api/rpc/v0/ b { \"jsonrpc\" : \"2.0\" , \"id\" : 234 , \"method\" : \"connections.add_from_known_connection\" , \"params\" : { \"nickname\" : \"anewconnection\" , \"db_name\" : \"mynewcooldb\" }, } Responses \u00b6 Success \u00b6 Upon a successful call to an RPC function, the API will return a success object. Such an object has the following form: { \"jsonrpc\" : \"2.0\" , \"id\" : 234 , \"result\" : <a n y> } The result is whatever was returned by the underlying function. Errors \u00b6 When an error is produced by a call to the RPC endpoint, we produce an error of the following form: { \"jsonrpc\" : \"2.0\" , \"id\" : 234 , \"error\" : { \"code\" : <i nt > , \"message\" : <s tr > } } The code is a negative integer. Some codes are produced according to the JSON-RPC spec . Other error codes are grouped according to the library that produced the Exception: builtins : -31xxx psycopg or psycopg2 : -30xxx django : -29xxx mathesar (our code): -28xxx db (our code): -27xxx sqlalchemy : -26xxx other: -25xxx Unrecognized errors from a given library return a \u201cround number\u201d code, so an unknown builtins error gets the code -31000. Collaborators \u00b6 collaborators.list_ \u00b6 list_ ( * , database_id = None , ** kwargs ) List information about collaborators. Exposed as list . If called with no database_id , all collaborators for all databases are listed. Parameters: Name Type Description Default database_id int The Django id of the database associated with the collaborators. None Returns: Type Description list [ CollaboratorInfo ] A list of collaborators. collaborators.add \u00b6 add ( * , database_id , user_id , configured_role_id , ** kwargs ) Set up a new collaborator for a database. Parameters: Name Type Description Default database_id int The Django id of the Database to associate with the collaborator. required user_id int The Django id of the User model instance who\u2019d be the collaborator. required configured_role_id int The Django id of the ConfiguredRole model instance to associate with the collaborator. required collaborators.delete \u00b6 delete ( * , collaborator_id , ** kwargs ) Delete a collaborator from a database. Parameters: Name Type Description Default collaborator_id int The Django id of the UserDatabaseRoleMap model instance of the collaborator. required collaborators.set_role \u00b6 set_role ( * , collaborator_id , configured_role_id , ** kwargs ) Set the role of a collaborator for a database. Parameters: Name Type Description Default collaborator_id int The Django id of the UserDatabaseRoleMap model instance of the collaborator. required configured_role_id int The Django id of the ConfiguredRole model instance to associate with the collaborator. required collaborators.CollaboratorInfo \u00b6 Bases: TypedDict Information about a collaborator. Attributes: Name Type Description id int the Django ID of the UserDatabaseRoleMap model instance. user_id int The Django ID of the User model instance of the collaborator. database_id int the Django ID of the Database model instance for the collaborator. configured_role_id int The Django ID of the ConfiguredRole model instance for the collaborator. Columns \u00b6 columns.list_ \u00b6 list_ ( * , table_oid , database_id , ** kwargs ) List information about columns for a table. Exposed as list . Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ ColumnInfo ] A list of column details. columns.add \u00b6 add ( * , column_data_list , table_oid , database_id , ** kwargs ) Add columns to a table. There are defaults for both the name and type of a column, and so passing [{}] for column_data_list would add a single column of type CHARACTER VARYING , with an auto-generated name. Parameters: Name Type Description Default column_data_list list [ CreatableColumnInfo ] A list describing desired columns to add. required table_oid int Identity of the table to which we\u2019ll add columns. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ int ] An array of the attnums of the new columns. columns.patch \u00b6 patch ( * , column_data_list , table_oid , database_id , ** kwargs ) Alter details of preexisting columns in a table. Does not support altering the type or type options of array columns. Parameters: Name Type Description Default column_data_list list [ SettableColumnInfo ] A list describing desired column alterations. required table_oid int Identity of the table whose columns we\u2019ll modify. required database_id int The Django id of the database containing the table. required Returns: Type Description int The number of columns altered. columns.delete \u00b6 delete ( * , column_attnums , table_oid , database_id , ** kwargs ) Delete columns from a table. Parameters: Name Type Description Default column_attnums list [ int ] A list of attnums of columns to delete. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description int The number of columns dropped. columns.list_with_metadata \u00b6 list_with_metadata ( * , table_oid , database_id , ** kwargs ) List information about columns for a table, along with the metadata associated with each column. Args: table_oid: Identity of the table in the user\u2019s database. database_id: The Django id of the database containing the table. Returns: A list of column details. columns.ColumnInfo \u00b6 Bases: TypedDict Information about a column. Extends the settable fields. Attributes: Name Type Description id int The attnum of the column in the table. name str The name of the column. type str The type of the column on the database. type_options TypeOptions The options applied to the column type. nullable bool Whether or not the column is nullable. primary_key bool Whether the column is in the primary key. default ColumnDefault The default value and whether it\u2019s dynamic. has_dependents bool Whether the column has dependent objects. description str The description of the column. current_role_priv list [ Literal ['SELECT', 'INSERT', 'UPDATE', 'REFERENCES']] The privileges available to the user for the column. valid_target_types list [ str ] A list of all types to which the column can be cast. columns.CreatableColumnInfo \u00b6 Bases: TypedDict Information needed to add a new column. No keys are required. Attributes: Name Type Description name Optional [ str ] The name of the column. type Optional [ str ] The type of the column on the database. type_options Optional [ TypeOptions ] The options applied to the column type. nullable Optional [ bool ] Whether or not the column is nullable. default Optional [ ColumnDefault ] The default value. description Optional [ str ] The description of the column. columns.PreviewableColumnInfo \u00b6 Bases: TypedDict Information needed to preview a column. Attributes: Name Type Description id int The attnum of the column in the table. type Optional [ str ] The new type to be applied to a column. type_options Optional [ TypeOptions ] The options to be applied to the column type. columns.SettableColumnInfo \u00b6 Bases: TypedDict Information about a column, restricted to settable fields. When possible, Passing null for a key will clear the underlying setting. E.g., default = null clears the column default setting. type_options = null clears the type options for the column. description = null clears the column description. Setting any of name , type , or nullable is a noop. Only the id key is required. Attributes: Name Type Description id int The attnum of the column in the table. name Optional [ str ] The name of the column. type Optional [ str ] The type of the column on the database. type_options Optional [ TypeOptions ] The options applied to the column type. nullable Optional [ bool ] Whether or not the column is nullable. default Optional [ ColumnDefault ] The default value. description Optional [ str ] The description of the column. columns.TypeOptions \u00b6 Bases: TypedDict Options applied to a type. All attributes are optional. Take special care with the difference between numeric and date/time types w.r.t. precision. The attribute has a different meaning depending on the type to which it\u2019s being applied. Attributes: Name Type Description precision int For numeric types, the number of significant digits. For date/time types, the number of fractional digits. scale int For numeric types, the number of fractional digits. fields str Which time fields are stored. See Postgres docs. length int The maximum length of a character-type field. item_type str The member type for arrays. columns.ColumnDefault \u00b6 Bases: TypedDict A dictionary describing the default value for a column. Attributes: Name Type Description value str An SQL expression giving the default value. is_dynamic bool Whether the value is possibly dynamic. Column Metadata \u00b6 Classes and functions exposed to the RPC endpoint for managing column metadata. columns.metadata.list_ \u00b6 list_ ( * , table_oid , database_id , ** kwargs ) List metadata associated with columns for a table. Exposed as list . Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ ColumnMetaDataRecord ] A list of column meta data objects. columns.metadata.set_ \u00b6 set_ ( * , column_meta_data_list , table_oid , database_id , ** kwargs ) Set metadata associated with columns of a table for a database. Exposed as set . Parameters: Name Type Description Default column_meta_data_list list [ ColumnMetaDataBlob ] A list describing desired metadata alterations. required table_oid int Identity of the table whose metadata we\u2019ll modify. required database_id int The Django id of the database containing the table. required columns.metadata.ColumnMetaDataRecord \u00b6 Bases: TypedDict Metadata for a column in a table. Only the database , table_oid , and attnum keys are required. Attributes: Name Type Description database_id int The Django id of the database containing the table. table_oid int The OID of the table containing the column. attnum int The attnum of the column in the table. bool_input Optional [ Literal ['dropdown', 'checkbox']] How the input for a boolean column should be shown. bool_true Optional [ str ] A string to display for true values. bool_false Optional [ str ] A string to display for false values. num_min_frac_digits Optional [ int ] Minimum digits shown after the decimal point. num_max_frac_digits Optional [ int ] Maximum digits shown after the decimal point. num_grouping Optional [ str ] Specifies how grouping separators are displayed for numeric values. num_format Optional [ str ] Specifies the locale-specific format for displaying numeric values. mon_currency_symbol Optional [ str ] The currency symbol shown for money value. mon_currency_location Optional [ Literal ['after-minus', 'end-with-space']] Where the currency symbol should be shown. time_format Optional [ str ] A string representing the format of time values. date_format Optional [ str ] A string representing the format of date values. duration_min Optional [ str ] The smallest unit for displaying durations. duration_max Optional [ str ] The largest unit for displaying durations. columns.metadata.ColumnMetaDataBlob \u00b6 Bases: TypedDict The metadata fields which can be set for a column in a table. Attributes: Name Type Description attnum int The attnum of the column in the table. bool_input Optional [ Literal ['dropdown', 'checkbox']] How the input for a boolean column should be shown. bool_true Optional [ str ] A string to display for true values. bool_false Optional [ str ] A string to display for false values. num_min_frac_digits Optional [ int ] Minimum digits shown after the decimal point. num_max_frac_digits Optional [ int ] Maximum digits shown after the decimal point. num_grouping Optional [ str ] Specifies how grouping separators are displayed for numeric values. num_format Optional [ str ] Specifies the locale-specific format for displaying numeric values. mon_currency_symbol Optional [ str ] The currency symbol shown for money value. mon_currency_location Optional [ Literal ['after-minus', 'end-with-space']] Where the currency symbol should be shown. time_format Optional [ str ] A string representing the format of time values. date_format Optional [ str ] A string representing the format of date values. duration_min Optional [ str ] The smallest unit for displaying durations. duration_max Optional [ str ] The largest unit for displaying durations. Configured Databases \u00b6 databases.configured.list_ \u00b6 list_ ( * , server_id = None , ** kwargs ) List information about databases for a server. Exposed as list . If called with no server_id , all databases for all servers are listed. Parameters: Name Type Description Default server_id int The Django id of the server containing the databases. None Returns: Type Description list [ ConfiguredDatabaseInfo ] A list of database details. databases.configured.disconnect \u00b6 disconnect ( * , database_id , ** kwargs ) Disconnect a configured database. Parameters: Name Type Description Default database_id int The Django id of the database. required databases.configured.ConfiguredDatabaseInfo \u00b6 Bases: TypedDict Information about a database. Attributes: Name Type Description id int the Django ID of the database model instance. name str The name of the database on the server. server_id int the Django ID of the server model instance for the database. Connections \u00b6 Classes and functions exposed to the RPC endpoint for creating connections. connections.add_from_known_connection \u00b6 add_from_known_connection ( * , nickname , database , create_db = False , connection_id = None , sample_data = [] ) Add a new connection from an already existing one. If no connection_id is passed, the internal database connection will be used. Parameters: Name Type Description Default nickname str Identify the added connection. Should be unique. required database str The name of the database on the server. required create_db bool Whether we should create the database database if it doesn\u2019t already exist. False connection_id int Identifies the known connection when combined with the user_database value for the connection_type parameter None sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. [] Returns: Type Description ConnectionReturn Metadata about the Database associated with the connection. connections.add_from_scratch \u00b6 add_from_scratch ( * , nickname , database , user , password , host , port , sample_data = [] ) Add a new connection to a PostgreSQL server from scratch. This requires inputting valid credentials for the connection. When setting up the connection, therefore, the database must already exist on the PostgreSQL server. Parameters: Name Type Description Default nickname str Identify the added connection. Should be unique. required database str The name of the database on the server. required user str A valid user (role) on the server, with CONNECT and CREATE privileges on the database given by database . required password str The password for user . required host str The hostname or IP address of the PostgreSQL server. required port int The port of the PostgreSQL server. required sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. [] Returns: Type Description ConnectionReturn Metadata about the Database associated with the connection. connections.grant_access_to_user \u00b6 grant_access_to_user ( * , connection_id , user_id ) Migrate a connection to new models and grant access to a user. This function is designed to be temporary, and should probably be removed once we have completed the new users and permissions setup for beta. You pass any conneciton id and user id. The function will fill the required models as needed. Parameters: Name Type Description Default connection_id int The Django id of an old-style connection. required user_id int The Django id of a user. required connections.ConnectionReturn \u00b6 Bases: TypedDict Information about a connection model. Attributes: Name Type Description id int The Django id of the Connection object added. nickname str Used to identify the added connection. database str The name of the database on the server. username str The username of the role for the connection. host str The hostname or IP address of the Postgres server. port int The port of the Postgres server. Constraints \u00b6 Classes and functions exposed to the RPC endpoint for managing table constraints. constraints.list_ \u00b6 list_ ( * , table_oid , database_id , ** kwargs ) List information about constraints in a table. Exposed as list . Parameters: Name Type Description Default table_oid int The oid of the table to list constraints for. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ ConstraintInfo ] A list of constraint details. constraints.add \u00b6 add ( * , table_oid , constraint_def_list , database_id , ** kwargs ) Add constraint(s) on a table in bulk. Parameters: Name Type Description Default table_oid int Identity of the table to delete constraint for. required constraint_def_list CreatableConstraintInfo A list describing the constraints to add. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ int ] The oid(s) of all the constraints on the table. constraints.delete \u00b6 delete ( * , table_oid , constraint_oid , database_id , ** kwargs ) Delete a constraint from a table. Parameters: Name Type Description Default table_oid int Identity of the table to delete constraint for. required constraint_oid int The OID of the constraint to delete. required database_id int The Django id of the database containing the table. required Returns: Type Description str The name of the dropped constraint. constraints.ForeignKeyConstraint \u00b6 Bases: TypedDict Information about a foreign key constraint. Attributes: Name Type Description type str The type of the constraint( 'f' for foreign key constraint). columns list [ int ] List of columns to set a foreign key on. fkey_relation_id int The OID of the referent table. fkey_columns list [ int ] List of referent column(s). name Optional [ str ] The name of the constraint. deferrable Optional [ bool ] Whether to postpone constraint checking until the end of the transaction. fkey_update_action Optional [ str ] Specifies what action should be taken when the referenced key is updated. Valid options include 'a'(no action) (default behavior), 'r'(restrict) , 'c'(cascade) , 'n'(set null) , 'd'(set default) fkey_delete_action Optional [ str ] Specifies what action should be taken when the referenced key is deleted. Valid options include 'a'(no action) (default behavior), 'r'(restrict) , 'c'(cascade) , 'n'(set null) , 'd'(set default) fkey_match_type Optional [ str ] Specifies how the foreign key matching should be performed. Valid options include 'f'(full match) , 's'(simple match) (default behavior). constraints.PrimaryKeyConstraint \u00b6 Bases: TypedDict Information about a primary key constraint. Attributes: Name Type Description type str The type of the constraint( 'p' for primary key constraint). columns list [ int ] List of columns to set a primary key on. name Optional [ str ] The name of the constraint. deferrable Optional [ bool ] Whether to postpone constraint checking until the end of the transaction. constraints.UniqueConstraint \u00b6 Bases: TypedDict Information about a unique constraint. Attributes: Name Type Description type str The type of the constraint( 'u' for unique constraint). columns list [ int ] List of columns to set a unique constraint on. name Optional [ str ] The name of the constraint. deferrable Optional [ bool ] Whether to postpone constraint checking until the end of the transaction. constraints.CreatableConstraintInfo module-attribute \u00b6 CreatableConstraintInfo = list [ Union [ ForeignKeyConstraint , PrimaryKeyConstraint , UniqueConstraint , ] ] Type alias for a list of createable constraints which can be unique, primary key, or foreign key constraints. Data Modeling \u00b6 Classes and functions exposed to the RPC endpoint for managing data models. data_modeling.add_foreign_key_column \u00b6 add_foreign_key_column ( * , column_name , referrer_table_oid , referent_table_oid , database_id , ** kwargs ) Add a foreign key column to a table. The foreign key column will be newly created, and will reference the id column of the referent table. Parameters: Name Type Description Default column_name str The name of the column to create. required referrer_table_oid int The OID of the table getting the new column. required referent_table_oid int The OID of the table being referenced. required data_modeling.add_mapping_table \u00b6 add_mapping_table ( * , table_name , mapping_columns , schema_oid , database_id , ** kwargs ) Add a mapping table to give a many-to-many link between referents. The foreign key columns in the mapping table will reference the id column of the referent tables. Parameters: Name Type Description Default table_name str The name for the new mapping table. required schema_oid int The OID of the schema for the mapping table. required mapping_columns list [ MappingColumn ] The foreign key columns to create in the mapping table. required data_modeling.suggest_types \u00b6 suggest_types ( * , table_oid , database_id , ** kwargs ) Infer the best type for each column in the table. Currently we only suggest different types for columns which originate as type text . Parameters: Name Type Description Default table_oid int The OID of the table whose columns we\u2019re inferring types for. required database_id int The Django id of the database containing the table. required The response JSON will have attnum keys, and values will be the result of format_type for the inferred type of each column, i.e., the canonical string referring to the type. data_modeling.split_table \u00b6 split_table ( * , table_oid , column_attnums , extracted_table_name , database_id , relationship_fk_column_name = None , ** kwargs ) Extract columns from a table to create a new table, linked by a foreign key. Parameters: Name Type Description Default table_oid int The OID of the table whose columns we\u2019ll extract. required column_attnums list A list of the attnums of the columns to extract. required extracted_table_name str The name of the new table to be made from the extracted columns. required database_id int The Django id of the database containing the table. required relationship_fk_column_name str The name to give the new foreign key column in the remainder table (optional) None Returns: Type Description SplitTableInfo The SplitTableInfo object describing the details for the created table as a result of column extraction. data_modeling.move_columns \u00b6 move_columns ( * , source_table_oid , target_table_oid , move_column_attnums , database_id , ** kwargs ) Extract columns from a table to a referent table, linked by a foreign key. Parameters: Name Type Description Default source_table_oid int The OID of the source table whose column(s) we\u2019ll extract. required target_table_oid int The OID of the target table where the extracted column(s) will be added. required move_column_attnums list [ int ] The list of attnum(s) to move from source table to the target table. required database_id int The Django id of the database containing the table. required data_modeling.MappingColumn \u00b6 Bases: TypedDict An object defining a foreign key column in a mapping table. Attributes: Name Type Description column_name str The name of the foreign key column. referent_table_oid int The OID of the table the column references. data_modeling.SplitTableInfo \u00b6 Bases: TypedDict Information about a table, created from column extraction. Attributes: Name Type Description extracted_table_oid int The OID of the table that is created from column extraction. new_fkey_attnum int The attnum of the newly created foreign key column referring the extracted_table on the original table. Databases \u00b6 databases.get \u00b6 get ( * , database_id , ** kwargs ) Get information about a database. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description DatabaseInfo Information about the database, and the current user privileges. databases.delete \u00b6 delete ( * , database_oid , database_id , ** kwargs ) Drop a database from the server. Parameters: Name Type Description Default database_oid int The OID of the database to delete on the database. required database_id int The Django id of the database to connect to. required databases.DatabaseInfo \u00b6 Bases: TypedDict Information about a database current user privileges on it. Attributes: Name Type Description oid int The oid of the database on the server. name str The name of the database on the server. owner_oid int The oid of the owner of the database. current_role_priv list [ Literal ['CONNECT', 'CREATE', 'TEMPORARY']] A list of privileges available to the user. current_role_owns bool Whether the user is an owner of the database. Database Privileges \u00b6 databases.privileges.list_direct \u00b6 list_direct ( * , database_id , ** kwargs ) List database privileges for non-inherited roles. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description list [ DBPrivileges ] A list of database privileges. databases.privileges.replace_for_roles \u00b6 replace_for_roles ( * , privileges , database_id , ** kwargs ) Replace direct database privileges for roles. Possible privileges are CONNECT , CREATE , and TEMPORARY . Only roles which are included in a passed DBPrivileges object are affected. WARNING: Any privilege included in the direct list for a role is GRANTed, and any privilege not included is REVOKEd. Attributes: Name Type Description privileges The new privilege sets for roles. database_id The Django id of the database. Returns: Type Description list [ DBPrivileges ] A list of all non-default privileges on the database after the list [ DBPrivileges ] operation. databases.privileges.transfer_ownership \u00b6 transfer_ownership ( * , new_owner_oid , database_id , ** kwargs ) Transfers ownership of the current database to a new owner. Attributes: Name Type Description new_owner_oid The OID of the role whom we want to be the new owner of the current database. database_id The Django id of the database whose ownership is to be transferred. To successfully transfer ownership of a database to a new owner the current user must: Be a Superuser/Owner of the current database. Be a MEMBER of the new owning role. i.e. The current role should be able to SET ROLE to the new owning role. Have CREATEDB privilege. Returns: Type Description DatabaseInfo Information about the database, and the current user privileges. databases.privileges.DBPrivileges \u00b6 Bases: TypedDict Information about database privileges. Attributes: Name Type Description role_oid int The oid of the role on the database server. direct list [ Literal ['CONNECT', 'CREATE', 'TEMPORARY']] A list of database privileges for the afforementioned role_oid. Database Setup \u00b6 RPC functions for setting up database connections. databases.setup.create_new \u00b6 create_new ( * , database , sample_data = [], ** kwargs ) Set up a new database on the internal server. The calling user will get access to that database using the default role stored in Django settings. Parameters: Name Type Description Default database str The name of the new database. required sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. [] databases.setup.connect_existing \u00b6 connect_existing ( * , host , port , database , role , password , sample_data = [], ** kwargs ) Connect Mathesar to an existing database on a server. The calling user will get access to that database using the credentials passed to this function. Parameters: Name Type Description Default host str The host of the database server. required port int The port of the database server. required database str The name of the database on the server. required role str The role on the server to use for the connection. required password str A password valid for the role. required sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. [] databases.setup.DatabaseConnectionResult \u00b6 Bases: TypedDict Info about the objects resulting from calling the setup functions. These functions will get or create an instance of the Server, Database, and ConfiguredRole models, as well as a UserDatabaseRoleMap entry. Attributes: Name Type Description server ConfiguredServerInfo Information on the Server model instance. database ConfiguredDatabaseInfo Information on the Database model instance. configured_role ConfiguredRoleInfo Information on the ConfiguredRole model instance. Explorations \u00b6 Classes and functions exposed to the RPC endpoint for managing explorations. explorations.list_ \u00b6 list_ ( * , database_id , schema_oid = None , ** kwargs ) List information about explorations for a database. Exposed as list . Parameters: Name Type Description Default database_id int The Django id of the database containing the explorations. required schema_oid int The OID of the schema containing the base table(s) of the exploration(s).(optional) None Returns: Type Description list [ ExplorationInfo ] A list of exploration details. explorations.get \u00b6 get ( * , exploration_id , ** kwargs ) List information about an exploration. Parameters: Name Type Description Default exploration_id int The Django id of the exploration. required Returns: Type Description ExplorationInfo Exploration details for a given exploration_id. explorations.add \u00b6 add ( * , exploration_def ) Add a new exploration. Parameters: Name Type Description Default exploration_def ExplorationDef A dict describing the exploration to create. required Returns: Type Description ExplorationInfo The exploration details for the newly created exploration. explorations.delete \u00b6 delete ( * , exploration_id , ** kwargs ) Delete an exploration. Parameters: Name Type Description Default exploration_id int The Django id of the exploration to delete. required explorations.replace \u00b6 replace ( * , new_exploration ) Replace a saved exploration. Parameters: Name Type Description Default new_exploration ExplorationInfo A dict describing the exploration to replace, including the updated fields. required Returns: Type Description ExplorationInfo The exploration details for the replaced exploration. explorations.run \u00b6 run ( * , exploration_def , limit = 100 , offset = 0 , ** kwargs ) Run an exploration. Parameters: Name Type Description Default exploration_def ExplorationDef A dict describing an exploration to run. required limit int The max number of rows to return.(default 100) 100 offset int The number of rows to skip.(default 0) 0 Returns: Type Description ExplorationResult The result of the exploration run. explorations.run_saved \u00b6 run_saved ( * , exploration_id , limit = 100 , offset = 0 , ** kwargs ) Run a saved exploration. Parameters: Name Type Description Default exploration_id int The Django id of the exploration to run. required limit int The max number of rows to return.(default 100) 100 offset int The number of rows to skip.(default 0) 0 Returns: Type Description ExplorationResult The result of the exploration run. explorations.ExplorationInfo \u00b6 Bases: TypedDict Information about an exploration. Attributes: Name Type Description id int The Django id of an exploration. database_id int The Django id of the database containing the exploration. name str The name of the exploration. base_table_oid int The OID of the base table of the exploration on the database. schema_oid int The OID of the schema containing the base table of the exploration. initial_columns list A list describing the columns to be included in the exploration. transformations Optional [ list ] A list describing the transformations to be made on the included columns. display_options Optional [ list ] A list describing metadata for the columns in the explorations. display_names Optional [ dict ] A map between the actual column names on the database and the alias to be displayed(if any). description Optional [ str ] The description of the exploration. explorations.ExplorationDef \u00b6 Bases: TypedDict Definition about a runnable exploration. Attributes: Name Type Description database_id int The Django id of the database containing the exploration. name str The name of the exploration. base_table_oid int The OID of the base table of the exploration on the database. schema_oid int The OID of the schema containing the base table of the exploration. initial_columns list A list describing the columns to be included in the exploration. transformations Optional [ list ] A list describing the transformations to be made on the included columns. display_options Optional [ list ] A list describing metadata for the columns in the explorations. display_names Optional [ dict ] A map between the actual column names on the database and the alias to be displayed(if any). description Optional [ str ] The description of the exploration. explorations.ExplorationResult \u00b6 Bases: TypedDict Result of an exploration run. Attributes: Name Type Description query dict A dict describing the exploration that ran. records dict A dict describing the total count of records along with the contents of those records. output_columns tuple A tuple describing the names of the columns included in the exploration. column_metadata dict A dict describing the metadata applied to included columns. limit Optional [ int ] Specifies the max number of rows returned.(default 100) offset Optional [ int ] Specifies the number of rows skipped.(default 0) filter Optional [ dict ] A dict describing filters applied to an exploration. order_by Optional [ list [ dict ]] The ordering applied to the columns of an exploration. search Optional [ list [ dict ]] Specifies a list of dicts containing column names and searched expression. duplicate_only Optional [ list ] A list of column names for which you want duplicate records. Records \u00b6 Classes and functions exposed to the RPC endpoint for managing table records. records.list_ \u00b6 list_ ( * , table_oid , database_id , limit = None , offset = None , order = None , filter = None , grouping = None , return_record_summaries = False , ** kwargs ) List records from a table, and its row count. Exposed as list . Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required limit int The maximum number of rows we\u2019ll return. None offset int The number of rows to skip before returning records from following rows. None order list [ OrderBy ] An array of ordering definition objects. None filter Filter An array of filter definition objects. None grouping Grouping An array of group definition objects. None return_record_summaries bool Whether to return summaries of retrieved records. False Returns: Type Description RecordList The requested records, along with some metadata. records.get \u00b6 get ( * , record_id , table_oid , database_id , return_record_summaries = False , ** kwargs ) Get single record from a table by its primary key. Parameters: Name Type Description Default record_id Any The primary key value of the record to be gotten. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required return_record_summaries bool Whether to return summaries of the retrieved record. False Returns: Type Description RecordList The requested record, along with some metadata. records.add \u00b6 add ( * , record_def , table_oid , database_id , return_record_summaries = False , ** kwargs ) Add a single record to a table. The form of the record_def is determined by the underlying table. Keys should be attnums, and values should be the desired value for that column in the created record. Missing keys will use default values (if set on the DB), and explicit null values will set null for that value regardless of default (with obvious exceptions where that would violate some constraint) Parameters: Name Type Description Default record_def dict An object representing the record to be added. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required return_record_summaries bool Whether to return summaries of the added record. False Returns: Type Description RecordAdded The created record, along with some metadata. records.patch \u00b6 patch ( * , record_def , record_id , table_oid , database_id , return_record_summaries = False , ** kwargs ) Modify a record in a table. The form of the record_def is determined by the underlying table. Keys should be attnums, and values should be the desired value for that column in the modified record. Explicit null values will set null for that value (with obvious exceptions where that would violate some constraint). Parameters: Name Type Description Default record_def dict An object representing the record to be added. required record_id Any The primary key value of the record to modify. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required return_record_summaries bool Whether to return summaries of the modified record. False Returns: Type Description RecordAdded The modified record, along with some metadata. records.delete \u00b6 delete ( * , record_ids , table_oid , database_id , ** kwargs ) Delete records from a table by primary key. Parameters: Name Type Description Default record_ids list [ Any ] The primary key values of the records to be deleted. required table_oid int The identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description Optional [ int ] The number of records deleted. records.search \u00b6 search ( * , table_oid , database_id , search_params = [], limit = 10 , return_record_summaries = False , ** kwargs ) List records from a table according to search_params . Literals will be searched for in a basic way in string-like columns, but will have to match exactly in non-string-like columns. Records are assigned a score based on how many matches, and of what quality, they have with the passed search parameters. Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required search_params list [ SearchParam ] Results are ranked and filtered according to the objects passed here. [] limit int The maximum number of rows we\u2019ll return. 10 Returns: Type Description RecordList The requested records, along with some metadata. records.RecordList \u00b6 Bases: TypedDict Records from a table, along with some meta data The form of the objects in the results array is determined by the underlying records being listed. The keys of each object are the attnums of the retrieved columns. The values are the value for the given row, for the given column. Attributes: Name Type Description count int The total number of records in the table. results list [ dict ] An array of record objects. grouping GroupingResponse Information for displaying grouped records. linked_record_smmaries GroupingResponse Information for previewing foreign key values, provides a map of foreign key to a text summary. record_summaries dict [ str , str ] Information for previewing returned records. records.RecordAdded \u00b6 Bases: TypedDict Record from a table, along with some meta data The form of the object in the results array is determined by the underlying records being listed. The keys of each object are the attnums of the retrieved columns. The values are the value for the given row, for the given column. Attributes: Name Type Description results list [ dict ] An array of a single record objects (the one added). linked_record_summaries dict [ str , dict [ str , str ]] Information for previewing foreign key values, provides a map of foreign key to a text summary. record_summaries dict [ str , str ] Information for previewing an added record. records.OrderBy \u00b6 Bases: TypedDict An object defining an ORDER BY clause. Attributes: Name Type Description attnum int The attnum of the column to order by. direction Literal ['asc', 'desc'] The direction to order by. records.Filter \u00b6 Bases: TypedDict An object defining a filter to be used in a WHERE clause. For valid type values, see the msar.filter_templates table defined in mathesar/db/sql/00_msar.sql . Attributes: Name Type Description type str a function or operator to be used in filtering. args list [ Union [ Filter , FilterAttnum , FilterLiteral ]] The ordered arguments for the function or operator. records.FilterAttnum \u00b6 Bases: TypedDict An object choosing a column for a filter. Attributes: Name Type Description type Literal ['attnum'] Must be \"attnum\" value int The attnum of the column to filter by records.FilterLiteral \u00b6 Bases: TypedDict An object defining a literal for an argument to a filter. Attributes: Name Type Description type Literal ['literal'] must be \"literal\" . value Any The value of the literal. records.Grouping \u00b6 Bases: TypedDict Grouping definition. The table involved must have a single column primary key. Attributes: Name Type Description columns list [ int ] The columns to be grouped by. preproc list [ str ] The preprocessing funtions to apply (if any). records.Group \u00b6 Bases: TypedDict Group definition. Note that the count is over all rows in the group, whether returned or not. However, result_indices is restricted to only the rows returned. This is to avoid potential problems if there are many rows in the group (e.g., the whole table), but we only return a few. Attributes: Name Type Description id int The id of the group. Consistent for same input. count int The number of items in the group. results_eq list [ dict ] The value the results of the group equal. result_indices list [ int ] The 0-indexed positions of group members in the results array. records.GroupingResponse \u00b6 Bases: TypedDict Grouping response object. Extends Grouping with actual groups. Attributes: Name Type Description columns list [ int ] The columns to be grouped by. preproc list [ str ] The preprocessing funtions to apply (if any). groups list [ Group ] The groups applicable to the records being returned. records.SearchParam \u00b6 Bases: TypedDict Search definition for a single column. Attributes: Name Type Description attnum int The attnum of the column in the table. literal Any The literal to search for in the column. Roles \u00b6 roles.list_ \u00b6 list_ ( * , database_id , ** kwargs ) List information about roles for a database server. Exposed as list . Requires a database id inorder to connect to the server. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description list [ RoleInfo ] A list of roles present on the database server. roles.add \u00b6 add ( * , rolename , database_id , password = None , login = None , ** kwargs ) Add a new login/non-login role on a database server. Parameters: Name Type Description Default rolename str The name of the role to be created. required database_id int The Django id of the database. required password str The password for the rolename to set. None login bool Whether the role to be created could login. None Returns: Type Description RoleInfo A dict describing the created role. roles.delete \u00b6 delete ( * , role_oid , database_id , ** kwargs ) Drop a role on a database server. Parameters: Name Type Description Default role_oid int The OID of the role to drop on the database. required database_id int The Django id of the database. required roles.get_current_role \u00b6 get_current_role ( * , database_id , ** kwargs ) Get information about the current role and all the parent role(s) whose privileges are immediately available to current role without doing SET ROLE. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description dict A dict describing the current role. roles.set_members \u00b6 set_members ( * , parent_role_oid , members , database_id , ** kwargs ) Grant/Revoke direct membership to/from roles. Parameters: Name Type Description Default parent_role_oid int The OID of role whose membership will be granted/revoked to/from other roles. required members list An array of role OID(s) whom we want to grant direct membership of the parent role. Only the OID(s) present in the array will be granted membership of parent role, Membership will be revoked for existing members not present in this array. required Returns: Type Description RoleInfo A dict describing the updated information of the parent role. roles.RoleInfo \u00b6 Bases: TypedDict Information about a role. Attributes: Name Type Description oid int The OID of the role. name str Name of the role. super bool Whether the role has SUPERUSER status. inherits bool Whether the role has INHERIT attribute. create_role bool Whether the role has CREATEROLE attribute. create_db bool Whether the role has CREATEDB attribute. login bool Whether the role has LOGIN attribute. description Optional [ str ] A description of the role members Optional [ list [ RoleMember ]] The member roles that directly inherit the role. Refer PostgreSQL documenation on pg_roles table . Role attributes Role membership roles.RoleMember \u00b6 Bases: TypedDict Information about a member role of a directly inherited role. Attributes: Name Type Description oid int The OID of the member role. admin bool Whether the member role has ADMIN option on the inherited role. Roles Configured \u00b6 roles.configured.list_ \u00b6 list_ ( * , server_id , ** kwargs ) List information about roles configured in Mathesar. Exposed as list . Parameters: Name Type Description Default server_id int The Django id of the Server containing the configured roles. required Returns: Type Description list [ ConfiguredRoleInfo ] A list of configured roles. roles.configured.add \u00b6 add ( * , server_id , name , password , ** kwargs ) Configure a role in Mathesar for a database server. Parameters: Name Type Description Default server_id int The Django id of the Server to contain the configured role. required name str The name of the role. required password str The password for the role. required Returns: Type Description ConfiguredRoleInfo The newly configured role. roles.configured.delete \u00b6 delete ( * , configured_role_id , ** kwargs ) Delete a configured role for a server. Parameters: Name Type Description Default configured_role_id int The Django id of the ConfiguredRole model instance. required roles.configured.set_password \u00b6 set_password ( * , configured_role_id , password , ** kwargs ) Set the password of a configured role for a server. Parameters: Name Type Description Default configured_role_id int The Django id of the ConfiguredRole model instance. required password str The password for the role. required roles.configured.ConfiguredRoleInfo \u00b6 Bases: TypedDict Information about a role configured in Mathesar. Attributes: Name Type Description id int the Django ID of the ConfiguredRole model instance. name str The name of the role. server_id int The Django ID of the Server model instance for the role. Schemas \u00b6 schemas.list_ \u00b6 list_ ( * , database_id , ** kwargs ) List information about schemas in a database. Exposed as list . Parameters: Name Type Description Default database_id int The Django id of the database containing the table. required Returns: Type Description list [ SchemaInfo ] A list of SchemaInfo objects schemas.get \u00b6 get ( * , schema_oid , database_id , ** kwargs ) Get information about a schema in a database. Parameters: Name Type Description Default schema_oid int The OID of the schema to get. required database_id int The Django id of the database containing the table. required Returns: Type Description SchemaInfo The SchemaInfo describing the user-defined schema in the database. schemas.add \u00b6 add ( * , name , database_id , owner_oid = None , description = None , ** kwargs ) Add a schema Parameters: Name Type Description Default name str The name of the schema to add. required database_id int The Django id of the database containing the schema. required owner_oid int The OID of the role who will own the new schema. If owner_oid is None, the current role will be the owner of the new schema. None description Optional [ str ] A description of the schema None Returns: Type Description SchemaInfo The SchemaInfo describing the user-defined schema in the database. schemas.delete \u00b6 delete ( * , schema_oid , database_id , ** kwargs ) Delete a schema, given its OID. Parameters: Name Type Description Default schema_oid int The OID of the schema to delete. required database_id int The Django id of the database containing the schema. required schemas.patch \u00b6 patch ( * , schema_oid , database_id , patch , ** kwargs ) Patch a schema, given its OID. Parameters: Name Type Description Default schema_oid int The OID of the schema to delete. required database_id int The Django id of the database containing the schema. required patch SchemaPatch A SchemaPatch object containing the fields to update. required Returns: Type Description SchemaInfo The SchemaInfo describing the user-defined schema in the database. schemas.SchemaInfo \u00b6 Bases: TypedDict Information about a schema Attributes: Name Type Description oid int The OID of the schema name str The name of the schema description Optional [ str ] A description of the schema owner_oid int The OID of the owner of the schema current_role_priv list [ Literal ['USAGE', 'CREATE']] All privileges available to the calling role on the schema. current_role_owns bool Whether the current role is the owner of the schema (even indirectly). table_count int The number of tables in the schema schemas.SchemaPatch \u00b6 Bases: TypedDict Attributes: Name Type Description name Optional [ str ] The name of the schema description Optional [ str ] A description of the schema Schema Privileges \u00b6 schemas.privileges.list_direct \u00b6 list_direct ( * , schema_oid , database_id , ** kwargs ) List direct schema privileges for roles. Parameters: Name Type Description Default schema_oid int The OID of the schema whose privileges we\u2019ll list. required database_id int The Django id of the database containing the schema. required Returns: Type Description list [ SchemaPrivileges ] A list of schema privileges. schemas.privileges.replace_for_roles \u00b6 replace_for_roles ( * , privileges , schema_oid , database_id , ** kwargs ) Replace direct schema privileges for roles. Possible privileges are USAGE and CREATE . Only roles which are included in a passed SchemaPrivileges object are affected. WARNING: Any privilege included in the direct list for a role is GRANTed, and any privilege not included is REVOKEd. Parameters: Name Type Description Default privileges list [ SchemaPrivileges ] The new privilege sets for roles. required schema_oid int The OID of the affected schema. required database_id int The Django id of the database containing the schema. required Returns: Type Description list [ SchemaPrivileges ] A list of all non-default privileges on the schema after the list [ SchemaPrivileges ] operation. schemas.privileges.transfer_ownership \u00b6 transfer_ownership ( * , schema_oid , new_owner_oid , database_id , ** kwargs ) Transfers ownership of a given schema to a new owner. Attributes: Name Type Description schema_oid The OID of the schema to transfer. new_owner_oid The OID of the role whom we want to be the new owner of the schema. To successfully transfer ownership of a schema to a new owner the current user must: Be a Superuser/Owner of the schema. Be a MEMBER of the new owning role. i.e. The current role should be able to SET ROLE to the new owning role. Have CREATE privilege for the database. Returns: Type Description SchemaInfo Information about the schema, and the current user privileges. schemas.privileges.SchemaPrivileges \u00b6 Bases: TypedDict Information about schema privileges for a role. Attributes: Name Type Description role_oid int The oid of the role. direct list [ Literal ['USAGE', 'CREATE']] A list of schema privileges for the afforementioned role_oid. Servers \u00b6 Tables \u00b6 tables.list_ \u00b6 list_ ( * , schema_oid , database_id , ** kwargs ) List information about tables for a schema. Exposed as list . Parameters: Name Type Description Default schema_oid int Identity of the schema in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ TableInfo ] A list of table details. tables.get \u00b6 get ( * , table_oid , database_id , ** kwargs ) List information about a table for a schema. Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description TableInfo Table details for a given table oid. tables.add \u00b6 add ( * , schema_oid , database_id , table_name = None , column_data_list = [], constraint_data_list = [], owner_oid = None , comment = None , ** kwargs ) Add a table with a default id column. Parameters: Name Type Description Default schema_oid int Identity of the schema in the user\u2019s database. required database_id int The Django id of the database containing the table. required table_name str Name of the table to be created. None column_data_list list [ CreatableColumnInfo ] A list describing columns to be created for the new table, in order. [] constraint_data_list list [ CreatableConstraintInfo ] A list describing constraints to be created for the new table. [] owner_oid int The OID of the role who will own the new table. If owner_oid is None, the current role will be the owner of the new table. None comment str The comment for the new table. None Returns: Type Description AddedTableInfo The oid & name of the created table. tables.delete \u00b6 delete ( * , table_oid , database_id , cascade = False , ** kwargs ) Delete a table from a schema. Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required cascade bool Whether to drop the dependent objects. False Returns: Type Description str The name of the dropped table. tables.patch \u00b6 patch ( * , table_oid , table_data_dict , database_id , ** kwargs ) Alter details of a preexisting table in a database. Parameters: Name Type Description Default table_oid str Identity of the table whose name, description or columns we\u2019ll modify. required table_data_dict SettableTableInfo A list describing desired table alterations. required database_id int The Django id of the database containing the table. required Returns: Type Description str The name of the altered table. tables.import_ \u00b6 import_ ( * , data_file_id , schema_oid , database_id , table_name = None , comment = None , ** kwargs ) Import a CSV/TSV into a table. Parameters: Name Type Description Default data_file_id int The Django id of the DataFile containing desired CSV/TSV. required schema_oid int Identity of the schema in the user\u2019s database. required database_id int The Django id of the database containing the table. required table_name str Name of the table to be imported. None comment str The comment for the new table. None Returns: Type Description AddedTableInfo The oid and name of the created table. tables.get_import_preview \u00b6 get_import_preview ( * , table_oid , columns , database_id , limit = 20 , ** kwargs ) Preview an imported table. Parameters: Name Type Description Default table_oid int Identity of the imported table in the user\u2019s database. required columns list [ PreviewableColumnInfo ] List of settings describing the casts to be applied to the columns. required database_id int The Django id of the database containing the table. required limit int The upper limit for the number of records to return. 20 Returns: Type Description list [ dict ] The records from the specified columns of the table. tables.list_joinable \u00b6 list_joinable ( * , table_oid , database_id , max_depth = 3 , ** kwargs ) List details for joinable tables. Parameters: Name Type Description Default table_oid int Identity of the table to get joinable tables for. required database_id int The Django id of the database containing the table. required max_depth int Specifies how far to search for joinable tables. 3 Returns: Type Description JoinableTableInfo Joinable table details for a given table. tables.list_with_metadata \u00b6 list_with_metadata ( * , schema_oid , database_id , ** kwargs ) List tables in a schema, along with the metadata associated with each table Parameters: Name Type Description Default schema_oid int PostgreSQL OID of the schema containing the tables. required database_id int The Django id of the database containing the table. required Returns: Type Description list A list of table details along with metadata. tables.get_with_metadata \u00b6 get_with_metadata ( * , table_oid , database_id , ** kwargs ) Get information about a table in a schema, along with the associated table metadata. Parameters: Name Type Description Default table_oid int The OID of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description dict A dict describing table details along with its metadata. tables.TableInfo \u00b6 Bases: TypedDict Information about a table. Attributes: Name Type Description oid int The oid of the table in the schema. name str The name of the table. schema int The oid of the schema where the table lives. description Optional [ str ] The description of the table. owner_oid int The OID of the direct owner of the table. current_role_priv list [ Literal ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'TRUNCATE', 'REFERENCES', 'TRIGGER']] The privileges available to the user on the table. current_role_owns bool Whether the current role owns the table. tables.AddedTableInfo \u00b6 Bases: TypedDict Information about a newly created table. Attributes: Name Type Description oid int The oid of the table in the schema. name str The name of the table. tables.SettableTableInfo \u00b6 Bases: TypedDict Information about a table, restricted to settable fields. When possible, Passing null for a key will clear the underlying setting. E.g., description = null clears the table description. Setting any of name , columns to null is a noop. Attributes: Name Type Description name Optional [ str ] The new name of the table. description Optional [ str ] The description of the table. columns Optional [ list [ SettableColumnInfo ]] A list describing desired column alterations. tables.JoinableTableRecord \u00b6 Bases: TypedDict Information about a singular joinable table. Attributes: Name Type Description base int The OID of the table from which the paths start target int The OID of the table where the paths end. join_path list A list describing joinable paths in the following form: [ [[L_oid0, L_attnum0], [R_oid0, R_attnum0]], [[L_oid1, L_attnum1], [R_oid1, R_attnum1]], [[L_oid2, L_attnum2], [R_oid2, R_attnum2]], \u2026 ] Here, [L_oidN, L_attnumN] represents the left column of a join, and [R_oidN, R_attnumN] the right. fkey_path list Same as join_path expressed in terms of foreign key constraints in the following form: [ [constraint_id0, reversed], [constraint_id1, reversed], ] In this form, constraint_idN is a foreign key constraint, and reversed is a boolean giving whether to travel from referrer to referant (when False) or from referant to referrer (when True). depth int Specifies how far to search for joinable tables. multiple_results bool Specifies whether the path included is reversed. tables.JoinableTableInfo \u00b6 Bases: TypedDict Information about joinable table(s). Attributes: Name Type Description joinable_tables list [ JoinableTableRecord ] List of reachable joinable table(s) from a base table. target_table_info list Additional info about target table(s) and its column(s). Table Metadata \u00b6 Classes and functions exposed to the RPC endpoint for managing table metadata. tables.metadata.list_ \u00b6 list_ ( * , database_id , ** kwargs ) List metadata associated with tables for a database. Parameters: Name Type Description Default database_id int The Django id of the database containing the table. required Returns: Type Description list [ TableMetaDataRecord ] Metadata object for a given table oid. tables.metadata.set_ \u00b6 set_ ( * , table_oid , metadata , database_id , ** kwargs ) Set metadata for a table. Parameters: Name Type Description Default table_oid int The PostgreSQL OID of the table. required metadata TableMetaDataBlob A TableMetaDataBlob object describing desired table metadata to set. required database_id int The Django id of the database containing the table. required tables.metadata.TableMetaDataBlob \u00b6 Bases: TypedDict The metadata fields which can be set on a table Attributes: Name Type Description data_file_id Optional [ int ] Specifies the DataFile model id used for the import. import_verified Optional [ bool ] Specifies whether a file has been successfully imported into a table. column_order Optional [ list [ int ]] The order in which columns of a table are displayed. record_summary_customized Optional [ bool ] Specifies whether the record summary has been customized. record_summary_template Optional [ str ] Record summary template for a referent column. tables.metadata.TableMetaDataRecord \u00b6 Bases: TypedDict Metadata for a table in a database. Only the database and table_oid keys are required. Attributes: Name Type Description id int The Django id of the TableMetaData object. database_id int The Django id of the database containing the table. table_oid int The OID of the table in the database. data_file_id Optional [ int ] Specifies the DataFile model id used for the import. import_verified Optional [ bool ] Specifies whether a file has been successfully imported into a table. column_order Optional [ list [ int ]] The order in which columns of a table are displayed. record_summary_customized Optional [ bool ] Specifies whether the record summary has been customized. record_summary_template Optional [ str ] Record summary template for a referent column. Table Privileges \u00b6 tables.privileges.list_direct \u00b6 list_direct ( * , table_oid , database_id , ** kwargs ) List direct table privileges for roles. Args: table_oid: The OID of the table whose privileges we\u2019ll list. database_id: The Django id of the database containing the table. Returns: A list of table privileges. tables.privileges.replace_for_roles \u00b6 replace_for_roles ( * , privileges , table_oid , database_id , ** kwargs ) Replace direct table privileges for roles. Possible privileges are INSERT , SELECT , UPDATE , DELETE , TRUNCATE , REFERENCES and TRIGGER . Only roles which are included in a passed TablePrivileges object are affected. WARNING: Any privilege included in the direct list for a role is GRANTed, and any privilege not included is REVOKEd. Parameters: Name Type Description Default privileges list [ TablePrivileges ] The new privilege sets for roles. required table_oid int The OID of the affected table. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ TablePrivileges ] A list of all non-default privileges on the table after the list [ TablePrivileges ] operation. tables.privileges.transfer_ownership \u00b6 transfer_ownership ( * , table_oid , new_owner_oid , database_id , ** kwargs ) Transfers ownership of a given table to a new owner. Attributes: Name Type Description table_oid The OID of the table to transfer. new_owner_oid The OID of the role whom we want to be the new owner of the table. To successfully transfer ownership of a table to a new owner the current user must: Be a Superuser/Owner of the table. Be a MEMBER of the new owning role. i.e. The current role should be able to SET ROLE to the new owning role. Have CREATE privilege on the table\u2019s schema. Returns: Type Description TableInfo Information about the table, and the current user privileges. tables.privileges.TablePrivileges \u00b6 Bases: TypedDict Information about table privileges for a role. Attributes: role_oid: The oid of the role. direct: A list of table privileges for the afforementioned role_oid. Types \u00b6 Classes and functions exposed to the RPC endpoint for listing types in a database. types.list_ \u00b6 list_ () List information about types available on the database. Exposed as list . types.TypeInfo \u00b6 Bases: TypedDict Information about a type. Attributes: Name Type Description identifier str Specifies the type class that db_type(s) belongs to. name str Specifies the UI name for a type class. db_types list Specifies the name(s) of types present on the database. display_options Optional [ dict ] Specifies metadata related to a type class.","title":"RPC"},{"location":"api/rpc/#rpc-api","text":"Mathesar has an API available at /api/rpc/v0/ which follows the JSON-RPC spec version 2.0. Not yet stable The RPC API is not yet stable and may change in the future. If you build logic that depends on this API, be mindful that it may change in the future without warning or notice.","title":"RPC API"},{"location":"api/rpc/#usage","text":"","title":"Usage"},{"location":"api/rpc/#requests","text":"To use an RPC function: Call it with a dot path starting from its root path. Always use named parameters. Ensure that your request includes HTTP headers for valid session IDs, as well as CSRF cookies and tokens. Example To call function add_from_known_connection from the connections section of this page, you\u2019d send something like: POST /api/rpc/v0/ b { \"jsonrpc\" : \"2.0\" , \"id\" : 234 , \"method\" : \"connections.add_from_known_connection\" , \"params\" : { \"nickname\" : \"anewconnection\" , \"db_name\" : \"mynewcooldb\" }, }","title":"Requests"},{"location":"api/rpc/#responses","text":"","title":"Responses"},{"location":"api/rpc/#success","text":"Upon a successful call to an RPC function, the API will return a success object. Such an object has the following form: { \"jsonrpc\" : \"2.0\" , \"id\" : 234 , \"result\" : <a n y> } The result is whatever was returned by the underlying function.","title":"Success"},{"location":"api/rpc/#errors","text":"When an error is produced by a call to the RPC endpoint, we produce an error of the following form: { \"jsonrpc\" : \"2.0\" , \"id\" : 234 , \"error\" : { \"code\" : <i nt > , \"message\" : <s tr > } } The code is a negative integer. Some codes are produced according to the JSON-RPC spec . Other error codes are grouped according to the library that produced the Exception: builtins : -31xxx psycopg or psycopg2 : -30xxx django : -29xxx mathesar (our code): -28xxx db (our code): -27xxx sqlalchemy : -26xxx other: -25xxx Unrecognized errors from a given library return a \u201cround number\u201d code, so an unknown builtins error gets the code -31000.","title":"Errors"},{"location":"api/rpc/#collaborators","text":"","title":"Collaborators"},{"location":"api/rpc/#collaborators.list_","text":"list_ ( * , database_id = None , ** kwargs ) List information about collaborators. Exposed as list . If called with no database_id , all collaborators for all databases are listed. Parameters: Name Type Description Default database_id int The Django id of the database associated with the collaborators. None Returns: Type Description list [ CollaboratorInfo ] A list of collaborators.","title":"list_"},{"location":"api/rpc/#collaborators.add","text":"add ( * , database_id , user_id , configured_role_id , ** kwargs ) Set up a new collaborator for a database. Parameters: Name Type Description Default database_id int The Django id of the Database to associate with the collaborator. required user_id int The Django id of the User model instance who\u2019d be the collaborator. required configured_role_id int The Django id of the ConfiguredRole model instance to associate with the collaborator. required","title":"add"},{"location":"api/rpc/#collaborators.delete","text":"delete ( * , collaborator_id , ** kwargs ) Delete a collaborator from a database. Parameters: Name Type Description Default collaborator_id int The Django id of the UserDatabaseRoleMap model instance of the collaborator. required","title":"delete"},{"location":"api/rpc/#collaborators.set_role","text":"set_role ( * , collaborator_id , configured_role_id , ** kwargs ) Set the role of a collaborator for a database. Parameters: Name Type Description Default collaborator_id int The Django id of the UserDatabaseRoleMap model instance of the collaborator. required configured_role_id int The Django id of the ConfiguredRole model instance to associate with the collaborator. required","title":"set_role"},{"location":"api/rpc/#collaborators.CollaboratorInfo","text":"Bases: TypedDict Information about a collaborator. Attributes: Name Type Description id int the Django ID of the UserDatabaseRoleMap model instance. user_id int The Django ID of the User model instance of the collaborator. database_id int the Django ID of the Database model instance for the collaborator. configured_role_id int The Django ID of the ConfiguredRole model instance for the collaborator.","title":"CollaboratorInfo"},{"location":"api/rpc/#columns","text":"","title":"Columns"},{"location":"api/rpc/#columns.list_","text":"list_ ( * , table_oid , database_id , ** kwargs ) List information about columns for a table. Exposed as list . Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ ColumnInfo ] A list of column details.","title":"list_"},{"location":"api/rpc/#columns.add","text":"add ( * , column_data_list , table_oid , database_id , ** kwargs ) Add columns to a table. There are defaults for both the name and type of a column, and so passing [{}] for column_data_list would add a single column of type CHARACTER VARYING , with an auto-generated name. Parameters: Name Type Description Default column_data_list list [ CreatableColumnInfo ] A list describing desired columns to add. required table_oid int Identity of the table to which we\u2019ll add columns. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ int ] An array of the attnums of the new columns.","title":"add"},{"location":"api/rpc/#columns.patch","text":"patch ( * , column_data_list , table_oid , database_id , ** kwargs ) Alter details of preexisting columns in a table. Does not support altering the type or type options of array columns. Parameters: Name Type Description Default column_data_list list [ SettableColumnInfo ] A list describing desired column alterations. required table_oid int Identity of the table whose columns we\u2019ll modify. required database_id int The Django id of the database containing the table. required Returns: Type Description int The number of columns altered.","title":"patch"},{"location":"api/rpc/#columns.delete","text":"delete ( * , column_attnums , table_oid , database_id , ** kwargs ) Delete columns from a table. Parameters: Name Type Description Default column_attnums list [ int ] A list of attnums of columns to delete. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description int The number of columns dropped.","title":"delete"},{"location":"api/rpc/#columns.list_with_metadata","text":"list_with_metadata ( * , table_oid , database_id , ** kwargs ) List information about columns for a table, along with the metadata associated with each column. Args: table_oid: Identity of the table in the user\u2019s database. database_id: The Django id of the database containing the table. Returns: A list of column details.","title":"list_with_metadata"},{"location":"api/rpc/#columns.ColumnInfo","text":"Bases: TypedDict Information about a column. Extends the settable fields. Attributes: Name Type Description id int The attnum of the column in the table. name str The name of the column. type str The type of the column on the database. type_options TypeOptions The options applied to the column type. nullable bool Whether or not the column is nullable. primary_key bool Whether the column is in the primary key. default ColumnDefault The default value and whether it\u2019s dynamic. has_dependents bool Whether the column has dependent objects. description str The description of the column. current_role_priv list [ Literal ['SELECT', 'INSERT', 'UPDATE', 'REFERENCES']] The privileges available to the user for the column. valid_target_types list [ str ] A list of all types to which the column can be cast.","title":"ColumnInfo"},{"location":"api/rpc/#columns.CreatableColumnInfo","text":"Bases: TypedDict Information needed to add a new column. No keys are required. Attributes: Name Type Description name Optional [ str ] The name of the column. type Optional [ str ] The type of the column on the database. type_options Optional [ TypeOptions ] The options applied to the column type. nullable Optional [ bool ] Whether or not the column is nullable. default Optional [ ColumnDefault ] The default value. description Optional [ str ] The description of the column.","title":"CreatableColumnInfo"},{"location":"api/rpc/#columns.PreviewableColumnInfo","text":"Bases: TypedDict Information needed to preview a column. Attributes: Name Type Description id int The attnum of the column in the table. type Optional [ str ] The new type to be applied to a column. type_options Optional [ TypeOptions ] The options to be applied to the column type.","title":"PreviewableColumnInfo"},{"location":"api/rpc/#columns.SettableColumnInfo","text":"Bases: TypedDict Information about a column, restricted to settable fields. When possible, Passing null for a key will clear the underlying setting. E.g., default = null clears the column default setting. type_options = null clears the type options for the column. description = null clears the column description. Setting any of name , type , or nullable is a noop. Only the id key is required. Attributes: Name Type Description id int The attnum of the column in the table. name Optional [ str ] The name of the column. type Optional [ str ] The type of the column on the database. type_options Optional [ TypeOptions ] The options applied to the column type. nullable Optional [ bool ] Whether or not the column is nullable. default Optional [ ColumnDefault ] The default value. description Optional [ str ] The description of the column.","title":"SettableColumnInfo"},{"location":"api/rpc/#columns.TypeOptions","text":"Bases: TypedDict Options applied to a type. All attributes are optional. Take special care with the difference between numeric and date/time types w.r.t. precision. The attribute has a different meaning depending on the type to which it\u2019s being applied. Attributes: Name Type Description precision int For numeric types, the number of significant digits. For date/time types, the number of fractional digits. scale int For numeric types, the number of fractional digits. fields str Which time fields are stored. See Postgres docs. length int The maximum length of a character-type field. item_type str The member type for arrays.","title":"TypeOptions"},{"location":"api/rpc/#columns.ColumnDefault","text":"Bases: TypedDict A dictionary describing the default value for a column. Attributes: Name Type Description value str An SQL expression giving the default value. is_dynamic bool Whether the value is possibly dynamic.","title":"ColumnDefault"},{"location":"api/rpc/#column-metadata","text":"Classes and functions exposed to the RPC endpoint for managing column metadata.","title":"Column Metadata"},{"location":"api/rpc/#columns.metadata.list_","text":"list_ ( * , table_oid , database_id , ** kwargs ) List metadata associated with columns for a table. Exposed as list . Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ ColumnMetaDataRecord ] A list of column meta data objects.","title":"list_"},{"location":"api/rpc/#columns.metadata.set_","text":"set_ ( * , column_meta_data_list , table_oid , database_id , ** kwargs ) Set metadata associated with columns of a table for a database. Exposed as set . Parameters: Name Type Description Default column_meta_data_list list [ ColumnMetaDataBlob ] A list describing desired metadata alterations. required table_oid int Identity of the table whose metadata we\u2019ll modify. required database_id int The Django id of the database containing the table. required","title":"set_"},{"location":"api/rpc/#columns.metadata.ColumnMetaDataRecord","text":"Bases: TypedDict Metadata for a column in a table. Only the database , table_oid , and attnum keys are required. Attributes: Name Type Description database_id int The Django id of the database containing the table. table_oid int The OID of the table containing the column. attnum int The attnum of the column in the table. bool_input Optional [ Literal ['dropdown', 'checkbox']] How the input for a boolean column should be shown. bool_true Optional [ str ] A string to display for true values. bool_false Optional [ str ] A string to display for false values. num_min_frac_digits Optional [ int ] Minimum digits shown after the decimal point. num_max_frac_digits Optional [ int ] Maximum digits shown after the decimal point. num_grouping Optional [ str ] Specifies how grouping separators are displayed for numeric values. num_format Optional [ str ] Specifies the locale-specific format for displaying numeric values. mon_currency_symbol Optional [ str ] The currency symbol shown for money value. mon_currency_location Optional [ Literal ['after-minus', 'end-with-space']] Where the currency symbol should be shown. time_format Optional [ str ] A string representing the format of time values. date_format Optional [ str ] A string representing the format of date values. duration_min Optional [ str ] The smallest unit for displaying durations. duration_max Optional [ str ] The largest unit for displaying durations.","title":"ColumnMetaDataRecord"},{"location":"api/rpc/#columns.metadata.ColumnMetaDataBlob","text":"Bases: TypedDict The metadata fields which can be set for a column in a table. Attributes: Name Type Description attnum int The attnum of the column in the table. bool_input Optional [ Literal ['dropdown', 'checkbox']] How the input for a boolean column should be shown. bool_true Optional [ str ] A string to display for true values. bool_false Optional [ str ] A string to display for false values. num_min_frac_digits Optional [ int ] Minimum digits shown after the decimal point. num_max_frac_digits Optional [ int ] Maximum digits shown after the decimal point. num_grouping Optional [ str ] Specifies how grouping separators are displayed for numeric values. num_format Optional [ str ] Specifies the locale-specific format for displaying numeric values. mon_currency_symbol Optional [ str ] The currency symbol shown for money value. mon_currency_location Optional [ Literal ['after-minus', 'end-with-space']] Where the currency symbol should be shown. time_format Optional [ str ] A string representing the format of time values. date_format Optional [ str ] A string representing the format of date values. duration_min Optional [ str ] The smallest unit for displaying durations. duration_max Optional [ str ] The largest unit for displaying durations.","title":"ColumnMetaDataBlob"},{"location":"api/rpc/#configured-databases","text":"","title":"Configured Databases"},{"location":"api/rpc/#databases.configured.list_","text":"list_ ( * , server_id = None , ** kwargs ) List information about databases for a server. Exposed as list . If called with no server_id , all databases for all servers are listed. Parameters: Name Type Description Default server_id int The Django id of the server containing the databases. None Returns: Type Description list [ ConfiguredDatabaseInfo ] A list of database details.","title":"list_"},{"location":"api/rpc/#databases.configured.disconnect","text":"disconnect ( * , database_id , ** kwargs ) Disconnect a configured database. Parameters: Name Type Description Default database_id int The Django id of the database. required","title":"disconnect"},{"location":"api/rpc/#databases.configured.ConfiguredDatabaseInfo","text":"Bases: TypedDict Information about a database. Attributes: Name Type Description id int the Django ID of the database model instance. name str The name of the database on the server. server_id int the Django ID of the server model instance for the database.","title":"ConfiguredDatabaseInfo"},{"location":"api/rpc/#connections","text":"Classes and functions exposed to the RPC endpoint for creating connections.","title":"Connections"},{"location":"api/rpc/#connections.add_from_known_connection","text":"add_from_known_connection ( * , nickname , database , create_db = False , connection_id = None , sample_data = [] ) Add a new connection from an already existing one. If no connection_id is passed, the internal database connection will be used. Parameters: Name Type Description Default nickname str Identify the added connection. Should be unique. required database str The name of the database on the server. required create_db bool Whether we should create the database database if it doesn\u2019t already exist. False connection_id int Identifies the known connection when combined with the user_database value for the connection_type parameter None sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. [] Returns: Type Description ConnectionReturn Metadata about the Database associated with the connection.","title":"add_from_known_connection"},{"location":"api/rpc/#connections.add_from_scratch","text":"add_from_scratch ( * , nickname , database , user , password , host , port , sample_data = [] ) Add a new connection to a PostgreSQL server from scratch. This requires inputting valid credentials for the connection. When setting up the connection, therefore, the database must already exist on the PostgreSQL server. Parameters: Name Type Description Default nickname str Identify the added connection. Should be unique. required database str The name of the database on the server. required user str A valid user (role) on the server, with CONNECT and CREATE privileges on the database given by database . required password str The password for user . required host str The hostname or IP address of the PostgreSQL server. required port int The port of the PostgreSQL server. required sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. [] Returns: Type Description ConnectionReturn Metadata about the Database associated with the connection.","title":"add_from_scratch"},{"location":"api/rpc/#connections.grant_access_to_user","text":"grant_access_to_user ( * , connection_id , user_id ) Migrate a connection to new models and grant access to a user. This function is designed to be temporary, and should probably be removed once we have completed the new users and permissions setup for beta. You pass any conneciton id and user id. The function will fill the required models as needed. Parameters: Name Type Description Default connection_id int The Django id of an old-style connection. required user_id int The Django id of a user. required","title":"grant_access_to_user"},{"location":"api/rpc/#connections.ConnectionReturn","text":"Bases: TypedDict Information about a connection model. Attributes: Name Type Description id int The Django id of the Connection object added. nickname str Used to identify the added connection. database str The name of the database on the server. username str The username of the role for the connection. host str The hostname or IP address of the Postgres server. port int The port of the Postgres server.","title":"ConnectionReturn"},{"location":"api/rpc/#constraints","text":"Classes and functions exposed to the RPC endpoint for managing table constraints.","title":"Constraints"},{"location":"api/rpc/#constraints.list_","text":"list_ ( * , table_oid , database_id , ** kwargs ) List information about constraints in a table. Exposed as list . Parameters: Name Type Description Default table_oid int The oid of the table to list constraints for. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ ConstraintInfo ] A list of constraint details.","title":"list_"},{"location":"api/rpc/#constraints.add","text":"add ( * , table_oid , constraint_def_list , database_id , ** kwargs ) Add constraint(s) on a table in bulk. Parameters: Name Type Description Default table_oid int Identity of the table to delete constraint for. required constraint_def_list CreatableConstraintInfo A list describing the constraints to add. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ int ] The oid(s) of all the constraints on the table.","title":"add"},{"location":"api/rpc/#constraints.delete","text":"delete ( * , table_oid , constraint_oid , database_id , ** kwargs ) Delete a constraint from a table. Parameters: Name Type Description Default table_oid int Identity of the table to delete constraint for. required constraint_oid int The OID of the constraint to delete. required database_id int The Django id of the database containing the table. required Returns: Type Description str The name of the dropped constraint.","title":"delete"},{"location":"api/rpc/#constraints.ForeignKeyConstraint","text":"Bases: TypedDict Information about a foreign key constraint. Attributes: Name Type Description type str The type of the constraint( 'f' for foreign key constraint). columns list [ int ] List of columns to set a foreign key on. fkey_relation_id int The OID of the referent table. fkey_columns list [ int ] List of referent column(s). name Optional [ str ] The name of the constraint. deferrable Optional [ bool ] Whether to postpone constraint checking until the end of the transaction. fkey_update_action Optional [ str ] Specifies what action should be taken when the referenced key is updated. Valid options include 'a'(no action) (default behavior), 'r'(restrict) , 'c'(cascade) , 'n'(set null) , 'd'(set default) fkey_delete_action Optional [ str ] Specifies what action should be taken when the referenced key is deleted. Valid options include 'a'(no action) (default behavior), 'r'(restrict) , 'c'(cascade) , 'n'(set null) , 'd'(set default) fkey_match_type Optional [ str ] Specifies how the foreign key matching should be performed. Valid options include 'f'(full match) , 's'(simple match) (default behavior).","title":"ForeignKeyConstraint"},{"location":"api/rpc/#constraints.PrimaryKeyConstraint","text":"Bases: TypedDict Information about a primary key constraint. Attributes: Name Type Description type str The type of the constraint( 'p' for primary key constraint). columns list [ int ] List of columns to set a primary key on. name Optional [ str ] The name of the constraint. deferrable Optional [ bool ] Whether to postpone constraint checking until the end of the transaction.","title":"PrimaryKeyConstraint"},{"location":"api/rpc/#constraints.UniqueConstraint","text":"Bases: TypedDict Information about a unique constraint. Attributes: Name Type Description type str The type of the constraint( 'u' for unique constraint). columns list [ int ] List of columns to set a unique constraint on. name Optional [ str ] The name of the constraint. deferrable Optional [ bool ] Whether to postpone constraint checking until the end of the transaction.","title":"UniqueConstraint"},{"location":"api/rpc/#constraints.CreatableConstraintInfo","text":"CreatableConstraintInfo = list [ Union [ ForeignKeyConstraint , PrimaryKeyConstraint , UniqueConstraint , ] ] Type alias for a list of createable constraints which can be unique, primary key, or foreign key constraints.","title":"CreatableConstraintInfo"},{"location":"api/rpc/#data-modeling","text":"Classes and functions exposed to the RPC endpoint for managing data models.","title":"Data Modeling"},{"location":"api/rpc/#data_modeling.add_foreign_key_column","text":"add_foreign_key_column ( * , column_name , referrer_table_oid , referent_table_oid , database_id , ** kwargs ) Add a foreign key column to a table. The foreign key column will be newly created, and will reference the id column of the referent table. Parameters: Name Type Description Default column_name str The name of the column to create. required referrer_table_oid int The OID of the table getting the new column. required referent_table_oid int The OID of the table being referenced. required","title":"add_foreign_key_column"},{"location":"api/rpc/#data_modeling.add_mapping_table","text":"add_mapping_table ( * , table_name , mapping_columns , schema_oid , database_id , ** kwargs ) Add a mapping table to give a many-to-many link between referents. The foreign key columns in the mapping table will reference the id column of the referent tables. Parameters: Name Type Description Default table_name str The name for the new mapping table. required schema_oid int The OID of the schema for the mapping table. required mapping_columns list [ MappingColumn ] The foreign key columns to create in the mapping table. required","title":"add_mapping_table"},{"location":"api/rpc/#data_modeling.suggest_types","text":"suggest_types ( * , table_oid , database_id , ** kwargs ) Infer the best type for each column in the table. Currently we only suggest different types for columns which originate as type text . Parameters: Name Type Description Default table_oid int The OID of the table whose columns we\u2019re inferring types for. required database_id int The Django id of the database containing the table. required The response JSON will have attnum keys, and values will be the result of format_type for the inferred type of each column, i.e., the canonical string referring to the type.","title":"suggest_types"},{"location":"api/rpc/#data_modeling.split_table","text":"split_table ( * , table_oid , column_attnums , extracted_table_name , database_id , relationship_fk_column_name = None , ** kwargs ) Extract columns from a table to create a new table, linked by a foreign key. Parameters: Name Type Description Default table_oid int The OID of the table whose columns we\u2019ll extract. required column_attnums list A list of the attnums of the columns to extract. required extracted_table_name str The name of the new table to be made from the extracted columns. required database_id int The Django id of the database containing the table. required relationship_fk_column_name str The name to give the new foreign key column in the remainder table (optional) None Returns: Type Description SplitTableInfo The SplitTableInfo object describing the details for the created table as a result of column extraction.","title":"split_table"},{"location":"api/rpc/#data_modeling.move_columns","text":"move_columns ( * , source_table_oid , target_table_oid , move_column_attnums , database_id , ** kwargs ) Extract columns from a table to a referent table, linked by a foreign key. Parameters: Name Type Description Default source_table_oid int The OID of the source table whose column(s) we\u2019ll extract. required target_table_oid int The OID of the target table where the extracted column(s) will be added. required move_column_attnums list [ int ] The list of attnum(s) to move from source table to the target table. required database_id int The Django id of the database containing the table. required","title":"move_columns"},{"location":"api/rpc/#data_modeling.MappingColumn","text":"Bases: TypedDict An object defining a foreign key column in a mapping table. Attributes: Name Type Description column_name str The name of the foreign key column. referent_table_oid int The OID of the table the column references.","title":"MappingColumn"},{"location":"api/rpc/#data_modeling.SplitTableInfo","text":"Bases: TypedDict Information about a table, created from column extraction. Attributes: Name Type Description extracted_table_oid int The OID of the table that is created from column extraction. new_fkey_attnum int The attnum of the newly created foreign key column referring the extracted_table on the original table.","title":"SplitTableInfo"},{"location":"api/rpc/#databases","text":"","title":"Databases"},{"location":"api/rpc/#databases.get","text":"get ( * , database_id , ** kwargs ) Get information about a database. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description DatabaseInfo Information about the database, and the current user privileges.","title":"get"},{"location":"api/rpc/#databases.delete","text":"delete ( * , database_oid , database_id , ** kwargs ) Drop a database from the server. Parameters: Name Type Description Default database_oid int The OID of the database to delete on the database. required database_id int The Django id of the database to connect to. required","title":"delete"},{"location":"api/rpc/#databases.DatabaseInfo","text":"Bases: TypedDict Information about a database current user privileges on it. Attributes: Name Type Description oid int The oid of the database on the server. name str The name of the database on the server. owner_oid int The oid of the owner of the database. current_role_priv list [ Literal ['CONNECT', 'CREATE', 'TEMPORARY']] A list of privileges available to the user. current_role_owns bool Whether the user is an owner of the database.","title":"DatabaseInfo"},{"location":"api/rpc/#database-privileges","text":"","title":"Database Privileges"},{"location":"api/rpc/#databases.privileges.list_direct","text":"list_direct ( * , database_id , ** kwargs ) List database privileges for non-inherited roles. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description list [ DBPrivileges ] A list of database privileges.","title":"list_direct"},{"location":"api/rpc/#databases.privileges.replace_for_roles","text":"replace_for_roles ( * , privileges , database_id , ** kwargs ) Replace direct database privileges for roles. Possible privileges are CONNECT , CREATE , and TEMPORARY . Only roles which are included in a passed DBPrivileges object are affected. WARNING: Any privilege included in the direct list for a role is GRANTed, and any privilege not included is REVOKEd. Attributes: Name Type Description privileges The new privilege sets for roles. database_id The Django id of the database. Returns: Type Description list [ DBPrivileges ] A list of all non-default privileges on the database after the list [ DBPrivileges ] operation.","title":"replace_for_roles"},{"location":"api/rpc/#databases.privileges.transfer_ownership","text":"transfer_ownership ( * , new_owner_oid , database_id , ** kwargs ) Transfers ownership of the current database to a new owner. Attributes: Name Type Description new_owner_oid The OID of the role whom we want to be the new owner of the current database. database_id The Django id of the database whose ownership is to be transferred. To successfully transfer ownership of a database to a new owner the current user must: Be a Superuser/Owner of the current database. Be a MEMBER of the new owning role. i.e. The current role should be able to SET ROLE to the new owning role. Have CREATEDB privilege. Returns: Type Description DatabaseInfo Information about the database, and the current user privileges.","title":"transfer_ownership"},{"location":"api/rpc/#databases.privileges.DBPrivileges","text":"Bases: TypedDict Information about database privileges. Attributes: Name Type Description role_oid int The oid of the role on the database server. direct list [ Literal ['CONNECT', 'CREATE', 'TEMPORARY']] A list of database privileges for the afforementioned role_oid.","title":"DBPrivileges"},{"location":"api/rpc/#database-setup","text":"RPC functions for setting up database connections.","title":"Database Setup"},{"location":"api/rpc/#databases.setup.create_new","text":"create_new ( * , database , sample_data = [], ** kwargs ) Set up a new database on the internal server. The calling user will get access to that database using the default role stored in Django settings. Parameters: Name Type Description Default database str The name of the new database. required sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. []","title":"create_new"},{"location":"api/rpc/#databases.setup.connect_existing","text":"connect_existing ( * , host , port , database , role , password , sample_data = [], ** kwargs ) Connect Mathesar to an existing database on a server. The calling user will get access to that database using the credentials passed to this function. Parameters: Name Type Description Default host str The host of the database server. required port int The port of the database server. required database str The name of the database on the server. required role str The role on the server to use for the connection. required password str A password valid for the role. required sample_data list [ str ] A list of strings requesting that some example data sets be installed on the underlying database. Valid list members are \u2018library_management\u2019 and \u2018movie_collection\u2019. []","title":"connect_existing"},{"location":"api/rpc/#databases.setup.DatabaseConnectionResult","text":"Bases: TypedDict Info about the objects resulting from calling the setup functions. These functions will get or create an instance of the Server, Database, and ConfiguredRole models, as well as a UserDatabaseRoleMap entry. Attributes: Name Type Description server ConfiguredServerInfo Information on the Server model instance. database ConfiguredDatabaseInfo Information on the Database model instance. configured_role ConfiguredRoleInfo Information on the ConfiguredRole model instance.","title":"DatabaseConnectionResult"},{"location":"api/rpc/#explorations","text":"Classes and functions exposed to the RPC endpoint for managing explorations.","title":"Explorations"},{"location":"api/rpc/#explorations.list_","text":"list_ ( * , database_id , schema_oid = None , ** kwargs ) List information about explorations for a database. Exposed as list . Parameters: Name Type Description Default database_id int The Django id of the database containing the explorations. required schema_oid int The OID of the schema containing the base table(s) of the exploration(s).(optional) None Returns: Type Description list [ ExplorationInfo ] A list of exploration details.","title":"list_"},{"location":"api/rpc/#explorations.get","text":"get ( * , exploration_id , ** kwargs ) List information about an exploration. Parameters: Name Type Description Default exploration_id int The Django id of the exploration. required Returns: Type Description ExplorationInfo Exploration details for a given exploration_id.","title":"get"},{"location":"api/rpc/#explorations.add","text":"add ( * , exploration_def ) Add a new exploration. Parameters: Name Type Description Default exploration_def ExplorationDef A dict describing the exploration to create. required Returns: Type Description ExplorationInfo The exploration details for the newly created exploration.","title":"add"},{"location":"api/rpc/#explorations.delete","text":"delete ( * , exploration_id , ** kwargs ) Delete an exploration. Parameters: Name Type Description Default exploration_id int The Django id of the exploration to delete. required","title":"delete"},{"location":"api/rpc/#explorations.replace","text":"replace ( * , new_exploration ) Replace a saved exploration. Parameters: Name Type Description Default new_exploration ExplorationInfo A dict describing the exploration to replace, including the updated fields. required Returns: Type Description ExplorationInfo The exploration details for the replaced exploration.","title":"replace"},{"location":"api/rpc/#explorations.run","text":"run ( * , exploration_def , limit = 100 , offset = 0 , ** kwargs ) Run an exploration. Parameters: Name Type Description Default exploration_def ExplorationDef A dict describing an exploration to run. required limit int The max number of rows to return.(default 100) 100 offset int The number of rows to skip.(default 0) 0 Returns: Type Description ExplorationResult The result of the exploration run.","title":"run"},{"location":"api/rpc/#explorations.run_saved","text":"run_saved ( * , exploration_id , limit = 100 , offset = 0 , ** kwargs ) Run a saved exploration. Parameters: Name Type Description Default exploration_id int The Django id of the exploration to run. required limit int The max number of rows to return.(default 100) 100 offset int The number of rows to skip.(default 0) 0 Returns: Type Description ExplorationResult The result of the exploration run.","title":"run_saved"},{"location":"api/rpc/#explorations.ExplorationInfo","text":"Bases: TypedDict Information about an exploration. Attributes: Name Type Description id int The Django id of an exploration. database_id int The Django id of the database containing the exploration. name str The name of the exploration. base_table_oid int The OID of the base table of the exploration on the database. schema_oid int The OID of the schema containing the base table of the exploration. initial_columns list A list describing the columns to be included in the exploration. transformations Optional [ list ] A list describing the transformations to be made on the included columns. display_options Optional [ list ] A list describing metadata for the columns in the explorations. display_names Optional [ dict ] A map between the actual column names on the database and the alias to be displayed(if any). description Optional [ str ] The description of the exploration.","title":"ExplorationInfo"},{"location":"api/rpc/#explorations.ExplorationDef","text":"Bases: TypedDict Definition about a runnable exploration. Attributes: Name Type Description database_id int The Django id of the database containing the exploration. name str The name of the exploration. base_table_oid int The OID of the base table of the exploration on the database. schema_oid int The OID of the schema containing the base table of the exploration. initial_columns list A list describing the columns to be included in the exploration. transformations Optional [ list ] A list describing the transformations to be made on the included columns. display_options Optional [ list ] A list describing metadata for the columns in the explorations. display_names Optional [ dict ] A map between the actual column names on the database and the alias to be displayed(if any). description Optional [ str ] The description of the exploration.","title":"ExplorationDef"},{"location":"api/rpc/#explorations.ExplorationResult","text":"Bases: TypedDict Result of an exploration run. Attributes: Name Type Description query dict A dict describing the exploration that ran. records dict A dict describing the total count of records along with the contents of those records. output_columns tuple A tuple describing the names of the columns included in the exploration. column_metadata dict A dict describing the metadata applied to included columns. limit Optional [ int ] Specifies the max number of rows returned.(default 100) offset Optional [ int ] Specifies the number of rows skipped.(default 0) filter Optional [ dict ] A dict describing filters applied to an exploration. order_by Optional [ list [ dict ]] The ordering applied to the columns of an exploration. search Optional [ list [ dict ]] Specifies a list of dicts containing column names and searched expression. duplicate_only Optional [ list ] A list of column names for which you want duplicate records.","title":"ExplorationResult"},{"location":"api/rpc/#records","text":"Classes and functions exposed to the RPC endpoint for managing table records.","title":"Records"},{"location":"api/rpc/#records.list_","text":"list_ ( * , table_oid , database_id , limit = None , offset = None , order = None , filter = None , grouping = None , return_record_summaries = False , ** kwargs ) List records from a table, and its row count. Exposed as list . Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required limit int The maximum number of rows we\u2019ll return. None offset int The number of rows to skip before returning records from following rows. None order list [ OrderBy ] An array of ordering definition objects. None filter Filter An array of filter definition objects. None grouping Grouping An array of group definition objects. None return_record_summaries bool Whether to return summaries of retrieved records. False Returns: Type Description RecordList The requested records, along with some metadata.","title":"list_"},{"location":"api/rpc/#records.get","text":"get ( * , record_id , table_oid , database_id , return_record_summaries = False , ** kwargs ) Get single record from a table by its primary key. Parameters: Name Type Description Default record_id Any The primary key value of the record to be gotten. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required return_record_summaries bool Whether to return summaries of the retrieved record. False Returns: Type Description RecordList The requested record, along with some metadata.","title":"get"},{"location":"api/rpc/#records.add","text":"add ( * , record_def , table_oid , database_id , return_record_summaries = False , ** kwargs ) Add a single record to a table. The form of the record_def is determined by the underlying table. Keys should be attnums, and values should be the desired value for that column in the created record. Missing keys will use default values (if set on the DB), and explicit null values will set null for that value regardless of default (with obvious exceptions where that would violate some constraint) Parameters: Name Type Description Default record_def dict An object representing the record to be added. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required return_record_summaries bool Whether to return summaries of the added record. False Returns: Type Description RecordAdded The created record, along with some metadata.","title":"add"},{"location":"api/rpc/#records.patch","text":"patch ( * , record_def , record_id , table_oid , database_id , return_record_summaries = False , ** kwargs ) Modify a record in a table. The form of the record_def is determined by the underlying table. Keys should be attnums, and values should be the desired value for that column in the modified record. Explicit null values will set null for that value (with obvious exceptions where that would violate some constraint). Parameters: Name Type Description Default record_def dict An object representing the record to be added. required record_id Any The primary key value of the record to modify. required table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required return_record_summaries bool Whether to return summaries of the modified record. False Returns: Type Description RecordAdded The modified record, along with some metadata.","title":"patch"},{"location":"api/rpc/#records.delete","text":"delete ( * , record_ids , table_oid , database_id , ** kwargs ) Delete records from a table by primary key. Parameters: Name Type Description Default record_ids list [ Any ] The primary key values of the records to be deleted. required table_oid int The identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description Optional [ int ] The number of records deleted.","title":"delete"},{"location":"api/rpc/#records.search","text":"search ( * , table_oid , database_id , search_params = [], limit = 10 , return_record_summaries = False , ** kwargs ) List records from a table according to search_params . Literals will be searched for in a basic way in string-like columns, but will have to match exactly in non-string-like columns. Records are assigned a score based on how many matches, and of what quality, they have with the passed search parameters. Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required search_params list [ SearchParam ] Results are ranked and filtered according to the objects passed here. [] limit int The maximum number of rows we\u2019ll return. 10 Returns: Type Description RecordList The requested records, along with some metadata.","title":"search"},{"location":"api/rpc/#records.RecordList","text":"Bases: TypedDict Records from a table, along with some meta data The form of the objects in the results array is determined by the underlying records being listed. The keys of each object are the attnums of the retrieved columns. The values are the value for the given row, for the given column. Attributes: Name Type Description count int The total number of records in the table. results list [ dict ] An array of record objects. grouping GroupingResponse Information for displaying grouped records. linked_record_smmaries GroupingResponse Information for previewing foreign key values, provides a map of foreign key to a text summary. record_summaries dict [ str , str ] Information for previewing returned records.","title":"RecordList"},{"location":"api/rpc/#records.RecordAdded","text":"Bases: TypedDict Record from a table, along with some meta data The form of the object in the results array is determined by the underlying records being listed. The keys of each object are the attnums of the retrieved columns. The values are the value for the given row, for the given column. Attributes: Name Type Description results list [ dict ] An array of a single record objects (the one added). linked_record_summaries dict [ str , dict [ str , str ]] Information for previewing foreign key values, provides a map of foreign key to a text summary. record_summaries dict [ str , str ] Information for previewing an added record.","title":"RecordAdded"},{"location":"api/rpc/#records.OrderBy","text":"Bases: TypedDict An object defining an ORDER BY clause. Attributes: Name Type Description attnum int The attnum of the column to order by. direction Literal ['asc', 'desc'] The direction to order by.","title":"OrderBy"},{"location":"api/rpc/#records.Filter","text":"Bases: TypedDict An object defining a filter to be used in a WHERE clause. For valid type values, see the msar.filter_templates table defined in mathesar/db/sql/00_msar.sql . Attributes: Name Type Description type str a function or operator to be used in filtering. args list [ Union [ Filter , FilterAttnum , FilterLiteral ]] The ordered arguments for the function or operator.","title":"Filter"},{"location":"api/rpc/#records.FilterAttnum","text":"Bases: TypedDict An object choosing a column for a filter. Attributes: Name Type Description type Literal ['attnum'] Must be \"attnum\" value int The attnum of the column to filter by","title":"FilterAttnum"},{"location":"api/rpc/#records.FilterLiteral","text":"Bases: TypedDict An object defining a literal for an argument to a filter. Attributes: Name Type Description type Literal ['literal'] must be \"literal\" . value Any The value of the literal.","title":"FilterLiteral"},{"location":"api/rpc/#records.Grouping","text":"Bases: TypedDict Grouping definition. The table involved must have a single column primary key. Attributes: Name Type Description columns list [ int ] The columns to be grouped by. preproc list [ str ] The preprocessing funtions to apply (if any).","title":"Grouping"},{"location":"api/rpc/#records.Group","text":"Bases: TypedDict Group definition. Note that the count is over all rows in the group, whether returned or not. However, result_indices is restricted to only the rows returned. This is to avoid potential problems if there are many rows in the group (e.g., the whole table), but we only return a few. Attributes: Name Type Description id int The id of the group. Consistent for same input. count int The number of items in the group. results_eq list [ dict ] The value the results of the group equal. result_indices list [ int ] The 0-indexed positions of group members in the results array.","title":"Group"},{"location":"api/rpc/#records.GroupingResponse","text":"Bases: TypedDict Grouping response object. Extends Grouping with actual groups. Attributes: Name Type Description columns list [ int ] The columns to be grouped by. preproc list [ str ] The preprocessing funtions to apply (if any). groups list [ Group ] The groups applicable to the records being returned.","title":"GroupingResponse"},{"location":"api/rpc/#records.SearchParam","text":"Bases: TypedDict Search definition for a single column. Attributes: Name Type Description attnum int The attnum of the column in the table. literal Any The literal to search for in the column.","title":"SearchParam"},{"location":"api/rpc/#roles","text":"","title":"Roles"},{"location":"api/rpc/#roles.list_","text":"list_ ( * , database_id , ** kwargs ) List information about roles for a database server. Exposed as list . Requires a database id inorder to connect to the server. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description list [ RoleInfo ] A list of roles present on the database server.","title":"list_"},{"location":"api/rpc/#roles.add","text":"add ( * , rolename , database_id , password = None , login = None , ** kwargs ) Add a new login/non-login role on a database server. Parameters: Name Type Description Default rolename str The name of the role to be created. required database_id int The Django id of the database. required password str The password for the rolename to set. None login bool Whether the role to be created could login. None Returns: Type Description RoleInfo A dict describing the created role.","title":"add"},{"location":"api/rpc/#roles.delete","text":"delete ( * , role_oid , database_id , ** kwargs ) Drop a role on a database server. Parameters: Name Type Description Default role_oid int The OID of the role to drop on the database. required database_id int The Django id of the database. required","title":"delete"},{"location":"api/rpc/#roles.get_current_role","text":"get_current_role ( * , database_id , ** kwargs ) Get information about the current role and all the parent role(s) whose privileges are immediately available to current role without doing SET ROLE. Parameters: Name Type Description Default database_id int The Django id of the database. required Returns: Type Description dict A dict describing the current role.","title":"get_current_role"},{"location":"api/rpc/#roles.set_members","text":"set_members ( * , parent_role_oid , members , database_id , ** kwargs ) Grant/Revoke direct membership to/from roles. Parameters: Name Type Description Default parent_role_oid int The OID of role whose membership will be granted/revoked to/from other roles. required members list An array of role OID(s) whom we want to grant direct membership of the parent role. Only the OID(s) present in the array will be granted membership of parent role, Membership will be revoked for existing members not present in this array. required Returns: Type Description RoleInfo A dict describing the updated information of the parent role.","title":"set_members"},{"location":"api/rpc/#roles.RoleInfo","text":"Bases: TypedDict Information about a role. Attributes: Name Type Description oid int The OID of the role. name str Name of the role. super bool Whether the role has SUPERUSER status. inherits bool Whether the role has INHERIT attribute. create_role bool Whether the role has CREATEROLE attribute. create_db bool Whether the role has CREATEDB attribute. login bool Whether the role has LOGIN attribute. description Optional [ str ] A description of the role members Optional [ list [ RoleMember ]] The member roles that directly inherit the role. Refer PostgreSQL documenation on pg_roles table . Role attributes Role membership","title":"RoleInfo"},{"location":"api/rpc/#roles.RoleMember","text":"Bases: TypedDict Information about a member role of a directly inherited role. Attributes: Name Type Description oid int The OID of the member role. admin bool Whether the member role has ADMIN option on the inherited role.","title":"RoleMember"},{"location":"api/rpc/#roles-configured","text":"","title":"Roles Configured"},{"location":"api/rpc/#roles.configured.list_","text":"list_ ( * , server_id , ** kwargs ) List information about roles configured in Mathesar. Exposed as list . Parameters: Name Type Description Default server_id int The Django id of the Server containing the configured roles. required Returns: Type Description list [ ConfiguredRoleInfo ] A list of configured roles.","title":"list_"},{"location":"api/rpc/#roles.configured.add","text":"add ( * , server_id , name , password , ** kwargs ) Configure a role in Mathesar for a database server. Parameters: Name Type Description Default server_id int The Django id of the Server to contain the configured role. required name str The name of the role. required password str The password for the role. required Returns: Type Description ConfiguredRoleInfo The newly configured role.","title":"add"},{"location":"api/rpc/#roles.configured.delete","text":"delete ( * , configured_role_id , ** kwargs ) Delete a configured role for a server. Parameters: Name Type Description Default configured_role_id int The Django id of the ConfiguredRole model instance. required","title":"delete"},{"location":"api/rpc/#roles.configured.set_password","text":"set_password ( * , configured_role_id , password , ** kwargs ) Set the password of a configured role for a server. Parameters: Name Type Description Default configured_role_id int The Django id of the ConfiguredRole model instance. required password str The password for the role. required","title":"set_password"},{"location":"api/rpc/#roles.configured.ConfiguredRoleInfo","text":"Bases: TypedDict Information about a role configured in Mathesar. Attributes: Name Type Description id int the Django ID of the ConfiguredRole model instance. name str The name of the role. server_id int The Django ID of the Server model instance for the role.","title":"ConfiguredRoleInfo"},{"location":"api/rpc/#schemas","text":"","title":"Schemas"},{"location":"api/rpc/#schemas.list_","text":"list_ ( * , database_id , ** kwargs ) List information about schemas in a database. Exposed as list . Parameters: Name Type Description Default database_id int The Django id of the database containing the table. required Returns: Type Description list [ SchemaInfo ] A list of SchemaInfo objects","title":"list_"},{"location":"api/rpc/#schemas.get","text":"get ( * , schema_oid , database_id , ** kwargs ) Get information about a schema in a database. Parameters: Name Type Description Default schema_oid int The OID of the schema to get. required database_id int The Django id of the database containing the table. required Returns: Type Description SchemaInfo The SchemaInfo describing the user-defined schema in the database.","title":"get"},{"location":"api/rpc/#schemas.add","text":"add ( * , name , database_id , owner_oid = None , description = None , ** kwargs ) Add a schema Parameters: Name Type Description Default name str The name of the schema to add. required database_id int The Django id of the database containing the schema. required owner_oid int The OID of the role who will own the new schema. If owner_oid is None, the current role will be the owner of the new schema. None description Optional [ str ] A description of the schema None Returns: Type Description SchemaInfo The SchemaInfo describing the user-defined schema in the database.","title":"add"},{"location":"api/rpc/#schemas.delete","text":"delete ( * , schema_oid , database_id , ** kwargs ) Delete a schema, given its OID. Parameters: Name Type Description Default schema_oid int The OID of the schema to delete. required database_id int The Django id of the database containing the schema. required","title":"delete"},{"location":"api/rpc/#schemas.patch","text":"patch ( * , schema_oid , database_id , patch , ** kwargs ) Patch a schema, given its OID. Parameters: Name Type Description Default schema_oid int The OID of the schema to delete. required database_id int The Django id of the database containing the schema. required patch SchemaPatch A SchemaPatch object containing the fields to update. required Returns: Type Description SchemaInfo The SchemaInfo describing the user-defined schema in the database.","title":"patch"},{"location":"api/rpc/#schemas.SchemaInfo","text":"Bases: TypedDict Information about a schema Attributes: Name Type Description oid int The OID of the schema name str The name of the schema description Optional [ str ] A description of the schema owner_oid int The OID of the owner of the schema current_role_priv list [ Literal ['USAGE', 'CREATE']] All privileges available to the calling role on the schema. current_role_owns bool Whether the current role is the owner of the schema (even indirectly). table_count int The number of tables in the schema","title":"SchemaInfo"},{"location":"api/rpc/#schemas.SchemaPatch","text":"Bases: TypedDict Attributes: Name Type Description name Optional [ str ] The name of the schema description Optional [ str ] A description of the schema","title":"SchemaPatch"},{"location":"api/rpc/#schema-privileges","text":"","title":"Schema Privileges"},{"location":"api/rpc/#schemas.privileges.list_direct","text":"list_direct ( * , schema_oid , database_id , ** kwargs ) List direct schema privileges for roles. Parameters: Name Type Description Default schema_oid int The OID of the schema whose privileges we\u2019ll list. required database_id int The Django id of the database containing the schema. required Returns: Type Description list [ SchemaPrivileges ] A list of schema privileges.","title":"list_direct"},{"location":"api/rpc/#schemas.privileges.replace_for_roles","text":"replace_for_roles ( * , privileges , schema_oid , database_id , ** kwargs ) Replace direct schema privileges for roles. Possible privileges are USAGE and CREATE . Only roles which are included in a passed SchemaPrivileges object are affected. WARNING: Any privilege included in the direct list for a role is GRANTed, and any privilege not included is REVOKEd. Parameters: Name Type Description Default privileges list [ SchemaPrivileges ] The new privilege sets for roles. required schema_oid int The OID of the affected schema. required database_id int The Django id of the database containing the schema. required Returns: Type Description list [ SchemaPrivileges ] A list of all non-default privileges on the schema after the list [ SchemaPrivileges ] operation.","title":"replace_for_roles"},{"location":"api/rpc/#schemas.privileges.transfer_ownership","text":"transfer_ownership ( * , schema_oid , new_owner_oid , database_id , ** kwargs ) Transfers ownership of a given schema to a new owner. Attributes: Name Type Description schema_oid The OID of the schema to transfer. new_owner_oid The OID of the role whom we want to be the new owner of the schema. To successfully transfer ownership of a schema to a new owner the current user must: Be a Superuser/Owner of the schema. Be a MEMBER of the new owning role. i.e. The current role should be able to SET ROLE to the new owning role. Have CREATE privilege for the database. Returns: Type Description SchemaInfo Information about the schema, and the current user privileges.","title":"transfer_ownership"},{"location":"api/rpc/#schemas.privileges.SchemaPrivileges","text":"Bases: TypedDict Information about schema privileges for a role. Attributes: Name Type Description role_oid int The oid of the role. direct list [ Literal ['USAGE', 'CREATE']] A list of schema privileges for the afforementioned role_oid.","title":"SchemaPrivileges"},{"location":"api/rpc/#servers","text":"","title":"Servers"},{"location":"api/rpc/#tables","text":"","title":"Tables"},{"location":"api/rpc/#tables.list_","text":"list_ ( * , schema_oid , database_id , ** kwargs ) List information about tables for a schema. Exposed as list . Parameters: Name Type Description Default schema_oid int Identity of the schema in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ TableInfo ] A list of table details.","title":"list_"},{"location":"api/rpc/#tables.get","text":"get ( * , table_oid , database_id , ** kwargs ) List information about a table for a schema. Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description TableInfo Table details for a given table oid.","title":"get"},{"location":"api/rpc/#tables.add","text":"add ( * , schema_oid , database_id , table_name = None , column_data_list = [], constraint_data_list = [], owner_oid = None , comment = None , ** kwargs ) Add a table with a default id column. Parameters: Name Type Description Default schema_oid int Identity of the schema in the user\u2019s database. required database_id int The Django id of the database containing the table. required table_name str Name of the table to be created. None column_data_list list [ CreatableColumnInfo ] A list describing columns to be created for the new table, in order. [] constraint_data_list list [ CreatableConstraintInfo ] A list describing constraints to be created for the new table. [] owner_oid int The OID of the role who will own the new table. If owner_oid is None, the current role will be the owner of the new table. None comment str The comment for the new table. None Returns: Type Description AddedTableInfo The oid & name of the created table.","title":"add"},{"location":"api/rpc/#tables.delete","text":"delete ( * , table_oid , database_id , cascade = False , ** kwargs ) Delete a table from a schema. Parameters: Name Type Description Default table_oid int Identity of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required cascade bool Whether to drop the dependent objects. False Returns: Type Description str The name of the dropped table.","title":"delete"},{"location":"api/rpc/#tables.patch","text":"patch ( * , table_oid , table_data_dict , database_id , ** kwargs ) Alter details of a preexisting table in a database. Parameters: Name Type Description Default table_oid str Identity of the table whose name, description or columns we\u2019ll modify. required table_data_dict SettableTableInfo A list describing desired table alterations. required database_id int The Django id of the database containing the table. required Returns: Type Description str The name of the altered table.","title":"patch"},{"location":"api/rpc/#tables.import_","text":"import_ ( * , data_file_id , schema_oid , database_id , table_name = None , comment = None , ** kwargs ) Import a CSV/TSV into a table. Parameters: Name Type Description Default data_file_id int The Django id of the DataFile containing desired CSV/TSV. required schema_oid int Identity of the schema in the user\u2019s database. required database_id int The Django id of the database containing the table. required table_name str Name of the table to be imported. None comment str The comment for the new table. None Returns: Type Description AddedTableInfo The oid and name of the created table.","title":"import_"},{"location":"api/rpc/#tables.get_import_preview","text":"get_import_preview ( * , table_oid , columns , database_id , limit = 20 , ** kwargs ) Preview an imported table. Parameters: Name Type Description Default table_oid int Identity of the imported table in the user\u2019s database. required columns list [ PreviewableColumnInfo ] List of settings describing the casts to be applied to the columns. required database_id int The Django id of the database containing the table. required limit int The upper limit for the number of records to return. 20 Returns: Type Description list [ dict ] The records from the specified columns of the table.","title":"get_import_preview"},{"location":"api/rpc/#tables.list_joinable","text":"list_joinable ( * , table_oid , database_id , max_depth = 3 , ** kwargs ) List details for joinable tables. Parameters: Name Type Description Default table_oid int Identity of the table to get joinable tables for. required database_id int The Django id of the database containing the table. required max_depth int Specifies how far to search for joinable tables. 3 Returns: Type Description JoinableTableInfo Joinable table details for a given table.","title":"list_joinable"},{"location":"api/rpc/#tables.list_with_metadata","text":"list_with_metadata ( * , schema_oid , database_id , ** kwargs ) List tables in a schema, along with the metadata associated with each table Parameters: Name Type Description Default schema_oid int PostgreSQL OID of the schema containing the tables. required database_id int The Django id of the database containing the table. required Returns: Type Description list A list of table details along with metadata.","title":"list_with_metadata"},{"location":"api/rpc/#tables.get_with_metadata","text":"get_with_metadata ( * , table_oid , database_id , ** kwargs ) Get information about a table in a schema, along with the associated table metadata. Parameters: Name Type Description Default table_oid int The OID of the table in the user\u2019s database. required database_id int The Django id of the database containing the table. required Returns: Type Description dict A dict describing table details along with its metadata.","title":"get_with_metadata"},{"location":"api/rpc/#tables.TableInfo","text":"Bases: TypedDict Information about a table. Attributes: Name Type Description oid int The oid of the table in the schema. name str The name of the table. schema int The oid of the schema where the table lives. description Optional [ str ] The description of the table. owner_oid int The OID of the direct owner of the table. current_role_priv list [ Literal ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'TRUNCATE', 'REFERENCES', 'TRIGGER']] The privileges available to the user on the table. current_role_owns bool Whether the current role owns the table.","title":"TableInfo"},{"location":"api/rpc/#tables.AddedTableInfo","text":"Bases: TypedDict Information about a newly created table. Attributes: Name Type Description oid int The oid of the table in the schema. name str The name of the table.","title":"AddedTableInfo"},{"location":"api/rpc/#tables.SettableTableInfo","text":"Bases: TypedDict Information about a table, restricted to settable fields. When possible, Passing null for a key will clear the underlying setting. E.g., description = null clears the table description. Setting any of name , columns to null is a noop. Attributes: Name Type Description name Optional [ str ] The new name of the table. description Optional [ str ] The description of the table. columns Optional [ list [ SettableColumnInfo ]] A list describing desired column alterations.","title":"SettableTableInfo"},{"location":"api/rpc/#tables.JoinableTableRecord","text":"Bases: TypedDict Information about a singular joinable table. Attributes: Name Type Description base int The OID of the table from which the paths start target int The OID of the table where the paths end. join_path list A list describing joinable paths in the following form: [ [[L_oid0, L_attnum0], [R_oid0, R_attnum0]], [[L_oid1, L_attnum1], [R_oid1, R_attnum1]], [[L_oid2, L_attnum2], [R_oid2, R_attnum2]], \u2026 ] Here, [L_oidN, L_attnumN] represents the left column of a join, and [R_oidN, R_attnumN] the right. fkey_path list Same as join_path expressed in terms of foreign key constraints in the following form: [ [constraint_id0, reversed], [constraint_id1, reversed], ] In this form, constraint_idN is a foreign key constraint, and reversed is a boolean giving whether to travel from referrer to referant (when False) or from referant to referrer (when True). depth int Specifies how far to search for joinable tables. multiple_results bool Specifies whether the path included is reversed.","title":"JoinableTableRecord"},{"location":"api/rpc/#tables.JoinableTableInfo","text":"Bases: TypedDict Information about joinable table(s). Attributes: Name Type Description joinable_tables list [ JoinableTableRecord ] List of reachable joinable table(s) from a base table. target_table_info list Additional info about target table(s) and its column(s).","title":"JoinableTableInfo"},{"location":"api/rpc/#table-metadata","text":"Classes and functions exposed to the RPC endpoint for managing table metadata.","title":"Table Metadata"},{"location":"api/rpc/#tables.metadata.list_","text":"list_ ( * , database_id , ** kwargs ) List metadata associated with tables for a database. Parameters: Name Type Description Default database_id int The Django id of the database containing the table. required Returns: Type Description list [ TableMetaDataRecord ] Metadata object for a given table oid.","title":"list_"},{"location":"api/rpc/#tables.metadata.set_","text":"set_ ( * , table_oid , metadata , database_id , ** kwargs ) Set metadata for a table. Parameters: Name Type Description Default table_oid int The PostgreSQL OID of the table. required metadata TableMetaDataBlob A TableMetaDataBlob object describing desired table metadata to set. required database_id int The Django id of the database containing the table. required","title":"set_"},{"location":"api/rpc/#tables.metadata.TableMetaDataBlob","text":"Bases: TypedDict The metadata fields which can be set on a table Attributes: Name Type Description data_file_id Optional [ int ] Specifies the DataFile model id used for the import. import_verified Optional [ bool ] Specifies whether a file has been successfully imported into a table. column_order Optional [ list [ int ]] The order in which columns of a table are displayed. record_summary_customized Optional [ bool ] Specifies whether the record summary has been customized. record_summary_template Optional [ str ] Record summary template for a referent column.","title":"TableMetaDataBlob"},{"location":"api/rpc/#tables.metadata.TableMetaDataRecord","text":"Bases: TypedDict Metadata for a table in a database. Only the database and table_oid keys are required. Attributes: Name Type Description id int The Django id of the TableMetaData object. database_id int The Django id of the database containing the table. table_oid int The OID of the table in the database. data_file_id Optional [ int ] Specifies the DataFile model id used for the import. import_verified Optional [ bool ] Specifies whether a file has been successfully imported into a table. column_order Optional [ list [ int ]] The order in which columns of a table are displayed. record_summary_customized Optional [ bool ] Specifies whether the record summary has been customized. record_summary_template Optional [ str ] Record summary template for a referent column.","title":"TableMetaDataRecord"},{"location":"api/rpc/#table-privileges","text":"","title":"Table Privileges"},{"location":"api/rpc/#tables.privileges.list_direct","text":"list_direct ( * , table_oid , database_id , ** kwargs ) List direct table privileges for roles. Args: table_oid: The OID of the table whose privileges we\u2019ll list. database_id: The Django id of the database containing the table. Returns: A list of table privileges.","title":"list_direct"},{"location":"api/rpc/#tables.privileges.replace_for_roles","text":"replace_for_roles ( * , privileges , table_oid , database_id , ** kwargs ) Replace direct table privileges for roles. Possible privileges are INSERT , SELECT , UPDATE , DELETE , TRUNCATE , REFERENCES and TRIGGER . Only roles which are included in a passed TablePrivileges object are affected. WARNING: Any privilege included in the direct list for a role is GRANTed, and any privilege not included is REVOKEd. Parameters: Name Type Description Default privileges list [ TablePrivileges ] The new privilege sets for roles. required table_oid int The OID of the affected table. required database_id int The Django id of the database containing the table. required Returns: Type Description list [ TablePrivileges ] A list of all non-default privileges on the table after the list [ TablePrivileges ] operation.","title":"replace_for_roles"},{"location":"api/rpc/#tables.privileges.transfer_ownership","text":"transfer_ownership ( * , table_oid , new_owner_oid , database_id , ** kwargs ) Transfers ownership of a given table to a new owner. Attributes: Name Type Description table_oid The OID of the table to transfer. new_owner_oid The OID of the role whom we want to be the new owner of the table. To successfully transfer ownership of a table to a new owner the current user must: Be a Superuser/Owner of the table. Be a MEMBER of the new owning role. i.e. The current role should be able to SET ROLE to the new owning role. Have CREATE privilege on the table\u2019s schema. Returns: Type Description TableInfo Information about the table, and the current user privileges.","title":"transfer_ownership"},{"location":"api/rpc/#tables.privileges.TablePrivileges","text":"Bases: TypedDict Information about table privileges for a role. Attributes: role_oid: The oid of the role. direct: A list of table privileges for the afforementioned role_oid.","title":"TablePrivileges"},{"location":"api/rpc/#types","text":"Classes and functions exposed to the RPC endpoint for listing types in a database.","title":"Types"},{"location":"api/rpc/#types.list_","text":"list_ () List information about types available on the database. Exposed as list .","title":"list_"},{"location":"api/rpc/#types.TypeInfo","text":"Bases: TypedDict Information about a type. Attributes: Name Type Description identifier str Specifies the type class that db_type(s) belongs to. name str Specifies the UI name for a type class. db_types list Specifies the name(s) of types present on the database. display_options Optional [ dict ] Specifies metadata related to a type class.","title":"TypeInfo"},{"location":"configuration/env-variables/","text":"Environment Variables \u00b6 This page contains all available environment variables supported by Mathesar. See the specific installation guides for the applicable environment variables and instructions on how to set them. Backend configuration \u00b6 SECRET_KEY \u00b6 Description : A unique random string used by Django for cryptographic signing ( see Django docs ). It helps Mathesar secure user sessions and encrypt saved PostgreSQL passwords. Format : A 50 character string Additional information : To generate a secret key you can use this browser-based generator or run this command on MacOS or Linux: echo $(cat /dev/urandom | LC_CTYPE=C tr -dc 'a-zA-Z0-9' | head -c 50) Internal Database configuration \u00b6 Info The database specified in this section will be used to store Mathesar\u2019s internal data. Additionally, it can be optionally repurposed via Mathesar\u2019s UI to store user data. POSTGRES_DB \u00b6 Description : Specifies a name for the database that will be created and used by Mathesar for managing internal data. Default value : mathesar_django POSTGRES_USER \u00b6 Description : Specifies creation of a user with superuser privileges and a database with the same name. Default value : mathesar POSTGRES_PASSWORD \u00b6 Description : Specifies the superuser password that is required to be set for the PostgreSQL docker image. Default value : mathesar POSTGRES_HOST \u00b6 Description : Specifies the host name on which portgres listen for connections from client applications. Default value : mathesar_db POSTGRES_PORT \u00b6 Description : Specifies the port on which portgres listen for connections from client applications. Default value : 5432 Caddy reverse proxy configuration \u00b6 Note These variables are only needed if you\u2019re using the Caddy configuration in our default Docker Compose file. DOMAIN_NAME \u00b6 Description : The public URL that will be used to access Mathesar ( see Caddy docs ). Format : A URL or hostname Example values https://example.com localhost http://localhost Additional information If the protocol is http , then Caddy will serve traffic via HTTP only. If the protocol is https or is not specified, then Caddy will serve traffic via HTTPS (and will redirect all HTTP traffic to HTTPS). In this case Caddy will also attempt to automatically set up HTTPS with Let\u2019s Encrypt for you ( see Caddy docs ). Tip Set this to localhost if you\u2019d like Mathesar to be available only on localhost Set the protocol to http if you don\u2019t want Caddy to automatically handle setting up SSL, e.g. http://example.com","title":"Environment variables"},{"location":"configuration/env-variables/#environment-variables","text":"This page contains all available environment variables supported by Mathesar. See the specific installation guides for the applicable environment variables and instructions on how to set them.","title":"Environment Variables"},{"location":"configuration/env-variables/#backend","text":"","title":"Backend configuration"},{"location":"configuration/env-variables/#secret_key","text":"Description : A unique random string used by Django for cryptographic signing ( see Django docs ). It helps Mathesar secure user sessions and encrypt saved PostgreSQL passwords. Format : A 50 character string Additional information : To generate a secret key you can use this browser-based generator or run this command on MacOS or Linux: echo $(cat /dev/urandom | LC_CTYPE=C tr -dc 'a-zA-Z0-9' | head -c 50)","title":"SECRET_KEY"},{"location":"configuration/env-variables/#db","text":"Info The database specified in this section will be used to store Mathesar\u2019s internal data. Additionally, it can be optionally repurposed via Mathesar\u2019s UI to store user data.","title":"Internal Database configuration"},{"location":"configuration/env-variables/#postgres_db","text":"Description : Specifies a name for the database that will be created and used by Mathesar for managing internal data. Default value : mathesar_django","title":"POSTGRES_DB"},{"location":"configuration/env-variables/#postgres_user","text":"Description : Specifies creation of a user with superuser privileges and a database with the same name. Default value : mathesar","title":"POSTGRES_USER"},{"location":"configuration/env-variables/#postgres_password","text":"Description : Specifies the superuser password that is required to be set for the PostgreSQL docker image. Default value : mathesar","title":"POSTGRES_PASSWORD"},{"location":"configuration/env-variables/#postgres_host","text":"Description : Specifies the host name on which portgres listen for connections from client applications. Default value : mathesar_db","title":"POSTGRES_HOST"},{"location":"configuration/env-variables/#postgres_port","text":"Description : Specifies the port on which portgres listen for connections from client applications. Default value : 5432","title":"POSTGRES_PORT"},{"location":"configuration/env-variables/#caddy","text":"Note These variables are only needed if you\u2019re using the Caddy configuration in our default Docker Compose file.","title":"Caddy reverse proxy configuration"},{"location":"configuration/env-variables/#domain_name","text":"Description : The public URL that will be used to access Mathesar ( see Caddy docs ). Format : A URL or hostname Example values https://example.com localhost http://localhost Additional information If the protocol is http , then Caddy will serve traffic via HTTP only. If the protocol is https or is not specified, then Caddy will serve traffic via HTTPS (and will redirect all HTTP traffic to HTTPS). In this case Caddy will also attempt to automatically set up HTTPS with Let\u2019s Encrypt for you ( see Caddy docs ). Tip Set this to localhost if you\u2019d like Mathesar to be available only on localhost Set the protocol to http if you don\u2019t want Caddy to automatically handle setting up SSL, e.g. http://example.com","title":"DOMAIN_NAME"},{"location":"installation/build-from-source/","text":"Install Mathesar from source on Linux \u00b6 Not a stable release This is a testing build released with the goal of gathering feedback from our community. It has many known issues and is not recommended for production use. For experienced Linux sysadmins To follow this guide you need be experienced with Linux server administration, including the command line interface and some common utilities. If you run into any trouble, we encourage you to open an issue or submit a PR proposing changes to this file . Requirements \u00b6 System \u00b6 We recommend having at least 60 GB disk space and 4 GB of RAM. Operating System \u00b6 We\u2019ve tested this on Debian 12 , but we expect that it can be adapted for other Linux distributions as well. Access \u00b6 You should have root access to the machine you\u2019re installing Mathesar on. Software \u00b6 You\u2019ll need to install the following system packages before you install Mathesar: Python 3.9, 3.10, or 3.11 (along with appropriate venv module) Python version Python older than 3.9 will not run Mathesar. Python 3.12 will run Mathesar, but you\u2019ll have to take extra steps to get some dependencies to build. Installing a package for your OS that provides the libpq-fe.h header file should be enough in most cases. On Debian 12, this header is provided by the libpq-dev package. PostgreSQL 13 or newer (Verify by logging in, and running the query: SELECT version(); ) Caddy (Verify with caddy version ) git (Verify with git --version ) GNU gettext (Verify with gettext --version ) unzip A utility tool to de-archive .zip files (Verify with unzip -v ) Domain (optional) \u00b6 If you want Mathesar to be accessible over the internet, you\u2019ll probably want to set up a domain or sub-domain to use. If you don\u2019t need a domain, you can skip this section. Before you start installation, ensure that the DNS for your sub-domain or domain is pointing to the machine that you\u2019re installing Mathesar on . Customizing this Guide \u00b6 Type your domain name into the box below. Do not include a trailing slash. Then press Enter to customize this guide with your domain name. Installation Steps \u00b6 Set up the database \u00b6 Open a psql shell. sudo -u postgres psql # Modify based on your Postgres installation. Let\u2019s create a Postgres user for Mathesar CREATE USER mathesar WITH ENCRYPTED PASSWORD '1234' ; Customize your password Be sure to change the password 1234 in the command above to something more secure and private. Record your custom password somewhere safe. You will need to reference it later. Next, we have to create a database for storing Mathesar metadata. Your PostgreSQL user will either need to be a SUPERUSER or OWNER of the database. In this guide, we will be setting the user to be OWNER of the database as it is slightly restrictive compared to a SUPERUSER . CREATE DATABASE mathesar_django OWNER mathesar ; Press Ctrl + D to exit the psql shell. Set up your installation directory \u00b6 Choose a directory to store the Mathesar application files. Examples /home/my_user_name/mathesar /etc/mathesar Type your installation directory into the box below. Do not include a trailing slash. Then press Enter to customize this guide with your installation directory. Create your installation directory. mkdir -p xMATHESAR_INSTALLATION_DIRx When installing outside your home folder If you choose a directory outside your home folder, then you\u2019ll need to create it with sudo and choose an appropriate owner for the directory (i.e. root or a custom user of your choosing). The remainder of this guide requires you to run commands with full permissions inside your installation directory . You can do this, for example via: chown my_user_name: xMATHESAR_INSTALLATION_DIRx Or sudo su Navigate into your installation directory. cd xMATHESAR_INSTALLATION_DIRx The remaining commands in this guide should be run from within your installation directory. Set up the environment \u00b6 Clone the git repo into the installation directory. git clone https://github.com/mathesar-foundation/mathesar.git . Check out the tag of the release or build you\u2019d like to install, 0.2.0-testing.1 . git checkout 0.2.0-testing.1 Important If you don\u2019t run the above command you\u2019ll end up installing the latest development version of Mathesar. We need to create a python virtual environment for the Mathesar application. <path-to-python-binary> -m venv ./mathesar-venv # /usr/bin/python3.9 -m venv ./mathesar-venv Next we will activate our virtual environment: source ./mathesar-venv/bin/activate Important You need to activate the environment each time you restart the shell as they don\u2019t persist across sessions. Install the Mathesar application \u00b6 Install Python dependencies pip install -r requirements-prod.txt Set the environment variables Create .env file touch .env Edit your .env file, adding environment variables to configure Mathesar. Example Your .env file should look something like this SECRET_KEY='REPLACE_THIS_WITH_YOUR_RANDOMLY_GENERATED_VALUE' DOMAIN_NAME='xDOMAIN_NAMEx' ALLOWED_HOSTS='xDOMAIN_NAMEx' POSTGRES_DB=mathesar_django POSTGRES_USER=mathesar POSTGRES_PASSWORD=REPLACE_THIS_WITH_APPROPRIATE_PASSWORD_FOR_THE_CHOSEN_POSTGRES_USER POSTGRES_HOST=localhost POSTGRES_PORT=5432 Tip To generate a SECRET_KEY you can use this browser-based generator or run this command on MacOS or Linux: echo $(cat /dev/urandom | LC_CTYPE=C tr -dc 'a-zA-Z0-9' | head -c 50) Tip If you want to host Mathesar on multiple domains/subdomains you can do so by adding multiple comma separated domain names to the following env variables without a whitespace: DOMAIN_NAME='xDOMAIN_NAMEx,xDOMAIN_NAMEx.example.org' ALLOWED_HOSTS='xDOMAIN_NAMEx,xDOMAIN_NAMEx.example.org' Add the environment variables to the shell You need to export the environment variables listed in the .env file to your shell. The easiest way would be to run the below command. export $(cat .env) Important You need to export the environment variables each time you restart the shell as they don\u2019t persist across sessions. Download release static files and extract into the correct directory wget https://github.com/mathesar-foundation/mathesar/releases/download/0.2.0-testing.1/static_files.zip unzip static_files.zip && mv static_files mathesar/static/mathesar && rm static_files.zip Compile Mathesar translation files python manage.py compilemessages Install Mathesar functions on the database: python -m mathesar.install --skip-confirm | tee /tmp/install.py.log Create a media directory for storing user-uploaded media mkdir .media Set up Gunicorn \u00b6 Elevated permissions needed Most of the commands below need to be run as a root user, or using sudo . If you try to run one of these commands, and see an error about \u201cpermission denied\u201d, use one of those methods. Create a user for running Gunicorn groupadd gunicorn && \\ useradd gunicorn -g gunicorn Make the gunicorn user the owner of the .media directory chown -R gunicorn:gunicorn .media/ Create the Gunicorn SystemD service file. touch /lib/systemd/system/gunicorn.service and copy the following code into it. [Unit] Description=gunicorn daemon After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=gunicorn Group=gunicorn RuntimeDirectory=gunicorn WorkingDirectory=xMATHESAR_INSTALLATION_DIRx ExecStart=/bin/bash -c 'xMATHESAR_INSTALLATION_DIRx/mathesar-venv/bin/gunicorn config.wsgi:application' EnvironmentFile=xMATHESAR_INSTALLATION_DIRx/.env [Install] WantedBy=multi-user.target Reload systemctl and start the Gunicorn socket systemctl daemon-reload systemctl start gunicorn.service systemctl enable gunicorn.service Check the logs to verify if Gunicorn is running without any errors journalctl --unit=gunicorn.service Set up the Caddy reverse proxy \u00b6 We will use the Caddy Reverse proxy to serve the static files and set up SSL certificates. Create the CaddyFile touch /etc/caddy/Caddyfile Add the configuration details to the CaddyFile $DOMAIN_NAME { log { output stdout } respond /caddy-health-check 200 encode zstd gzip handle_path /media/* { @downloads { query dl=* } header @downloads Content-disposition \"attachment; filename={query.dl}\" file_server { precompressed br zstd gzip root {$MEDIA_ROOT:xMATHESAR_INSTALLATION_DIRx/.media/} } } handle_path /static/* { file_server { precompressed br zstd gzip root {$STATIC_ROOT:xMATHESAR_INSTALLATION_DIRx/static/} } } reverse_proxy localhost:8000 } Create a user for running Caddy groupadd caddy && \\ useradd caddy -g caddy Create the Caddy systemd service file. touch /lib/systemd/system/caddy.service and copy the following code into it. [Unit] Description=Caddy Documentation=https://caddyserver.com/docs/ After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=caddy Group=caddy ExecStart=/usr/bin/caddy run --config /etc/caddy/Caddyfile ExecReload=/usr/bin/caddy reload --config /etc/caddy/Caddyfile --force TimeoutStopSec=5s LimitNOFILE=1048576 LimitNPROC=512 PrivateTmp=true ProtectSystem=full AmbientCapabilities=CAP_NET_BIND_SERVICE [Install] WantedBy=multi-user.target Reload the systemctl and start the Caddy socket systemctl daemon-reload && \\ systemctl start caddy.service && \\ systemctl enable caddy.service Check the logs to verify if Caddy is running without any errors journalctl --unit=caddy.service Set up your user account \u00b6 Mathesar is now installed! You can use it by visiting the URL xDOMAIN_NAMEx . You\u2019ll be prompted to set up an admin user account the first time you open Mathesar. Follow the instructions on screen.","title":"Install from scratch"},{"location":"installation/build-from-source/#install-mathesar-from-source-on-linux","text":"Not a stable release This is a testing build released with the goal of gathering feedback from our community. It has many known issues and is not recommended for production use. For experienced Linux sysadmins To follow this guide you need be experienced with Linux server administration, including the command line interface and some common utilities. If you run into any trouble, we encourage you to open an issue or submit a PR proposing changes to this file .","title":"Install Mathesar from source on Linux"},{"location":"installation/build-from-source/#requirements","text":"","title":"Requirements"},{"location":"installation/build-from-source/#system","text":"We recommend having at least 60 GB disk space and 4 GB of RAM.","title":"System"},{"location":"installation/build-from-source/#operating-system","text":"We\u2019ve tested this on Debian 12 , but we expect that it can be adapted for other Linux distributions as well.","title":"Operating System"},{"location":"installation/build-from-source/#access","text":"You should have root access to the machine you\u2019re installing Mathesar on.","title":"Access"},{"location":"installation/build-from-source/#software","text":"You\u2019ll need to install the following system packages before you install Mathesar: Python 3.9, 3.10, or 3.11 (along with appropriate venv module) Python version Python older than 3.9 will not run Mathesar. Python 3.12 will run Mathesar, but you\u2019ll have to take extra steps to get some dependencies to build. Installing a package for your OS that provides the libpq-fe.h header file should be enough in most cases. On Debian 12, this header is provided by the libpq-dev package. PostgreSQL 13 or newer (Verify by logging in, and running the query: SELECT version(); ) Caddy (Verify with caddy version ) git (Verify with git --version ) GNU gettext (Verify with gettext --version ) unzip A utility tool to de-archive .zip files (Verify with unzip -v )","title":"Software"},{"location":"installation/build-from-source/#domain-optional","text":"If you want Mathesar to be accessible over the internet, you\u2019ll probably want to set up a domain or sub-domain to use. If you don\u2019t need a domain, you can skip this section. Before you start installation, ensure that the DNS for your sub-domain or domain is pointing to the machine that you\u2019re installing Mathesar on .","title":"Domain (optional)"},{"location":"installation/build-from-source/#customizing-this-guide","text":"Type your domain name into the box below. Do not include a trailing slash. Then press Enter to customize this guide with your domain name.","title":"Customizing this Guide"},{"location":"installation/build-from-source/#installation-steps","text":"","title":"Installation Steps"},{"location":"installation/build-from-source/#set-up-the-database","text":"Open a psql shell. sudo -u postgres psql # Modify based on your Postgres installation. Let\u2019s create a Postgres user for Mathesar CREATE USER mathesar WITH ENCRYPTED PASSWORD '1234' ; Customize your password Be sure to change the password 1234 in the command above to something more secure and private. Record your custom password somewhere safe. You will need to reference it later. Next, we have to create a database for storing Mathesar metadata. Your PostgreSQL user will either need to be a SUPERUSER or OWNER of the database. In this guide, we will be setting the user to be OWNER of the database as it is slightly restrictive compared to a SUPERUSER . CREATE DATABASE mathesar_django OWNER mathesar ; Press Ctrl + D to exit the psql shell.","title":"Set up the database"},{"location":"installation/build-from-source/#set-up-your-installation-directory","text":"Choose a directory to store the Mathesar application files. Examples /home/my_user_name/mathesar /etc/mathesar Type your installation directory into the box below. Do not include a trailing slash. Then press Enter to customize this guide with your installation directory. Create your installation directory. mkdir -p xMATHESAR_INSTALLATION_DIRx When installing outside your home folder If you choose a directory outside your home folder, then you\u2019ll need to create it with sudo and choose an appropriate owner for the directory (i.e. root or a custom user of your choosing). The remainder of this guide requires you to run commands with full permissions inside your installation directory . You can do this, for example via: chown my_user_name: xMATHESAR_INSTALLATION_DIRx Or sudo su Navigate into your installation directory. cd xMATHESAR_INSTALLATION_DIRx The remaining commands in this guide should be run from within your installation directory.","title":"Set up your installation directory"},{"location":"installation/build-from-source/#set-up-the-environment","text":"Clone the git repo into the installation directory. git clone https://github.com/mathesar-foundation/mathesar.git . Check out the tag of the release or build you\u2019d like to install, 0.2.0-testing.1 . git checkout 0.2.0-testing.1 Important If you don\u2019t run the above command you\u2019ll end up installing the latest development version of Mathesar. We need to create a python virtual environment for the Mathesar application. <path-to-python-binary> -m venv ./mathesar-venv # /usr/bin/python3.9 -m venv ./mathesar-venv Next we will activate our virtual environment: source ./mathesar-venv/bin/activate Important You need to activate the environment each time you restart the shell as they don\u2019t persist across sessions.","title":"Set up the environment"},{"location":"installation/build-from-source/#install-the-mathesar-application","text":"Install Python dependencies pip install -r requirements-prod.txt Set the environment variables Create .env file touch .env Edit your .env file, adding environment variables to configure Mathesar. Example Your .env file should look something like this SECRET_KEY='REPLACE_THIS_WITH_YOUR_RANDOMLY_GENERATED_VALUE' DOMAIN_NAME='xDOMAIN_NAMEx' ALLOWED_HOSTS='xDOMAIN_NAMEx' POSTGRES_DB=mathesar_django POSTGRES_USER=mathesar POSTGRES_PASSWORD=REPLACE_THIS_WITH_APPROPRIATE_PASSWORD_FOR_THE_CHOSEN_POSTGRES_USER POSTGRES_HOST=localhost POSTGRES_PORT=5432 Tip To generate a SECRET_KEY you can use this browser-based generator or run this command on MacOS or Linux: echo $(cat /dev/urandom | LC_CTYPE=C tr -dc 'a-zA-Z0-9' | head -c 50) Tip If you want to host Mathesar on multiple domains/subdomains you can do so by adding multiple comma separated domain names to the following env variables without a whitespace: DOMAIN_NAME='xDOMAIN_NAMEx,xDOMAIN_NAMEx.example.org' ALLOWED_HOSTS='xDOMAIN_NAMEx,xDOMAIN_NAMEx.example.org' Add the environment variables to the shell You need to export the environment variables listed in the .env file to your shell. The easiest way would be to run the below command. export $(cat .env) Important You need to export the environment variables each time you restart the shell as they don\u2019t persist across sessions. Download release static files and extract into the correct directory wget https://github.com/mathesar-foundation/mathesar/releases/download/0.2.0-testing.1/static_files.zip unzip static_files.zip && mv static_files mathesar/static/mathesar && rm static_files.zip Compile Mathesar translation files python manage.py compilemessages Install Mathesar functions on the database: python -m mathesar.install --skip-confirm | tee /tmp/install.py.log Create a media directory for storing user-uploaded media mkdir .media","title":"Install the Mathesar application"},{"location":"installation/build-from-source/#set-up-gunicorn","text":"Elevated permissions needed Most of the commands below need to be run as a root user, or using sudo . If you try to run one of these commands, and see an error about \u201cpermission denied\u201d, use one of those methods. Create a user for running Gunicorn groupadd gunicorn && \\ useradd gunicorn -g gunicorn Make the gunicorn user the owner of the .media directory chown -R gunicorn:gunicorn .media/ Create the Gunicorn SystemD service file. touch /lib/systemd/system/gunicorn.service and copy the following code into it. [Unit] Description=gunicorn daemon After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=gunicorn Group=gunicorn RuntimeDirectory=gunicorn WorkingDirectory=xMATHESAR_INSTALLATION_DIRx ExecStart=/bin/bash -c 'xMATHESAR_INSTALLATION_DIRx/mathesar-venv/bin/gunicorn config.wsgi:application' EnvironmentFile=xMATHESAR_INSTALLATION_DIRx/.env [Install] WantedBy=multi-user.target Reload systemctl and start the Gunicorn socket systemctl daemon-reload systemctl start gunicorn.service systemctl enable gunicorn.service Check the logs to verify if Gunicorn is running without any errors journalctl --unit=gunicorn.service","title":"Set up Gunicorn"},{"location":"installation/build-from-source/#set-up-the-caddy-reverse-proxy","text":"We will use the Caddy Reverse proxy to serve the static files and set up SSL certificates. Create the CaddyFile touch /etc/caddy/Caddyfile Add the configuration details to the CaddyFile $DOMAIN_NAME { log { output stdout } respond /caddy-health-check 200 encode zstd gzip handle_path /media/* { @downloads { query dl=* } header @downloads Content-disposition \"attachment; filename={query.dl}\" file_server { precompressed br zstd gzip root {$MEDIA_ROOT:xMATHESAR_INSTALLATION_DIRx/.media/} } } handle_path /static/* { file_server { precompressed br zstd gzip root {$STATIC_ROOT:xMATHESAR_INSTALLATION_DIRx/static/} } } reverse_proxy localhost:8000 } Create a user for running Caddy groupadd caddy && \\ useradd caddy -g caddy Create the Caddy systemd service file. touch /lib/systemd/system/caddy.service and copy the following code into it. [Unit] Description=Caddy Documentation=https://caddyserver.com/docs/ After=network.target network-online.target Requires=network-online.target [Service] Type=notify User=caddy Group=caddy ExecStart=/usr/bin/caddy run --config /etc/caddy/Caddyfile ExecReload=/usr/bin/caddy reload --config /etc/caddy/Caddyfile --force TimeoutStopSec=5s LimitNOFILE=1048576 LimitNPROC=512 PrivateTmp=true ProtectSystem=full AmbientCapabilities=CAP_NET_BIND_SERVICE [Install] WantedBy=multi-user.target Reload the systemctl and start the Caddy socket systemctl daemon-reload && \\ systemctl start caddy.service && \\ systemctl enable caddy.service Check the logs to verify if Caddy is running without any errors journalctl --unit=caddy.service","title":"Set up the Caddy reverse proxy"},{"location":"installation/build-from-source/#set-up-your-user-account","text":"Mathesar is now installed! You can use it by visiting the URL xDOMAIN_NAMEx . You\u2019ll be prompted to set up an admin user account the first time you open Mathesar. Follow the instructions on screen.","title":"Set up your user account"},{"location":"installation/docker-compose/","text":"Install Mathesar via Docker Compose \u00b6 Not a stable release This is a testing build released with the goal of gathering feedback from our community. It has many known issues and is not recommended for production use. Prerequisites \u00b6 Operating System \u00b6 You can install Mathesar using this method on Linux, MacOS, and Windows. Software \u00b6 You\u2019ll need to install the following software before you install Mathesar: Docker v23+ Docker Compose v2.10+ If you\u2019re installing on Windows: Ensure you have WSL installed Turn on Docker Desktop WSL 2, see Docker docs for more information Step-by-Step Guide \u00b6 Note Depending on your Docker setup, you may need to run docker commands with sudo . Video walkthrough (Click to expand) Download our docker-compose.yml file. wget https://github.com/mathesar-foundation/mathesar/raw/0.2.0-testing.1/docker-compose.yml Open the downloaded docker-compose file using your text editor. Set the required environment variables in the x-config section of the docker compose file. Config x-config : &config # (REQUIRED) Replace '?' with '-' followed by a 50 character random string. # You can generate one at https://djecrety.ir/ or by running: # echo $(cat /dev/urandom | LC_CTYPE=C tr -dc 'a-zA-Z0-9' | head -c 50) SECRET_KEY : ${SECRET_KEY:?} # (Optional) Replace 'http://localhost' with custom domain(s) e.g. # 'yourdomain.com, 127.0.0.1' to manage the host(s) at which you want to # access Mathesar over http or https DOMAIN_NAME : ${DOMAIN_NAME:-http://localhost} # Edit the POSTGRES_* variables if you are not using the db service provided # below, or if you want to use a custom database user. # (Optional) Replace 'mathesar_django' with any custom name for the internal # database managed by mathesar web-service POSTGRES_DB : ${POSTGRES_DB:-mathesar_django} # (Optional) Replace 'mathesar' with any custom username for the # aforementioned database POSTGRES_USER : ${POSTGRES_USER:-mathesar} # (Optional) Replace 'mathesar' with any custom password for the # aforementioned database POSTGRES_PASSWORD : ${POSTGRES_PASSWORD:-mathesar} # (Optional) Replace 'mathesar_db' with the name of the host running postgres POSTGRES_HOST : ${POSTGRES_HOST:-mathesar_db} # (Optional) Replace '5432' with the port on which postgres is running POSTGRES_PORT : ${POSTGRES_PORT:-5432} Run the docker compose file using: docker compose -f docker-compose.yml up Set up your user account Mathesar is now installed! You can use it by visiting localhost or the domain you\u2019ve set up. You\u2019ll be prompted to set up an admin user account the first time you open Mathesar. Just follow the instructions on screen. Starting and stopping Mathesar \u00b6 The Mathesar server needs to be running for you to use Mathesar. If you restart your machine, you\u2019ll need to start the server again. Start Mathesar: docker compose -f docker-compose.yml up -d Info Exclude the -d flag if you\u2019d like to see the container\u2019s logs. Stop Mathesar: docker compose -f docker-compose.yml down This stops all Mathesar Docker containers and releases their ports. Optional configurations \u00b6 Hosting Mathesar over a custom domain with https \u00b6 If you want Mathesar to be accessible over the internet, you\u2019ll probably want to set up a domain or sub-domain to use. If you don\u2019t need a domain, you can skip this section. Ensure that the DNS for your domain or sub-domain is pointing to the public IP address of the machine that you\u2019re installing Mathesar on . Add your domain(s) or sub-domain(s) to the DOMAIN_NAME environment variable, in the CONFIG section of the docker-compose file. Example DOMAIN_NAME : ${DOMAIN_NAME:-yourdomain.org, yoursubdomain.example.org} Restart the docker containers for the configuration to take effect. Using an external PostgreSQL server for Mathesar\u2019s internal database \u00b6 If you\u2019d like to use an external PostgreSQL server for Mathesar\u2019s internal database, you\u2019ll need to do the following: On the existing database server, create a new database for Mathesar to store its metadata. psql -c 'create database mathesar_django;' Configure the internal database environment variables to point to the database you just created. Ensure that you change the default values for the user, password, and host.","title":"Install using Docker Compose"},{"location":"installation/docker-compose/#install-mathesar-via-docker-compose","text":"Not a stable release This is a testing build released with the goal of gathering feedback from our community. It has many known issues and is not recommended for production use.","title":"Install Mathesar via Docker Compose"},{"location":"installation/docker-compose/#prerequisites","text":"","title":"Prerequisites"},{"location":"installation/docker-compose/#operating-system","text":"You can install Mathesar using this method on Linux, MacOS, and Windows.","title":"Operating System"},{"location":"installation/docker-compose/#software","text":"You\u2019ll need to install the following software before you install Mathesar: Docker v23+ Docker Compose v2.10+ If you\u2019re installing on Windows: Ensure you have WSL installed Turn on Docker Desktop WSL 2, see Docker docs for more information","title":"Software"},{"location":"installation/docker-compose/#steps","text":"Note Depending on your Docker setup, you may need to run docker commands with sudo . Video walkthrough (Click to expand) Download our docker-compose.yml file. wget https://github.com/mathesar-foundation/mathesar/raw/0.2.0-testing.1/docker-compose.yml Open the downloaded docker-compose file using your text editor. Set the required environment variables in the x-config section of the docker compose file. Config x-config : &config # (REQUIRED) Replace '?' with '-' followed by a 50 character random string. # You can generate one at https://djecrety.ir/ or by running: # echo $(cat /dev/urandom | LC_CTYPE=C tr -dc 'a-zA-Z0-9' | head -c 50) SECRET_KEY : ${SECRET_KEY:?} # (Optional) Replace 'http://localhost' with custom domain(s) e.g. # 'yourdomain.com, 127.0.0.1' to manage the host(s) at which you want to # access Mathesar over http or https DOMAIN_NAME : ${DOMAIN_NAME:-http://localhost} # Edit the POSTGRES_* variables if you are not using the db service provided # below, or if you want to use a custom database user. # (Optional) Replace 'mathesar_django' with any custom name for the internal # database managed by mathesar web-service POSTGRES_DB : ${POSTGRES_DB:-mathesar_django} # (Optional) Replace 'mathesar' with any custom username for the # aforementioned database POSTGRES_USER : ${POSTGRES_USER:-mathesar} # (Optional) Replace 'mathesar' with any custom password for the # aforementioned database POSTGRES_PASSWORD : ${POSTGRES_PASSWORD:-mathesar} # (Optional) Replace 'mathesar_db' with the name of the host running postgres POSTGRES_HOST : ${POSTGRES_HOST:-mathesar_db} # (Optional) Replace '5432' with the port on which postgres is running POSTGRES_PORT : ${POSTGRES_PORT:-5432} Run the docker compose file using: docker compose -f docker-compose.yml up Set up your user account Mathesar is now installed! You can use it by visiting localhost or the domain you\u2019ve set up. You\u2019ll be prompted to set up an admin user account the first time you open Mathesar. Just follow the instructions on screen.","title":"Step-by-Step Guide"},{"location":"installation/docker-compose/#start-stop","text":"The Mathesar server needs to be running for you to use Mathesar. If you restart your machine, you\u2019ll need to start the server again. Start Mathesar: docker compose -f docker-compose.yml up -d Info Exclude the -d flag if you\u2019d like to see the container\u2019s logs. Stop Mathesar: docker compose -f docker-compose.yml down This stops all Mathesar Docker containers and releases their ports.","title":"Starting and stopping Mathesar"},{"location":"installation/docker-compose/#optional-configurations","text":"","title":"Optional configurations"},{"location":"installation/docker-compose/#hosting-mathesar-over-a-custom-domain-with-https","text":"If you want Mathesar to be accessible over the internet, you\u2019ll probably want to set up a domain or sub-domain to use. If you don\u2019t need a domain, you can skip this section. Ensure that the DNS for your domain or sub-domain is pointing to the public IP address of the machine that you\u2019re installing Mathesar on . Add your domain(s) or sub-domain(s) to the DOMAIN_NAME environment variable, in the CONFIG section of the docker-compose file. Example DOMAIN_NAME : ${DOMAIN_NAME:-yourdomain.org, yoursubdomain.example.org} Restart the docker containers for the configuration to take effect.","title":"Hosting Mathesar over a custom domain with https"},{"location":"installation/docker-compose/#using-an-external-postgresql-server-for-mathesars-internal-database","text":"If you\u2019d like to use an external PostgreSQL server for Mathesar\u2019s internal database, you\u2019ll need to do the following: On the existing database server, create a new database for Mathesar to store its metadata. psql -c 'create database mathesar_django;' Configure the internal database environment variables to point to the database you just created. Ensure that you change the default values for the user, password, and host.","title":"Using an external PostgreSQL server for Mathesar's internal database"},{"location":"releases/","text":"Release notes \u00b6 This is developer documentation to help with release notes. It is not published in our docs guide. Requirements \u00b6 Install DuckDB . On Macs, the easiest way to do this is via Homebrew : brew install duckdb . Install the GitHub CLI . On Macs, the easiest way to do this is via Homebrew : brew install gh . How to generate release notes \u00b6 Run the find_missing_prs.sh script, passing the release version number as the only argument. ./find_missing_prs.sh 1.2.3 You can run this any time during the development cycle. If there is not yet a release branch, the script will compare develop to the previous release. If you haven\u2019t yet created a release notes file for this release, it will create one for you. The script will find PRs which have been merged but not yet included in the release notes file. Open the release notes file and find a new section at the end titled (TO CATEGORIZE) . Incorporate PRs listed within this section into the release notes as you see fit. Rewrite the title text that appears directly in the markdown. Leave the titles as-written within the quotes (these will appear within hover text). Save the release notes and commit them. Edit mkdocs.yml , adding the newly-generated release notes file to the nav menu. Re-run the script as needed.","title":"Release notes"},{"location":"releases/#release-notes","text":"This is developer documentation to help with release notes. It is not published in our docs guide.","title":"Release notes"},{"location":"releases/#requirements","text":"Install DuckDB . On Macs, the easiest way to do this is via Homebrew : brew install duckdb . Install the GitHub CLI . On Macs, the easiest way to do this is via Homebrew : brew install gh .","title":"Requirements"},{"location":"releases/#how-to-generate-release-notes","text":"Run the find_missing_prs.sh script, passing the release version number as the only argument. ./find_missing_prs.sh 1.2.3 You can run this any time during the development cycle. If there is not yet a release branch, the script will compare develop to the previous release. If you haven\u2019t yet created a release notes file for this release, it will create one for you. The script will find PRs which have been merged but not yet included in the release notes file. Open the release notes file and find a new section at the end titled (TO CATEGORIZE) . Incorporate PRs listed within this section into the release notes as you see fit. Rewrite the title text that appears directly in the markdown. Leave the titles as-written within the quotes (these will appear within hover text). Save the release notes and commit them. Edit mkdocs.yml , adding the newly-generated release notes file to the nav menu. Re-run the script as needed.","title":"How to generate release notes"},{"location":"releases/0.1.0/","text":"Mathesar 0.1.0 (alpha release) \u00b6 Mathesar\u2019s first alpha release! Features: Built on Postgres : Connect to an existing Postgres database or set one up from scratch. Set up your data models : Easily create and update Postgres schemas and tables. Data entry : Use our spreadsheet-like interface to view, create, update, and delete table records. Filter, sort, and group : Quickly slice your data in different ways. Query builder : Use our Data Explorer to build queries without knowing anything about SQL or joins. Schema migrations : Transfer columns between tables in two clicks. Uses Postgres features : Mathesar uses and manipulates Postgres schemas, primary keys, foreign keys, constraints and data types. e.g. \u201cLinks\u201d in the UI are foreign keys in the database. Custom data types : Custom data types for emails and URLs (more coming soon), validated at the database level. Basic access control : Users can have Viewer (read-only), Editor (can only edit data, but not data structure), or Manager (can edit both data and its structure) roles. Basic documentation : Users can install Mathesar using Docker Compose, and tricky product features are documented. Full Changelog","title":"0.1.0"},{"location":"releases/0.1.0/#mathesar-010-alpha-release","text":"Mathesar\u2019s first alpha release! Features: Built on Postgres : Connect to an existing Postgres database or set one up from scratch. Set up your data models : Easily create and update Postgres schemas and tables. Data entry : Use our spreadsheet-like interface to view, create, update, and delete table records. Filter, sort, and group : Quickly slice your data in different ways. Query builder : Use our Data Explorer to build queries without knowing anything about SQL or joins. Schema migrations : Transfer columns between tables in two clicks. Uses Postgres features : Mathesar uses and manipulates Postgres schemas, primary keys, foreign keys, constraints and data types. e.g. \u201cLinks\u201d in the UI are foreign keys in the database. Custom data types : Custom data types for emails and URLs (more coming soon), validated at the database level. Basic access control : Users can have Viewer (read-only), Editor (can only edit data, but not data structure), or Manager (can edit both data and its structure) roles. Basic documentation : Users can install Mathesar using Docker Compose, and tricky product features are documented. Full Changelog","title":"Mathesar 0.1.0 (alpha release)"},{"location":"releases/0.1.1/","text":"Mathesar 0.1.1 (alpha release) \u00b6 This is a minor release focused on addressing bugs and improving user experience. Bug fixes \u00b6 The UI now supports non-ASCII characters in column names and column settings. The record page works when the primary key is not an integer. Mathesar can now support primary keys that are UUIDs. Access level permissions presented on the UI are now consistent with the API access levels. Deleting newly created records immediately no longer results in getting stuck in a loading screen. Empty columns are now inferred as text instead of boolean during import. The UI now displays an appropriate failure message when failing to delete rows. Mathesar no longer crashes when attempting to order rows by non-orderable columns. Row selection gets cleared correctly when a placeholder cell is selected. Improvements \u00b6 The UI cancels edits when users press the Esc key in table cells. Group headers with record summaries now have links to allow users to navigate to the associated record. Dropdown positioning is improved across the app, so that they do not overflow the browser window. A bunch of smaller visual and UX improvements made by our Google Summer of Code (GSoC) applicants. Full Changelog","title":"0.1.1"},{"location":"releases/0.1.1/#mathesar-011-alpha-release","text":"This is a minor release focused on addressing bugs and improving user experience.","title":"Mathesar 0.1.1 (alpha release)"},{"location":"releases/0.1.1/#bug-fixes","text":"The UI now supports non-ASCII characters in column names and column settings. The record page works when the primary key is not an integer. Mathesar can now support primary keys that are UUIDs. Access level permissions presented on the UI are now consistent with the API access levels. Deleting newly created records immediately no longer results in getting stuck in a loading screen. Empty columns are now inferred as text instead of boolean during import. The UI now displays an appropriate failure message when failing to delete rows. Mathesar no longer crashes when attempting to order rows by non-orderable columns. Row selection gets cleared correctly when a placeholder cell is selected.","title":"Bug fixes"},{"location":"releases/0.1.1/#improvements","text":"The UI cancels edits when users press the Esc key in table cells. Group headers with record summaries now have links to allow users to navigate to the associated record. Dropdown positioning is improved across the app, so that they do not overflow the browser window. A bunch of smaller visual and UX improvements made by our Google Summer of Code (GSoC) applicants. Full Changelog","title":"Improvements"},{"location":"releases/0.1.2/","text":"Mathesar 0.1.2 (alpha release) \u00b6 This release focuses on documenting additional options for installing Mathesar, some improvements to the user experience, and some bug fixes. We\u2019ve also added support for switching between multiple databases in the UI. Improvements to the UI \u00b6 Mathesar now supports switching between multiple databases using the UI. ( #2847 ) You can now copy data from the Mathesar UI to paste into other applications. ( #2773 ) The first non-primary key column is now highlighted when a new record is created. ( #2515 ) Form inputs are disabled when the form is being submitted. ( #2762 ) Action pane sidebars are now resizable. ( #2808 ) Table deletion now requires you to enter the table\u2019s name (to prevent accidental deletion). ( #2858 ) Long table names are now truncated and the full name is shown on hover. ( #2825 ) We\u2019ve disabled setting columns to JSON List and Map types using the UI until we have a better editing experience for cells of those types. ( #2772 ) Filter conditions can now be added and removed via the column header menu ( #2782 ) Cell level context menus now also show menu items related to the row and column. ( #2803 ) Improvements to installation \u00b6 We have documented additional installation options for Mathesar. Visit the Mathesar docs site to explore these options. ( #2809 #2826 #2824 ) A reference for Mathesar configuration options has been added to our documentation. ( #2824 ) We have documented connecting to databases running on localhost outside of Docker. ( #2819 ) The Mathesar Docker image is now standalone and can be started using the docker run command. ( #2848 ) Superuser and database passwords are now validated when using the guided install script. ( #2625 ) Bug fixes \u00b6 Mathesar no longer crashes when importing tables with long column names. ( #2725 ) Static default values can no longer be assigned to a dynamic default column. ( #2780 ) Column names no longer overlap when the browser window is resized. ( #2856 ) Databases removed from the configuration environment file won\u2019t show up in the UI anymore. ( #2891 ) Fixed inconsistencies with the foreign key column icon. ( #2768 ) API changes \u00b6 The URL for the database page has been moved from /<db_name>/ to /db/<db_name>/ to avoid conflicts with other Mathesar URLs. ( #2791 ) Maintenance \u00b6 A \u201csponsors\u201d section has been added to the README. ( #2710 ) Full Changelog","title":"0.1.2"},{"location":"releases/0.1.2/#mathesar-012-alpha-release","text":"This release focuses on documenting additional options for installing Mathesar, some improvements to the user experience, and some bug fixes. We\u2019ve also added support for switching between multiple databases in the UI.","title":"Mathesar 0.1.2 (alpha release)"},{"location":"releases/0.1.2/#improvements-to-the-ui","text":"Mathesar now supports switching between multiple databases using the UI. ( #2847 ) You can now copy data from the Mathesar UI to paste into other applications. ( #2773 ) The first non-primary key column is now highlighted when a new record is created. ( #2515 ) Form inputs are disabled when the form is being submitted. ( #2762 ) Action pane sidebars are now resizable. ( #2808 ) Table deletion now requires you to enter the table\u2019s name (to prevent accidental deletion). ( #2858 ) Long table names are now truncated and the full name is shown on hover. ( #2825 ) We\u2019ve disabled setting columns to JSON List and Map types using the UI until we have a better editing experience for cells of those types. ( #2772 ) Filter conditions can now be added and removed via the column header menu ( #2782 ) Cell level context menus now also show menu items related to the row and column. ( #2803 )","title":"Improvements to the UI"},{"location":"releases/0.1.2/#improvements-to-installation","text":"We have documented additional installation options for Mathesar. Visit the Mathesar docs site to explore these options. ( #2809 #2826 #2824 ) A reference for Mathesar configuration options has been added to our documentation. ( #2824 ) We have documented connecting to databases running on localhost outside of Docker. ( #2819 ) The Mathesar Docker image is now standalone and can be started using the docker run command. ( #2848 ) Superuser and database passwords are now validated when using the guided install script. ( #2625 )","title":"Improvements to installation"},{"location":"releases/0.1.2/#bug-fixes","text":"Mathesar no longer crashes when importing tables with long column names. ( #2725 ) Static default values can no longer be assigned to a dynamic default column. ( #2780 ) Column names no longer overlap when the browser window is resized. ( #2856 ) Databases removed from the configuration environment file won\u2019t show up in the UI anymore. ( #2891 ) Fixed inconsistencies with the foreign key column icon. ( #2768 )","title":"Bug fixes"},{"location":"releases/0.1.2/#api-changes","text":"The URL for the database page has been moved from /<db_name>/ to /db/<db_name>/ to avoid conflicts with other Mathesar URLs. ( #2791 )","title":"API changes"},{"location":"releases/0.1.2/#maintenance","text":"A \u201csponsors\u201d section has been added to the README. ( #2710 ) Full Changelog","title":"Maintenance"},{"location":"releases/0.1.3/","text":"Mathesar 0.1.3 (alpha release) \u00b6 This release: makes improvements to the installation process, adds support for sharing tables and explorations publicly, begins a framework for internationalization and translation of UI elements, moves DDL (SQL) logic to DB-layer functions to increase performance and reduce complexity, Improves summarization behavior in the data explorer, Adds support for importing JSON and Excel files, fixes user-reported issues, improves developer experience, fixes numerous small backend issues, fixes numerous small frontend issues, improves the user documentation, and improves the API documentation. What\u2019s Changed \u00b6 Installation improvements \u00b6 Add superuser creation page ( #3088 ) Create superuser page\u2019s stylings ( #3131 ) Remove the documented steps for creating a superuser from the command line ( #3134 ) Sharing tables and explorations \u00b6 Shareable links backend - Models, APIs, bypass auth for table requests ( #3092 ) Shareable links frontend - shared table consumer view ( #3093 ) Shared queries - Auth handling for query requests, frontend consumer view, API tests ( #3113 ) UI for creating & managing shares for tables and explorations ( #3127 ) Shares - regenerate link, general fixes ( #3133 ) Internationalization \u00b6 Install typesafe-i18n & translates one component ( #3099 ) RichText component ( #3100 ) Django templates translatable ( #3101 ) RSQLA1: Move DDL Operations to SQL functions \u00b6 Sql test setup ( #2903 ) Add SQL for column adding ( #2923 ) Move constraint creation to SQL ( #2952 ) Cleaner consolidated logic for adding constraints ( #2976 ) Column creation and duplication DDL 2 ( #2978 ) SQL for links creation ( #2986 ) Table create ddl ( #3016 ) Add DDL functions for altering columns ( #3097 ) SQL tests for schema ddl ( #3098 ) Remove pglast , use SQL function instead ( #3107 ) Move table splitting logic to SQL ( #3119 ) Tests for links & constraints ddl ( #3120 ) Properly detect identity columns ( #3125 ) Wiring sql functions for links and tables ( #3130 ) Tests for alter table ( #3139 ) Add constraint copying to column extration logic ( #3168 ) Summarization improvements \u00b6 Fix SQL Syntax error while summarizing Money, URI, Email column ( #2911 ) Add Sum aggregation function ( #2893 ) Add max aggregation function ( #2912 ) Add min aggregation function ( #2914 ) Add mean aggregation function ( #2916 ) Add median aggregation function ( #2932 ) Add Mode aggregation function ( #2940 ) Add Percentage True aggregation function ( #2945 ) Add Peak Time aggregation function. ( #2981 ) Add Peak Day of Week aggregation function. ( #3004 ) Add Peak Month aggregation function. ( #3006 ) Fix NaN:NaN error while aggregating duration column ( #3136 ) JSON and Excel file improvements \u00b6 Updated datafile model to store file type ( #2890 ) Added methods to import a perfect JSON ( #2906 ) Removed code duplication while importing datafiles ( #2926 ) Added tests to check importing json feature ( #2933 ) Added pandas and JSON normalization code ( #2968 ) Added api tests for importing JSON feature ( #2977 ) Added documentation for importing data into tables ( #2992 ) Extended import via copy-paste for JSON and updated UI ( #3008 ) Updated documentation navigation to show importing data doc ( #3023 ) Added max_level param for JSON import feature in the backend ( #3039 ) Added functionality to import perfect Excel ( #3059 ) Fixes for user-reported issues \u00b6 Help text: \u201cits linked tables\u201d (possessive adjective) ( #3086 ) DX improvements \u00b6 Remove .env from developer guide. ( #2925 ) Add SQL files to the pytest workflow ( #3082 ) New linting rule ( #3116 ) Repeat failed tests ( #3118 ) Add pldebugger to dev db ( #3126 ) Backend fixes and improvements \u00b6 Fix migrations ( #2899 ) Remove lazydict dependency ( #2993 ) Add API tests for multi-column primary key constraints ( #3025 ) Support unknown types (backend) ( #3040 ) Allow usage of local.py for untracked settings ( #3064 ) Fix the error when list aggregation on mathesar custom array ( #3106 ) Merge db list demo mode commits into release 0.1.3 ( #3171 ) Frontend fixes and improvements \u00b6 Schema updates in database page without reloading. Fixes #2736 ( #2745 ) Make columns re-orderable ( #2831 ) Fix caret out of view when using Input on Chrome ( #2836 ) Improve TSV serialization when copying cells ( #2867 ) Add max_split=1 to retrieve the column name ( #2956 ) Fix default value input stealing focus ( #2957 ) Auto-focus input when editing number/money cells ( #2975 ) Updated frontend to send a single bulk delete request instead of one request for each record ( #2985 ) Added margin between breadcrumb selector and bottom of the veiwport ( #3014 ) Date Input closes now on tab ( #3038 ) Scroll sheet all the way down when clicking the New Record button ( #3045 ) Use Truncate component in Record Selector table cells ( #3077 ) Copy formatted cell values to clipboard instead of raw values ( #3094 ) Fix regression: Move UserProfile to the App level context from Route level context ( #3175 ) Documentation \u00b6 Update README.md with troubleshooting instructions ( #2751 ) Update documentation styles for active and hover ( #2937 ) Added the command that generates the API documentation schema file to\u2026 ( #2970 ) Added the command to copy the .env file, to the DEVELOPER GUIDE ( #2972 ) Update demo\u2019s documentation ( #2996 ) Fix typo error in DEVELOPER_GUIDE.md ( #2999 ) Update build from source documentation ( #3029 ) Clean up import docs ( #3042 ) API documentation \u00b6 Integrated drf-spectacular library ( #2939 ) Improved the operationIds by implementing a post hook function ( #3021 ) Added OpenAPI spec for datafiles endpoint ( #3044 ) Added OpenAPI specification for databases endpoint ( #3047 ) Added OpenAPI specification for /schemas/ endpoint ( #3074 ) Full Changelog","title":"0.1.3"},{"location":"releases/0.1.3/#mathesar-013-alpha-release","text":"This release: makes improvements to the installation process, adds support for sharing tables and explorations publicly, begins a framework for internationalization and translation of UI elements, moves DDL (SQL) logic to DB-layer functions to increase performance and reduce complexity, Improves summarization behavior in the data explorer, Adds support for importing JSON and Excel files, fixes user-reported issues, improves developer experience, fixes numerous small backend issues, fixes numerous small frontend issues, improves the user documentation, and improves the API documentation.","title":"Mathesar 0.1.3 (alpha release)"},{"location":"releases/0.1.3/#whats-changed","text":"","title":"What's Changed"},{"location":"releases/0.1.3/#installation-improvements","text":"Add superuser creation page ( #3088 ) Create superuser page\u2019s stylings ( #3131 ) Remove the documented steps for creating a superuser from the command line ( #3134 )","title":"Installation improvements"},{"location":"releases/0.1.3/#sharing-tables-and-explorations","text":"Shareable links backend - Models, APIs, bypass auth for table requests ( #3092 ) Shareable links frontend - shared table consumer view ( #3093 ) Shared queries - Auth handling for query requests, frontend consumer view, API tests ( #3113 ) UI for creating & managing shares for tables and explorations ( #3127 ) Shares - regenerate link, general fixes ( #3133 )","title":"Sharing tables and explorations"},{"location":"releases/0.1.3/#internationalization","text":"Install typesafe-i18n & translates one component ( #3099 ) RichText component ( #3100 ) Django templates translatable ( #3101 )","title":"Internationalization"},{"location":"releases/0.1.3/#rsqla1-move-ddl-operations-to-sql-functions","text":"Sql test setup ( #2903 ) Add SQL for column adding ( #2923 ) Move constraint creation to SQL ( #2952 ) Cleaner consolidated logic for adding constraints ( #2976 ) Column creation and duplication DDL 2 ( #2978 ) SQL for links creation ( #2986 ) Table create ddl ( #3016 ) Add DDL functions for altering columns ( #3097 ) SQL tests for schema ddl ( #3098 ) Remove pglast , use SQL function instead ( #3107 ) Move table splitting logic to SQL ( #3119 ) Tests for links & constraints ddl ( #3120 ) Properly detect identity columns ( #3125 ) Wiring sql functions for links and tables ( #3130 ) Tests for alter table ( #3139 ) Add constraint copying to column extration logic ( #3168 )","title":"RSQLA1: Move DDL Operations to SQL functions"},{"location":"releases/0.1.3/#summarization-improvements","text":"Fix SQL Syntax error while summarizing Money, URI, Email column ( #2911 ) Add Sum aggregation function ( #2893 ) Add max aggregation function ( #2912 ) Add min aggregation function ( #2914 ) Add mean aggregation function ( #2916 ) Add median aggregation function ( #2932 ) Add Mode aggregation function ( #2940 ) Add Percentage True aggregation function ( #2945 ) Add Peak Time aggregation function. ( #2981 ) Add Peak Day of Week aggregation function. ( #3004 ) Add Peak Month aggregation function. ( #3006 ) Fix NaN:NaN error while aggregating duration column ( #3136 )","title":"Summarization improvements"},{"location":"releases/0.1.3/#json-and-excel-file-improvements","text":"Updated datafile model to store file type ( #2890 ) Added methods to import a perfect JSON ( #2906 ) Removed code duplication while importing datafiles ( #2926 ) Added tests to check importing json feature ( #2933 ) Added pandas and JSON normalization code ( #2968 ) Added api tests for importing JSON feature ( #2977 ) Added documentation for importing data into tables ( #2992 ) Extended import via copy-paste for JSON and updated UI ( #3008 ) Updated documentation navigation to show importing data doc ( #3023 ) Added max_level param for JSON import feature in the backend ( #3039 ) Added functionality to import perfect Excel ( #3059 )","title":"JSON and Excel file improvements"},{"location":"releases/0.1.3/#fixes-for-user-reported-issues","text":"Help text: \u201cits linked tables\u201d (possessive adjective) ( #3086 )","title":"Fixes for user-reported issues"},{"location":"releases/0.1.3/#dx-improvements","text":"Remove .env from developer guide. ( #2925 ) Add SQL files to the pytest workflow ( #3082 ) New linting rule ( #3116 ) Repeat failed tests ( #3118 ) Add pldebugger to dev db ( #3126 )","title":"DX improvements"},{"location":"releases/0.1.3/#backend-fixes-and-improvements","text":"Fix migrations ( #2899 ) Remove lazydict dependency ( #2993 ) Add API tests for multi-column primary key constraints ( #3025 ) Support unknown types (backend) ( #3040 ) Allow usage of local.py for untracked settings ( #3064 ) Fix the error when list aggregation on mathesar custom array ( #3106 ) Merge db list demo mode commits into release 0.1.3 ( #3171 )","title":"Backend fixes and improvements"},{"location":"releases/0.1.3/#frontend-fixes-and-improvements","text":"Schema updates in database page without reloading. Fixes #2736 ( #2745 ) Make columns re-orderable ( #2831 ) Fix caret out of view when using Input on Chrome ( #2836 ) Improve TSV serialization when copying cells ( #2867 ) Add max_split=1 to retrieve the column name ( #2956 ) Fix default value input stealing focus ( #2957 ) Auto-focus input when editing number/money cells ( #2975 ) Updated frontend to send a single bulk delete request instead of one request for each record ( #2985 ) Added margin between breadcrumb selector and bottom of the veiwport ( #3014 ) Date Input closes now on tab ( #3038 ) Scroll sheet all the way down when clicking the New Record button ( #3045 ) Use Truncate component in Record Selector table cells ( #3077 ) Copy formatted cell values to clipboard instead of raw values ( #3094 ) Fix regression: Move UserProfile to the App level context from Route level context ( #3175 )","title":"Frontend fixes and improvements"},{"location":"releases/0.1.3/#documentation","text":"Update README.md with troubleshooting instructions ( #2751 ) Update documentation styles for active and hover ( #2937 ) Added the command that generates the API documentation schema file to\u2026 ( #2970 ) Added the command to copy the .env file, to the DEVELOPER GUIDE ( #2972 ) Update demo\u2019s documentation ( #2996 ) Fix typo error in DEVELOPER_GUIDE.md ( #2999 ) Update build from source documentation ( #3029 ) Clean up import docs ( #3042 )","title":"Documentation"},{"location":"releases/0.1.3/#api-documentation","text":"Integrated drf-spectacular library ( #2939 ) Improved the operationIds by implementing a post hook function ( #3021 ) Added OpenAPI spec for datafiles endpoint ( #3044 ) Added OpenAPI specification for databases endpoint ( #3047 ) Added OpenAPI specification for /schemas/ endpoint ( #3074 ) Full Changelog","title":"API documentation"},{"location":"releases/0.1.4/","text":"Mathesar 0.1.4 \u00b6 Summary \u00b6 Mathesar 0.1.4 focuses on improving the installation and setup experience. This page provides a comprehensive list of all changes in the release. Upgrading to 0.1.4 \u00b6 See our guide on upgrading Mathesar to 0.1.4 . New Features \u00b6 UI for configuring database connections \u00b6 Now you can add, edit, and delete connections to multiple databases from within Mathesar\u2019s UI. Previously this was only possible via editing text-based configuration. #3170 #3223 #3299 #3309 #3319 #3326 #3341 #3348 #3349 #3352 #3354 #3356 #3368 #3377 #3387 Sample data loader \u00b6 When adding a new database connection, you can choose to load sample data into that database. Sample data will be contained within specific schemas and may be useful to help new users play with Mathesar\u2019s features. #3368 PostgreSQL column COMMENTs \u00b6 PostgreSQL COMMENT values on columns are now exposed via a read/write \u201cdescription\u201d field within Mathesar. This feature was previously available for schemas and tables and is now available for columns too. #3186 #3219 Text-only imports \u00b6 When importing CSV data, Mathesar now gives you the option to use TEXT as the database type for all columns. This choice speeds up the import for larger data sets by skipping the process of guessing colum types. #3050 We are still considering additional ways to improve performance when importing \u2014 especially for data sets with lots of columns. Reduced database privilege installations \u00b6 Mathesar can now be installed as long as the database role used during the installation has at least CONNECT and CREATE privileges on the database targeted by the installation. If you want to create a new database for Mathesar\u2019s use, the installation will (naturally) require a role with the CREATEDB privilege. #3117 Unified Mathesar Docker image \u00b6 The published Mathesar Docker image now contains a PostgreSQL server. This is used to provide a database backend in cases where Mathesar is started via Docker without being configured to connect to any other database. #3121 #3212 Metadata storage within SQLite \u00b6 We\u2019ve added experimental SQLite support for the storage of Mathesar metadata. This will allow brave (or foolish) users to run Mathesar with this lighter-weight DB when installing from scratch on Linux. #3203 #3225 #2778 Improved PostgreSQL compatibility \u00b6 Mathesar now officially supports, and is tested against, Postgres versions 13, 14, and 15. It\u2019s also possible (but not yet recommended) to run Mathesar using Postgres 16. #3206 Easier modification of sorting precedence \u00b6 When you have multiple sorting conditions applied to a table, you can now rearrange them via drag and drop to adjust the precedence of the sorting conditions. #3316 Cell values displayed within sidebar \u00b6 The table sidebar features a new \u201cCell\u201d tab to show the content of cells, simplifying the process of viewing large text cells. Groundwork \u00b6 We made significant progress towards internationalizing Mathesar\u2019s user interface. We expect to our next release to offer users the ability to toggle between English and Japanese. Subsequent releases will continue to add additional languages. #3102 #3103 #3104 #3302 #3321 #3337 #3340 #3350 #3389 We began some work that will help us eventually distribute Mathesar via a Debian .deb package. Some additional work remains but we hope to introduce this installation method in a future version. #3189 #3225 We implemented the backend side of a new feature to import Excel and JSON files through Mathesar\u2019s import UI. More work still remains to implement the frontend side of this feature. #3083 #3195 #3132 We took some baby steps towards building a system to automatically generate human-readable documentation for all our API endpoints. Significant work still remains. #3271 #3146 Documentation \u00b6 We improved and updated our documentation for installing and updating Mathesar. ( #3227 ) Bug fixes \u00b6 Tables having CHECK constraints are now usable within Mathesar. ( #3243 ) Records can now be inserted into tables without primary keys. ( #3252 ) We fixed inconsistent state when selecting a different column while editing a column\u2019s name. ( #3219 ) URL cells now retain their focus after a contained hyperlink is clicked. ( #3012 ) Searching for a record via a partially-entered date string no longer gives an error. ( #3343 ) The Database Page now shows loading and error indicators. ( #3351 ) The Schema Page now displays more detailed information about errors encountered when loading tables and explorations. ( #3323 ) Exclusion constraint violations now produce more helpful error messages. ( #3200 ) Files with missing or duplicate id values can now be imported without error. ( #3155 ) The record selector can now be closed by clicking on the overlay outside its modal. ( #3220 ) Help text for foreign key column data types is now more accurate. ( #3260 ) Users of Mathesar\u2019s public demo site will no longer see database connections listed for other demo users. ( #3129 ) More UI elements have visually distinctive focus states. ( #3313 ) Date formatting is applied to arrays of date values. ( #3325 ) On the record page, values within foreign key columns can now be set to NULL more intuitively. ( #3310 ) A visual layout overflow bug on the record page is fixed. ( #3303 ) Foreign keys referencing non-primary-key columns now display properly. ( #3239 ) Maintenance \u00b6 We made our CI pipeline more robust. ( #3254 ) We made some updates to our workflows and developer documentation to support improvements to our issue labeling scheme. ( #3338 #3298 #3280 #3336 ) We made some routine upgrades to dependencies and small adjustments to development tooling. ( #3214 #3353 #3334 #3201 #3295 #3156 #3234 #3229 #3317 ) We addressed regressions from work during this release. ( #3197 ) We improved error handling by preventing storing non-positive IDs for certain objects. ( #3177 ) We clarified the API behavior by specifying JSON-only requests ( #3090 ) We improved testing against DB objects with long names ( #3140 ) We updated our org name to reflect a change from \u201cCenter of Complex Interventions\u201d to \u201cMathesar Foundation\u201d. ( #3312 ) We made some improvements to our developer documentation. ( #3300 #3210 #3279 ) We improved our process for generating release notes. ( #3427 ) We resolved some merge conflicts after finalizing our previous release. ( #3190 )","title":"0.1.4"},{"location":"releases/0.1.4/#mathesar-014","text":"","title":"Mathesar 0.1.4"},{"location":"releases/0.1.4/#summary","text":"Mathesar 0.1.4 focuses on improving the installation and setup experience. This page provides a comprehensive list of all changes in the release.","title":"Summary"},{"location":"releases/0.1.4/#upgrading-to-014","text":"See our guide on upgrading Mathesar to 0.1.4 .","title":"Upgrading to 0.1.4"},{"location":"releases/0.1.4/#new-features","text":"","title":"New Features"},{"location":"releases/0.1.4/#ui-for-configuring-database-connections","text":"Now you can add, edit, and delete connections to multiple databases from within Mathesar\u2019s UI. Previously this was only possible via editing text-based configuration. #3170 #3223 #3299 #3309 #3319 #3326 #3341 #3348 #3349 #3352 #3354 #3356 #3368 #3377 #3387","title":"UI for configuring database connections"},{"location":"releases/0.1.4/#sample-data-loader","text":"When adding a new database connection, you can choose to load sample data into that database. Sample data will be contained within specific schemas and may be useful to help new users play with Mathesar\u2019s features. #3368","title":"Sample data loader"},{"location":"releases/0.1.4/#postgresql-column-comments","text":"PostgreSQL COMMENT values on columns are now exposed via a read/write \u201cdescription\u201d field within Mathesar. This feature was previously available for schemas and tables and is now available for columns too. #3186 #3219","title":"PostgreSQL column COMMENTs"},{"location":"releases/0.1.4/#text-only-imports","text":"When importing CSV data, Mathesar now gives you the option to use TEXT as the database type for all columns. This choice speeds up the import for larger data sets by skipping the process of guessing colum types. #3050 We are still considering additional ways to improve performance when importing \u2014 especially for data sets with lots of columns.","title":"Text-only imports"},{"location":"releases/0.1.4/#reduced-database-privilege-installations","text":"Mathesar can now be installed as long as the database role used during the installation has at least CONNECT and CREATE privileges on the database targeted by the installation. If you want to create a new database for Mathesar\u2019s use, the installation will (naturally) require a role with the CREATEDB privilege. #3117","title":"Reduced database privilege installations"},{"location":"releases/0.1.4/#unified-mathesar-docker-image","text":"The published Mathesar Docker image now contains a PostgreSQL server. This is used to provide a database backend in cases where Mathesar is started via Docker without being configured to connect to any other database. #3121 #3212","title":"Unified Mathesar Docker image"},{"location":"releases/0.1.4/#metadata-storage-within-sqlite","text":"We\u2019ve added experimental SQLite support for the storage of Mathesar metadata. This will allow brave (or foolish) users to run Mathesar with this lighter-weight DB when installing from scratch on Linux. #3203 #3225 #2778","title":"Metadata storage within SQLite"},{"location":"releases/0.1.4/#improved-postgresql-compatibility","text":"Mathesar now officially supports, and is tested against, Postgres versions 13, 14, and 15. It\u2019s also possible (but not yet recommended) to run Mathesar using Postgres 16. #3206","title":"Improved PostgreSQL compatibility"},{"location":"releases/0.1.4/#easier-modification-of-sorting-precedence","text":"When you have multiple sorting conditions applied to a table, you can now rearrange them via drag and drop to adjust the precedence of the sorting conditions. #3316","title":"Easier modification of sorting precedence"},{"location":"releases/0.1.4/#cell-values-displayed-within-sidebar","text":"The table sidebar features a new \u201cCell\u201d tab to show the content of cells, simplifying the process of viewing large text cells.","title":"Cell values displayed within sidebar"},{"location":"releases/0.1.4/#groundwork","text":"We made significant progress towards internationalizing Mathesar\u2019s user interface. We expect to our next release to offer users the ability to toggle between English and Japanese. Subsequent releases will continue to add additional languages. #3102 #3103 #3104 #3302 #3321 #3337 #3340 #3350 #3389 We began some work that will help us eventually distribute Mathesar via a Debian .deb package. Some additional work remains but we hope to introduce this installation method in a future version. #3189 #3225 We implemented the backend side of a new feature to import Excel and JSON files through Mathesar\u2019s import UI. More work still remains to implement the frontend side of this feature. #3083 #3195 #3132 We took some baby steps towards building a system to automatically generate human-readable documentation for all our API endpoints. Significant work still remains. #3271 #3146","title":"Groundwork"},{"location":"releases/0.1.4/#documentation","text":"We improved and updated our documentation for installing and updating Mathesar. ( #3227 )","title":"Documentation"},{"location":"releases/0.1.4/#bug-fixes","text":"Tables having CHECK constraints are now usable within Mathesar. ( #3243 ) Records can now be inserted into tables without primary keys. ( #3252 ) We fixed inconsistent state when selecting a different column while editing a column\u2019s name. ( #3219 ) URL cells now retain their focus after a contained hyperlink is clicked. ( #3012 ) Searching for a record via a partially-entered date string no longer gives an error. ( #3343 ) The Database Page now shows loading and error indicators. ( #3351 ) The Schema Page now displays more detailed information about errors encountered when loading tables and explorations. ( #3323 ) Exclusion constraint violations now produce more helpful error messages. ( #3200 ) Files with missing or duplicate id values can now be imported without error. ( #3155 ) The record selector can now be closed by clicking on the overlay outside its modal. ( #3220 ) Help text for foreign key column data types is now more accurate. ( #3260 ) Users of Mathesar\u2019s public demo site will no longer see database connections listed for other demo users. ( #3129 ) More UI elements have visually distinctive focus states. ( #3313 ) Date formatting is applied to arrays of date values. ( #3325 ) On the record page, values within foreign key columns can now be set to NULL more intuitively. ( #3310 ) A visual layout overflow bug on the record page is fixed. ( #3303 ) Foreign keys referencing non-primary-key columns now display properly. ( #3239 )","title":"Bug fixes"},{"location":"releases/0.1.4/#maintenance","text":"We made our CI pipeline more robust. ( #3254 ) We made some updates to our workflows and developer documentation to support improvements to our issue labeling scheme. ( #3338 #3298 #3280 #3336 ) We made some routine upgrades to dependencies and small adjustments to development tooling. ( #3214 #3353 #3334 #3201 #3295 #3156 #3234 #3229 #3317 ) We addressed regressions from work during this release. ( #3197 ) We improved error handling by preventing storing non-positive IDs for certain objects. ( #3177 ) We clarified the API behavior by specifying JSON-only requests ( #3090 ) We improved testing against DB objects with long names ( #3140 ) We updated our org name to reflect a change from \u201cCenter of Complex Interventions\u201d to \u201cMathesar Foundation\u201d. ( #3312 ) We made some improvements to our developer documentation. ( #3300 #3210 #3279 ) We improved our process for generating release notes. ( #3427 ) We resolved some merge conflicts after finalizing our previous release. ( #3190 )","title":"Maintenance"},{"location":"releases/0.1.5/","text":"Mathesar 0.1.5 \u00b6 Summary \u00b6 Mathesar 0.1.5 is a small, bug fix release. This page provides a comprehensive list of all changes in the release. Upgrading to Mathesar 0.1.5 \u00b6 See our guide on upgrading Mathesar to 0.1.5 . Improvements \u00b6 Improve performance of loading sample data when adding a new connection #3448 Constrain the width of the connections page #3439 Bug fixes \u00b6 Fix \u201cPage not found\u201d error when viewing a shared exploration #3456 Fix bugs preventing Mathesar from running in demo mode #3459 Fix timeout when setting up a new database with sample data in installations with higher network latency #3448 Restore display of column type icons within shared tables #3456 Temporarily hide link to missing docs page #3451 Fix active cell displaying above row header cell #3382 Documentation \u00b6 Improve docs on using an external PostgreSQL server for Mathesar\u2019s internal database #3457 Add embedded video walkthrough within installation steps #3437 #3443 0.1.5 release notes #3449 Maintenance \u00b6 Improve our release notes helper script #3435 Post-release cleanup #3432","title":"0.1.5"},{"location":"releases/0.1.5/#mathesar-015","text":"","title":"Mathesar 0.1.5"},{"location":"releases/0.1.5/#summary","text":"Mathesar 0.1.5 is a small, bug fix release. This page provides a comprehensive list of all changes in the release.","title":"Summary"},{"location":"releases/0.1.5/#upgrading-to-mathesar-015","text":"See our guide on upgrading Mathesar to 0.1.5 .","title":"Upgrading to Mathesar 0.1.5"},{"location":"releases/0.1.5/#improvements","text":"Improve performance of loading sample data when adding a new connection #3448 Constrain the width of the connections page #3439","title":"Improvements"},{"location":"releases/0.1.5/#bug-fixes","text":"Fix \u201cPage not found\u201d error when viewing a shared exploration #3456 Fix bugs preventing Mathesar from running in demo mode #3459 Fix timeout when setting up a new database with sample data in installations with higher network latency #3448 Restore display of column type icons within shared tables #3456 Temporarily hide link to missing docs page #3451 Fix active cell displaying above row header cell #3382","title":"Bug fixes"},{"location":"releases/0.1.5/#documentation","text":"Improve docs on using an external PostgreSQL server for Mathesar\u2019s internal database #3457 Add embedded video walkthrough within installation steps #3437 #3443 0.1.5 release notes #3449","title":"Documentation"},{"location":"releases/0.1.5/#maintenance","text":"Improve our release notes helper script #3435 Post-release cleanup #3432","title":"Maintenance"},{"location":"releases/0.1.6/","text":"Mathesar 0.1.6 \u00b6 Summary \u00b6 Mathesar 0.1.6 introduces Japanese localization of the UI and adds better support for working with long text in individual record pages. Improvements for administrators include compatibility with Python 3.10 and 3.11, support for databases running PostgreSQL 16, and the removal of npm and nodejs as dependencies when installing from scratch. This page provides a comprehensive list of all changes in the release. Upgrading to 0.1.6 \u00b6 See our guide on upgrading Mathesar to 0.1.6 . Improvements \u00b6 You can now configure Mathesar\u2019s UI to display in Japanese \u00b6 The language setting is stored per-user and can be modified when logging in or when editing a user. This changes the text displayed on buttons and other UI elements within Mathesar. It does not change the display of data within your database (e.g. table names, column names, and cell values). We are hoping to support more languages beyond English and Japanese eventually. Please reach out to us if your are interested in helping to add more translations! #3486 , #3484 , #3483 , #3472 , #3501 Text fields now auto-expands on the record page to accommodate longer texts \u00b6 Before All text inputs on the record page had the same height, regardless of their content. After All text inputs in record page dynamically adjust to accommodate the content seamlessly. #3470 , #3488 , #3495 Mathesar is now compatible with Python versions: 3.10 and 3.11 along with 3.9 \u00b6 Mathesar now officially supports Python versions 3.10 and 3.11, in addition to the existing 3.9 compatibility. This will provide great flexibility while building Mathesar from source on an OS that natively ships with relatively newer versions of Python. #3478 , #3499 , #3503 , #3504 Mathesar is now compatible with PostgreSQL 16 \u00b6 Mathesar now officially supports, and is tested against, Postgres versions 13, 14, 15 and 16. #3480 NodeJS is no longer a requirement for building Mathesar from source \u00b6 We removed NodeJS as a dependency in favour of providing users with pre-built static assest for building Mathesar from source. #3489 Bug fix \u00b6 Fixed connection creation failures due to schema name collisions while adding provided sample schema(s) in the database #3490 Documentation \u00b6 Documented upgrade instructions for v0.1.6 #3507 0.1.6 release notes #3506 Documented mathesar-debug image for Docker based installations #3513 Fixed upgrade instructions for v0.1.5 #3469 Updated Mathesar\u2019s version number in docs #3476 Added MkDocs edit URI #3482 Removed stale code coverage badge #3491 Maintenance \u00b6 Added a health check endpoint for Mathesar #3479 Bumped Django from 4.2.8 to 4.2.10 #3492 Removed NodeJS from Docker production image #3474 Post release cleanup #3463","title":"0.1.6"},{"location":"releases/0.1.6/#mathesar-016","text":"","title":"Mathesar 0.1.6"},{"location":"releases/0.1.6/#summary","text":"Mathesar 0.1.6 introduces Japanese localization of the UI and adds better support for working with long text in individual record pages. Improvements for administrators include compatibility with Python 3.10 and 3.11, support for databases running PostgreSQL 16, and the removal of npm and nodejs as dependencies when installing from scratch. This page provides a comprehensive list of all changes in the release.","title":"Summary"},{"location":"releases/0.1.6/#upgrading-to-016","text":"See our guide on upgrading Mathesar to 0.1.6 .","title":"Upgrading to 0.1.6"},{"location":"releases/0.1.6/#improvements","text":"","title":"Improvements"},{"location":"releases/0.1.6/#you-can-now-configure-mathesars-ui-to-display-in-japanese","text":"The language setting is stored per-user and can be modified when logging in or when editing a user. This changes the text displayed on buttons and other UI elements within Mathesar. It does not change the display of data within your database (e.g. table names, column names, and cell values). We are hoping to support more languages beyond English and Japanese eventually. Please reach out to us if your are interested in helping to add more translations! #3486 , #3484 , #3483 , #3472 , #3501","title":"You can now configure Mathesar's UI to display in Japanese"},{"location":"releases/0.1.6/#text-fields-now-auto-expands-on-the-record-page-to-accommodate-longer-texts","text":"Before All text inputs on the record page had the same height, regardless of their content. After All text inputs in record page dynamically adjust to accommodate the content seamlessly. #3470 , #3488 , #3495","title":"Text fields now auto-expands on the record page to accommodate longer texts"},{"location":"releases/0.1.6/#mathesar-is-now-compatible-with-python-versions-310-and-311-along-with-39","text":"Mathesar now officially supports Python versions 3.10 and 3.11, in addition to the existing 3.9 compatibility. This will provide great flexibility while building Mathesar from source on an OS that natively ships with relatively newer versions of Python. #3478 , #3499 , #3503 , #3504","title":"Mathesar is now compatible with Python versions: 3.10 and 3.11 along with 3.9"},{"location":"releases/0.1.6/#mathesar-is-now-compatible-with-postgresql-16","text":"Mathesar now officially supports, and is tested against, Postgres versions 13, 14, 15 and 16. #3480","title":"Mathesar is now compatible with PostgreSQL 16"},{"location":"releases/0.1.6/#nodejs-is-no-longer-a-requirement-for-building-mathesar-from-source","text":"We removed NodeJS as a dependency in favour of providing users with pre-built static assest for building Mathesar from source. #3489","title":"NodeJS is no longer a requirement for building Mathesar from source"},{"location":"releases/0.1.6/#bug-fix","text":"Fixed connection creation failures due to schema name collisions while adding provided sample schema(s) in the database #3490","title":"Bug fix"},{"location":"releases/0.1.6/#documentation","text":"Documented upgrade instructions for v0.1.6 #3507 0.1.6 release notes #3506 Documented mathesar-debug image for Docker based installations #3513 Fixed upgrade instructions for v0.1.5 #3469 Updated Mathesar\u2019s version number in docs #3476 Added MkDocs edit URI #3482 Removed stale code coverage badge #3491","title":"Documentation"},{"location":"releases/0.1.6/#maintenance","text":"Added a health check endpoint for Mathesar #3479 Bumped Django from 4.2.8 to 4.2.10 #3492 Removed NodeJS from Docker production image #3474 Post release cleanup #3463","title":"Maintenance"},{"location":"releases/0.1.7/","text":"Mathesar 0.1.7 \u00b6 Summary \u00b6 Mathesar 0.1.7 introduces linked table navigation from the data cell context menu. This release also fixes the regeneration of exploration share URLs and removes the \u2018group\u2019 suffix in the Data Explorer column names. This page provides a comprehensive list of all changes in the release. Upgrading to 0.1.7 \u00b6 See our guide on upgrading Mathesar to 0.1.7 . Improvements \u00b6 Linked Table Navigation from Cell Context Menu \u00b6 Users can now navigate to linked tables from the cell context menu, providing a more seamless experience when working with linked data. #3526 Bug fixes \u00b6 Fixed Regeneration of Exploration Share URL \u00b6 Fixed an issue where clicking \u201cRegenerate Link\u201d for a shared exploration failed to create a new URL and resulted in a 404 API request. Now, users will see a successful API call with a new, regenerated share URL. #3521 Remove \u2018group\u2019 Suffix in Data Explorer \u00b6 Resolved an issue in the Data Explorer where the grouping column name was incorrectly suffixed with \u2018group\u2019. Now, the original column names are preserved when summarizing data. #3357 Documentation \u00b6 Upgrade Instructions for 0.1.7 #3534 Maintenance \u00b6 Bump Django from 4.2.10 to 4.2.11 #3496 Made Release Notes Script Portable #3529 Removed Stray Changes Post Script Update #3530 Integrated Changes from Previous Release Preparation #3517 Added Demo Target in Dockerfile for Future Deployments #3523 New RPC Endpoint Implementation for Superuser Functions #3524","title":"0.1.7"},{"location":"releases/0.1.7/#mathesar-017","text":"","title":"Mathesar 0.1.7"},{"location":"releases/0.1.7/#summary","text":"Mathesar 0.1.7 introduces linked table navigation from the data cell context menu. This release also fixes the regeneration of exploration share URLs and removes the \u2018group\u2019 suffix in the Data Explorer column names. This page provides a comprehensive list of all changes in the release.","title":"Summary"},{"location":"releases/0.1.7/#upgrading-to-017","text":"See our guide on upgrading Mathesar to 0.1.7 .","title":"Upgrading to 0.1.7"},{"location":"releases/0.1.7/#improvements","text":"","title":"Improvements"},{"location":"releases/0.1.7/#linked-table-navigation-from-cell-context-menu","text":"Users can now navigate to linked tables from the cell context menu, providing a more seamless experience when working with linked data. #3526","title":"Linked Table Navigation from Cell Context Menu"},{"location":"releases/0.1.7/#bug-fixes","text":"","title":"Bug fixes"},{"location":"releases/0.1.7/#fixed-regeneration-of-exploration-share-url","text":"Fixed an issue where clicking \u201cRegenerate Link\u201d for a shared exploration failed to create a new URL and resulted in a 404 API request. Now, users will see a successful API call with a new, regenerated share URL. #3521","title":"Fixed Regeneration of Exploration Share URL"},{"location":"releases/0.1.7/#remove-group-suffix-in-data-explorer","text":"Resolved an issue in the Data Explorer where the grouping column name was incorrectly suffixed with \u2018group\u2019. Now, the original column names are preserved when summarizing data. #3357","title":"Remove 'group' Suffix in Data Explorer"},{"location":"releases/0.1.7/#documentation","text":"Upgrade Instructions for 0.1.7 #3534","title":"Documentation"},{"location":"releases/0.1.7/#maintenance","text":"Bump Django from 4.2.10 to 4.2.11 #3496 Made Release Notes Script Portable #3529 Removed Stray Changes Post Script Update #3530 Integrated Changes from Previous Release Preparation #3517 Added Demo Target in Dockerfile for Future Deployments #3523 New RPC Endpoint Implementation for Superuser Functions #3524","title":"Maintenance"},{"location":"releases/0.2.0-testing.1/","text":"\ud83e\uddea Mathesar 0.2.0-testing.1 \u00b6 Not a stable release This is a testing build released with the goal of gathering feedback from our community. It has many known issues and is not recommended for production use. Summary \u00b6 Mathesar 0.2.0-testing.1 provides an early preview of improvements we plan to release in our beta version. We have a brand new access control system based entirely on PostgreSQL database permissions, and we\u2019ve also made major improvements to the responsiveness of the Mathesar UI. We\u2019ve also built out a new RPC API, and we\u2019re deprecating our REST API in favor of it. This page provides a comprehensive list of all changes in the release. Installing 0.2.0-testing.1 \u00b6 You will need to create a new installation of Mathesar to use this version, which you can do via Docker Compose or from source . We do not support upgrading from previous versions to 0.2.0-testing.1 . Improvements \u00b6 Access control based on PostgreSQL roles and privileges \u00b6 We have a brand new access control system based entirely on PostgreSQL database roles and privileges. Mathesar users must now be assigned a database role, and any operations performed by the user through the Mathesar UI will connect to the database using that role. This gives Mathesar several new capabilities. Database administrators can set up access control directly on the database and use those roles in Mathesar. Mathesar also supports setting up PostgreSQL roles and privileges via the UI, including granular access control at the individual table level. This replaces our previous access control system (which was enforced at the API layer, and only supported permissions at the database and schema levels). It also eliminates the need for Mathesar to use a database superuser for day-to-day operations. More detailed documentation can be found in our User Guide under Permissions and Users . Initial permissions remodel #3626 Implement RPC method for listing roles in server #3663 Initial database_setup RPC methods #3665 Cast OID values to bigint in msar.get_roles #3667 RPC methods for servers, collaborators #3684 RPC methods for configured roles #3685 Remove existing permissions logic on the frontend #3689 Homepage changes for database connections #3710 Homepage UI #3711 Implement database_privileges.list_direct RPC method. #3750 Implement database_privileges.get_owner_oid_and_curr_role_db_priv RPC method #3760 Database page role configuration, collaborators, roles #3762 Implement roles.add RPC endpoint #3769 Add database_privileges.replace_for_roles RPC method. #3781 Add schema_privileges.replace_for_roles RPC method #3786 Move DB page contexts to the route level #3789 Add privilege information fields #3795 Database permissions modal - \u2018Share\u2019 tab #3810 Implement transfer_ownership for schemas and tables #3833 Implement permissions modal for schemas and tables #3836 , #3838 Allow setting owner at creation #3840 Implement roles.delete , databases.drop & databases.configured.disconnect RPC methods #3858 Implement \u2018Transfer ownership\u2019 tabs #3859 Permission checks in all pages, disconnect database option #3861 Bugfix get_current_role when only one role exists #3869 Grant appropriate permissions for msar , __msar and mathesar_types to PUBLIC #3881 Filter databases for admin and standard users #3895 Fix logic in get_current_role #3922 Fix quoting for role grant/revoke expressions #3931 Performance improvements and RPC API \u00b6 We\u2019ve made major improvements to the responsiveness of the Mathesar UI. Loading data and data entry should be much more snappy, and importing data into Mathsar is around 50 times faster. We\u2019ve also eliminated the need to manually sync database schema changes to Mathesar, any DDL changes will be reflected in the UI automatically. To achieve these performance benefits, we needed to overhaul our backend architecture and API. We have built out a new RPC API and our frontend UI now primarily uses that API. The RPC API has some documentation here , but should not be considered stable yet. Most of our REST API endpoints are now deprecated and will be removed soon. The /users/ and /data-files/ endpoints remain in use. Connections RPC front end #3543 Exception handler tests #3547 Fix SQL syntax highlighting in VS code for SQL tests #3588 Remove dead front end API client code to GET one schema #3589 Implement tables.delete RPC method #3608 Implement schemas.delete RPC method #3610 Implement tables.get RPC method #3612 Implement tables.add RPC method #3614 Add columns.patch RPC method #3615 Add columns.add RPC method #3616 Implement tables.patch RPC method #3618 Implement schemas.add RPC method #3620 Implement table.import RPC method #3623 Implement schemas.patch RPC method #3628 Wire RPC methods to new models #3632 Quoting refactor #3633 Implement tables.get_import_preview RPC method #3635 Auto generate table name #3637 Add columns.metadata.list RPC method #3641 Implement tables.metadata list & patch RPC method #3646 Fix issue with removing comments on schemas #3649 Drop old SQL function signature #3650 Implement tables list and delete RPC methods #3651 Columns meta RPC patch #3653 Constraints RPC transition #3664 Cast OIDs to bigint before putting in JSON #3666 RPC implementation for tables.list_joinable #3669 Improve tables metadata #3672 RPC implementation for types.list #3676 Add records.list RPC method #3691 RPC transition for explorations list and delete #3694 Implement explorations.run RPC method #3696 Fix return type error when re-defining get_constraints_for_table SQL function #3698 Fix Issues with tables.patch RPC method #3699 RPC records list filtering #3700 Return empty array when schema has no tables #3702 RPC function for column info with metadata #3703 First steps of RPC implementation for table page #3704 Add records.search RPC method #3708 Wire up valid_target_type function to column lister #3709 Alter column metadata fields #3717 Add target_table_info in tables.list_joinable's response #3718 Records grouping #3721 Fix \u201cno current database\u201d error #3723 Implement explorations run_saved & get RPC methods #3725 Handle new records filtering on the front end #3728 Implement explorations add & replace method #3731 Add records.get RPC method #3740 Add records.delete RPC method #3741 Add records.add RPC method #3745 Adapt front end to new RPC-based joinable tables API #3746 Fix edge case while getting joinable tables for tables with no links #3748 Add records.patch RPC method #3749 Records grouping bugfix #3751 Records delete bugfix #3754 Adapt front end to new records grouping API #3755 Implement RPC records CRUD operations on front end #3759 Add simplified record summaries #3761 Add link-adding RPC methods #3767 Add data_modeling.suggest_types method. #3771 Add schema_privileges.list_direct RPC method #3782 Add table_privileges.list_direct RPC method #3783 Add table_privileges.replace_for_roles RPC method #3791 Add roles.get_current_role RPC method #3796 Reorganize namespacing #3799 Hard-code abstract types response in client #3800 Change response structure for record summary #3802 Implement data_modeling.split_table RPC methods #3803 Modify pkey finder to return False when no pkey exists #3804 Change response for tables.add and tables.import #3807 Add summaries to self #3808 Move columns SQL #3809 Propagate RPC record summary changes to front end #3811 Add data_file_id field to TableMetaData #3813 Implement data_modeling.move_columns RPC method #3814 Get imports working again #3819 Implement databases.privileges.transfer_ownership RPC method #3821 Implement tables.get_with_metadata RPC method #3823 Use data file name as table name during import #3824 A couple small front end RPC changes #3825 Bugfix listing records from a table with self-Referential FK #3831 Hard-code type cast map on front end #3832 Alter response for schemas add and patch methods & implement schemas.get #3837 Propagate RPC changes to record selector #3843 Use RPC API for column metadata #3845 Propagate RPC changes to link table dialog #3847 Fix response for split_table #3850 Alter response for record summaries with NULL records #3852 Make records.get work with stringified PK values #3853 Enabling running of very simple explorations #3855 Get \u201cextract columns\u201d and \u201cmove columns\u201d functionality working again #3856 Allow patching records via string PKs #3857 Implement roles.set_members RPC method #3866 Fix updating of table name #3879 Bugfix summarizations #3884 Fix insert for table with only ID column #3885 Add schema_oid to Explorations model #3892 Get explorations CRUD working again #3893 Reduces frontend caching, fixes a few bugs #3897 Fix broken exploration \u201ccolumn added\u201d indicators #3894 Fix bug when updating table twice _ #3909 Fix response of explorations.run for summarizations #3940 Fixes server errors when RPC exceptions are thrown while rendering common_data #3948 Visual improvements \u00b6 We made several visual improvements to Mathesar to ensure consistency, better usability, and adherence to design guidelines. The changes were mainly to various modals and to the table inspector. A before-and-after comparison of the \u201cCreate Link\u201d modal can be seen below. Show a loading spinner for table pages #3602 UI consistency improvements for modals and table inspector #3860 Bug fixes \u00b6 Bugs related to permissions or the backend overhaul are listed in the relevant sections above. The bugs listed here are unrelated to those changes. Remove nonsensical cast_to_email and cast_to_uri functions #3564 Add 0.1.7 release notes to the nav menu #3569 Fix error when trying to reset password of other user #3536 Handle negative numbers not being serialized correctly when copying #3582 Fix timeout when installing Mathesar on a remote DB #3917 Use a semver library to parse our version strings on the front end #3938 Documentation \u00b6 Updated user guide to cover new features and remove unnecessary pages #3910 Improvements to installation from scratch documentation #3945 Maintenance \u00b6 Miscellanous work done to reduce technical debt, improve developer documentation, and maintain our workflow. Refactor CellSelection data structure and store #3037 Remove API documentation infrastructure #3541 Remove Debian build #3546 Update docs to add instructions for loading data from playground #3535 Merge 0.1.7 release back into develop #3558 Resolve merge conflict for #3558 #3559 Revert #3559 #3567 Bump dependencies #3544 , #3604 Sort frontend imports #3552 Architectural overhaul #3587 Add SQL code standard for casting OIDs to bigint #3643 Fix issue with SQL migrations not running when service restarts #3678 Merge breaking changes into develop #3695 Update MkDocs dependencies #3763 Merge develop into release branch. #3950 Live demo changes \u00b6 We have removed code related to Mathesar\u2019s \u201clive demo\u201d mode since we didn\u2019t think it made sense to include code for our promotional website in the core product. If we do choose to maintain our live demo in the future, we will set up a separate microservice that performs some of these functions. We also set up a workflow to reset the live demo regularly to mitigate reliability issues. Remove demo code and E2E infrastructure #3538 , #3551 Add GitHub workflow to reset demo #3577 Updates to GH workflow for resetting demo #3579 Updates to GH workflow to reset demo #3580 Remove the demo reset workflow #3581","title":"0.2.0-testing.1"},{"location":"releases/0.2.0-testing.1/#mathesar-020-testing1","text":"Not a stable release This is a testing build released with the goal of gathering feedback from our community. It has many known issues and is not recommended for production use.","title":"\ud83e\uddea Mathesar 0.2.0-testing.1"},{"location":"releases/0.2.0-testing.1/#summary","text":"Mathesar 0.2.0-testing.1 provides an early preview of improvements we plan to release in our beta version. We have a brand new access control system based entirely on PostgreSQL database permissions, and we\u2019ve also made major improvements to the responsiveness of the Mathesar UI. We\u2019ve also built out a new RPC API, and we\u2019re deprecating our REST API in favor of it. This page provides a comprehensive list of all changes in the release.","title":"Summary"},{"location":"releases/0.2.0-testing.1/#installing-020-testing1","text":"You will need to create a new installation of Mathesar to use this version, which you can do via Docker Compose or from source . We do not support upgrading from previous versions to 0.2.0-testing.1 .","title":"Installing 0.2.0-testing.1"},{"location":"releases/0.2.0-testing.1/#improvements","text":"","title":"Improvements"},{"location":"releases/0.2.0-testing.1/#access-control-based-on-postgresql-roles-and-privileges","text":"We have a brand new access control system based entirely on PostgreSQL database roles and privileges. Mathesar users must now be assigned a database role, and any operations performed by the user through the Mathesar UI will connect to the database using that role. This gives Mathesar several new capabilities. Database administrators can set up access control directly on the database and use those roles in Mathesar. Mathesar also supports setting up PostgreSQL roles and privileges via the UI, including granular access control at the individual table level. This replaces our previous access control system (which was enforced at the API layer, and only supported permissions at the database and schema levels). It also eliminates the need for Mathesar to use a database superuser for day-to-day operations. More detailed documentation can be found in our User Guide under Permissions and Users . Initial permissions remodel #3626 Implement RPC method for listing roles in server #3663 Initial database_setup RPC methods #3665 Cast OID values to bigint in msar.get_roles #3667 RPC methods for servers, collaborators #3684 RPC methods for configured roles #3685 Remove existing permissions logic on the frontend #3689 Homepage changes for database connections #3710 Homepage UI #3711 Implement database_privileges.list_direct RPC method. #3750 Implement database_privileges.get_owner_oid_and_curr_role_db_priv RPC method #3760 Database page role configuration, collaborators, roles #3762 Implement roles.add RPC endpoint #3769 Add database_privileges.replace_for_roles RPC method. #3781 Add schema_privileges.replace_for_roles RPC method #3786 Move DB page contexts to the route level #3789 Add privilege information fields #3795 Database permissions modal - \u2018Share\u2019 tab #3810 Implement transfer_ownership for schemas and tables #3833 Implement permissions modal for schemas and tables #3836 , #3838 Allow setting owner at creation #3840 Implement roles.delete , databases.drop & databases.configured.disconnect RPC methods #3858 Implement \u2018Transfer ownership\u2019 tabs #3859 Permission checks in all pages, disconnect database option #3861 Bugfix get_current_role when only one role exists #3869 Grant appropriate permissions for msar , __msar and mathesar_types to PUBLIC #3881 Filter databases for admin and standard users #3895 Fix logic in get_current_role #3922 Fix quoting for role grant/revoke expressions #3931","title":"Access control based on PostgreSQL roles and privileges"},{"location":"releases/0.2.0-testing.1/#performance-improvements-and-rpc-api","text":"We\u2019ve made major improvements to the responsiveness of the Mathesar UI. Loading data and data entry should be much more snappy, and importing data into Mathsar is around 50 times faster. We\u2019ve also eliminated the need to manually sync database schema changes to Mathesar, any DDL changes will be reflected in the UI automatically. To achieve these performance benefits, we needed to overhaul our backend architecture and API. We have built out a new RPC API and our frontend UI now primarily uses that API. The RPC API has some documentation here , but should not be considered stable yet. Most of our REST API endpoints are now deprecated and will be removed soon. The /users/ and /data-files/ endpoints remain in use. Connections RPC front end #3543 Exception handler tests #3547 Fix SQL syntax highlighting in VS code for SQL tests #3588 Remove dead front end API client code to GET one schema #3589 Implement tables.delete RPC method #3608 Implement schemas.delete RPC method #3610 Implement tables.get RPC method #3612 Implement tables.add RPC method #3614 Add columns.patch RPC method #3615 Add columns.add RPC method #3616 Implement tables.patch RPC method #3618 Implement schemas.add RPC method #3620 Implement table.import RPC method #3623 Implement schemas.patch RPC method #3628 Wire RPC methods to new models #3632 Quoting refactor #3633 Implement tables.get_import_preview RPC method #3635 Auto generate table name #3637 Add columns.metadata.list RPC method #3641 Implement tables.metadata list & patch RPC method #3646 Fix issue with removing comments on schemas #3649 Drop old SQL function signature #3650 Implement tables list and delete RPC methods #3651 Columns meta RPC patch #3653 Constraints RPC transition #3664 Cast OIDs to bigint before putting in JSON #3666 RPC implementation for tables.list_joinable #3669 Improve tables metadata #3672 RPC implementation for types.list #3676 Add records.list RPC method #3691 RPC transition for explorations list and delete #3694 Implement explorations.run RPC method #3696 Fix return type error when re-defining get_constraints_for_table SQL function #3698 Fix Issues with tables.patch RPC method #3699 RPC records list filtering #3700 Return empty array when schema has no tables #3702 RPC function for column info with metadata #3703 First steps of RPC implementation for table page #3704 Add records.search RPC method #3708 Wire up valid_target_type function to column lister #3709 Alter column metadata fields #3717 Add target_table_info in tables.list_joinable's response #3718 Records grouping #3721 Fix \u201cno current database\u201d error #3723 Implement explorations run_saved & get RPC methods #3725 Handle new records filtering on the front end #3728 Implement explorations add & replace method #3731 Add records.get RPC method #3740 Add records.delete RPC method #3741 Add records.add RPC method #3745 Adapt front end to new RPC-based joinable tables API #3746 Fix edge case while getting joinable tables for tables with no links #3748 Add records.patch RPC method #3749 Records grouping bugfix #3751 Records delete bugfix #3754 Adapt front end to new records grouping API #3755 Implement RPC records CRUD operations on front end #3759 Add simplified record summaries #3761 Add link-adding RPC methods #3767 Add data_modeling.suggest_types method. #3771 Add schema_privileges.list_direct RPC method #3782 Add table_privileges.list_direct RPC method #3783 Add table_privileges.replace_for_roles RPC method #3791 Add roles.get_current_role RPC method #3796 Reorganize namespacing #3799 Hard-code abstract types response in client #3800 Change response structure for record summary #3802 Implement data_modeling.split_table RPC methods #3803 Modify pkey finder to return False when no pkey exists #3804 Change response for tables.add and tables.import #3807 Add summaries to self #3808 Move columns SQL #3809 Propagate RPC record summary changes to front end #3811 Add data_file_id field to TableMetaData #3813 Implement data_modeling.move_columns RPC method #3814 Get imports working again #3819 Implement databases.privileges.transfer_ownership RPC method #3821 Implement tables.get_with_metadata RPC method #3823 Use data file name as table name during import #3824 A couple small front end RPC changes #3825 Bugfix listing records from a table with self-Referential FK #3831 Hard-code type cast map on front end #3832 Alter response for schemas add and patch methods & implement schemas.get #3837 Propagate RPC changes to record selector #3843 Use RPC API for column metadata #3845 Propagate RPC changes to link table dialog #3847 Fix response for split_table #3850 Alter response for record summaries with NULL records #3852 Make records.get work with stringified PK values #3853 Enabling running of very simple explorations #3855 Get \u201cextract columns\u201d and \u201cmove columns\u201d functionality working again #3856 Allow patching records via string PKs #3857 Implement roles.set_members RPC method #3866 Fix updating of table name #3879 Bugfix summarizations #3884 Fix insert for table with only ID column #3885 Add schema_oid to Explorations model #3892 Get explorations CRUD working again #3893 Reduces frontend caching, fixes a few bugs #3897 Fix broken exploration \u201ccolumn added\u201d indicators #3894 Fix bug when updating table twice _ #3909 Fix response of explorations.run for summarizations #3940 Fixes server errors when RPC exceptions are thrown while rendering common_data #3948","title":"Performance improvements and RPC API"},{"location":"releases/0.2.0-testing.1/#visual-improvements","text":"We made several visual improvements to Mathesar to ensure consistency, better usability, and adherence to design guidelines. The changes were mainly to various modals and to the table inspector. A before-and-after comparison of the \u201cCreate Link\u201d modal can be seen below. Show a loading spinner for table pages #3602 UI consistency improvements for modals and table inspector #3860","title":"Visual improvements"},{"location":"releases/0.2.0-testing.1/#bug-fixes","text":"Bugs related to permissions or the backend overhaul are listed in the relevant sections above. The bugs listed here are unrelated to those changes. Remove nonsensical cast_to_email and cast_to_uri functions #3564 Add 0.1.7 release notes to the nav menu #3569 Fix error when trying to reset password of other user #3536 Handle negative numbers not being serialized correctly when copying #3582 Fix timeout when installing Mathesar on a remote DB #3917 Use a semver library to parse our version strings on the front end #3938","title":"Bug fixes"},{"location":"releases/0.2.0-testing.1/#documentation","text":"Updated user guide to cover new features and remove unnecessary pages #3910 Improvements to installation from scratch documentation #3945","title":"Documentation"},{"location":"releases/0.2.0-testing.1/#maintenance","text":"Miscellanous work done to reduce technical debt, improve developer documentation, and maintain our workflow. Refactor CellSelection data structure and store #3037 Remove API documentation infrastructure #3541 Remove Debian build #3546 Update docs to add instructions for loading data from playground #3535 Merge 0.1.7 release back into develop #3558 Resolve merge conflict for #3558 #3559 Revert #3559 #3567 Bump dependencies #3544 , #3604 Sort frontend imports #3552 Architectural overhaul #3587 Add SQL code standard for casting OIDs to bigint #3643 Fix issue with SQL migrations not running when service restarts #3678 Merge breaking changes into develop #3695 Update MkDocs dependencies #3763 Merge develop into release branch. #3950","title":"Maintenance"},{"location":"releases/0.2.0-testing.1/#live-demo-changes","text":"We have removed code related to Mathesar\u2019s \u201clive demo\u201d mode since we didn\u2019t think it made sense to include code for our promotional website in the core product. If we do choose to maintain our live demo in the future, we will set up a separate microservice that performs some of these functions. We also set up a workflow to reset the live demo regularly to mitigate reliability issues. Remove demo code and E2E infrastructure #3538 , #3551 Add GitHub workflow to reset demo #3577 Updates to GH workflow for resetting demo #3579 Updates to GH workflow to reset demo #3580 Remove the demo reset workflow #3581","title":"Live demo changes"},{"location":"releases/TEMPLATE/","text":"Mathesar VERSION \u00b6 Summary \u00b6 TODO This page provides a comprehensive list of all changes in the release. Upgrading to VERSION \u00b6 TODO","title":"Mathesar __VERSION__"},{"location":"releases/TEMPLATE/#mathesar-version","text":"","title":"Mathesar VERSION"},{"location":"releases/TEMPLATE/#summary","text":"TODO This page provides a comprehensive list of all changes in the release.","title":"Summary"},{"location":"releases/TEMPLATE/#upgrading-to-version","text":"TODO","title":"Upgrading to VERSION"},{"location":"snippets/docker-compose-prerequisites/","text":"Operating System \u00b6 You can install Mathesar using this method on Linux, MacOS, and Windows. Software \u00b6 You\u2019ll need to install the following software before you install Mathesar: Docker v23+ Docker Compose v2.10+ If you\u2019re installing on Windows: Ensure you have WSL installed Turn on Docker Desktop WSL 2, see Docker docs for more information","title":"Docker compose prerequisites"},{"location":"snippets/docker-compose-prerequisites/#operating-system","text":"You can install Mathesar using this method on Linux, MacOS, and Windows.","title":"Operating System"},{"location":"snippets/docker-compose-prerequisites/#software","text":"You\u2019ll need to install the following software before you install Mathesar: Docker v23+ Docker Compose v2.10+ If you\u2019re installing on Windows: Ensure you have WSL installed Turn on Docker Desktop WSL 2, see Docker docs for more information","title":"Software"},{"location":"snippets/uninstall-schemas/","text":"Remove Mathesar internal schemas. If you\u2019d like to continue using your PostgreSQL database , you\u2019ll need to remove the schemas created for Mathesar\u2019s use during installation. You can remove them from the database as follows: Connect to the database. psql -h <DB HOSTNAME> -p <DB PORT> -U <DB_USER> <DB_NAME> Delete the types schema. DROP SCHEMA mathesar_types CASCADE ; Deleting this schema will also delete any database objects that depend on it. This should not be an issue if you don\u2019t have any data using Mathesar\u2019s custom data types. Delete the function schemas. DROP SCHEMA msar CASCADE ; DROP SCHEMA __msar CASCADE ;","title":"Uninstall schemas"},{"location":"user-guide/","text":"Using Mathesar \u00b6 Welcome! At this point, we assume you\u2019ve installed Mathesar successfully and have logged into the web UI. If you\u2019ve connected Mathesar to an existing database, you should see all your schemas and tables once you log in, and you can work with them as you please. More\u2026 \ud83d\udc48 Browse the \u201cUsing Mathesar\u201d navigation section to find more detailed documentation pages.","title":"Introduction"},{"location":"user-guide/#using-mathesar","text":"Welcome! At this point, we assume you\u2019ve installed Mathesar successfully and have logged into the web UI. If you\u2019ve connected Mathesar to an existing database, you should see all your schemas and tables once you log in, and you can work with them as you please. More\u2026 \ud83d\udc48 Browse the \u201cUsing Mathesar\u201d navigation section to find more detailed documentation pages.","title":"Using Mathesar"},{"location":"user-guide/databases/","text":"Databases \u00b6 Each installation of Mathesar can connect to multiple PostgreSQL databases. Connecting your first database will likely be your first step in using Mathesar. PostgreSQL servers \u00b6 Every PostgreSQL database lives within a PostgreSQL server. External servers: Mathesar can connect to any Internet-exposed PostgreSQL server to access the databases within it. We\u2019ll refer to these PostgreSQL servers as \u201cexternal servers\u201d. The Internal Server: Most Mathesar installations have an internal PostgreSQL server which the Mathesar application controls and utilizes for storage of application-specific metadata. Some Mathesar installations don\u2019t have an internal server It\u2019s possible (though not recommended) to configure Mathesar to store its internal metadata in SQLite, thereby circumventing the need for an internal server. Creating a new database \u00b6 If you\u2019re starting your database from scratch with Mathesar you can either: Use Mathesar to create a new database within Mathesar\u2019s internal server and connect to it. This is a good option to get up and running quickly, but it might require more work later should you decide to set up periodic backups or connect other tools to the same database. Also, this option won\u2019t be possible if Mathesar was installed without an internal server. OR Use another tool to create your database on an external server and then connect Mathesar to it. You can administer that external server yourself, or choose from a variety of hosted PostgreSQL solutions such as Amazon RDS , Google Cloud SQL , Supabase , and others. Connecting a database \u00b6 Click the Connect Database button from the home page of your Mathesar application and follow the prompts. Once you\u2019ve connected a database, you can navigate to Mathesar\u2019s page for it where you can browse the database\u2019s schemas and configure various permissions for it. Mathesar will remember the connection even after the application is shut down. Your Mathesar user will be added as a \u201ccollaborator\u201d on the database (along with the PostgreSQL role you entered). And the password you entered for that role will be stored in Mathesar\u2019s internal database, encrypted using Mathesar\u2019s SECRET_KEY .","title":"Databases"},{"location":"user-guide/databases/#databases","text":"Each installation of Mathesar can connect to multiple PostgreSQL databases. Connecting your first database will likely be your first step in using Mathesar.","title":"Databases"},{"location":"user-guide/databases/#postgresql-servers","text":"Every PostgreSQL database lives within a PostgreSQL server. External servers: Mathesar can connect to any Internet-exposed PostgreSQL server to access the databases within it. We\u2019ll refer to these PostgreSQL servers as \u201cexternal servers\u201d. The Internal Server: Most Mathesar installations have an internal PostgreSQL server which the Mathesar application controls and utilizes for storage of application-specific metadata. Some Mathesar installations don\u2019t have an internal server It\u2019s possible (though not recommended) to configure Mathesar to store its internal metadata in SQLite, thereby circumventing the need for an internal server.","title":"PostgreSQL servers"},{"location":"user-guide/databases/#creating-a-new-database","text":"If you\u2019re starting your database from scratch with Mathesar you can either: Use Mathesar to create a new database within Mathesar\u2019s internal server and connect to it. This is a good option to get up and running quickly, but it might require more work later should you decide to set up periodic backups or connect other tools to the same database. Also, this option won\u2019t be possible if Mathesar was installed without an internal server. OR Use another tool to create your database on an external server and then connect Mathesar to it. You can administer that external server yourself, or choose from a variety of hosted PostgreSQL solutions such as Amazon RDS , Google Cloud SQL , Supabase , and others.","title":"Creating a new database"},{"location":"user-guide/databases/#connecting-a-database","text":"Click the Connect Database button from the home page of your Mathesar application and follow the prompts. Once you\u2019ve connected a database, you can navigate to Mathesar\u2019s page for it where you can browse the database\u2019s schemas and configure various permissions for it. Mathesar will remember the connection even after the application is shut down. Your Mathesar user will be added as a \u201ccollaborator\u201d on the database (along with the PostgreSQL role you entered). And the password you entered for that role will be stored in Mathesar\u2019s internal database, encrypted using Mathesar\u2019s SECRET_KEY .","title":"Connecting a database"},{"location":"user-guide/glossary/","text":"Glossary \u00b6 Internal database \u00b6 The \u201cinternal database\u201d holds Mathesar-specific metadata about the actual data (which lives in the user database ). Examples of such metadata include: Exploration definitions Column display formatting settings Record summary template customizations Custom column ordering Each Mathesar installation requires one and only one internal database, and PostgreSQL and SQLite are both supported. User database \u00b6 The data you see within Mathesar lives in the \u201cuser database\u201d, which must use PostgreSQL. Each Mathesar installation can connect to multiple user databases, potentially on different servers. Mathesar also uses an internal database to store metadata.","title":"Glossary"},{"location":"user-guide/glossary/#glossary","text":"","title":"Glossary"},{"location":"user-guide/glossary/#internal-db","text":"The \u201cinternal database\u201d holds Mathesar-specific metadata about the actual data (which lives in the user database ). Examples of such metadata include: Exploration definitions Column display formatting settings Record summary template customizations Custom column ordering Each Mathesar installation requires one and only one internal database, and PostgreSQL and SQLite are both supported.","title":"Internal database"},{"location":"user-guide/glossary/#user-db","text":"The data you see within Mathesar lives in the \u201cuser database\u201d, which must use PostgreSQL. Each Mathesar installation can connect to multiple user databases, potentially on different servers. Mathesar also uses an internal database to store metadata.","title":"User database"},{"location":"user-guide/importing-data/","text":"Importing data into Mathesar \u00b6 Mathesar allows importing data in CSV and JSON format. It also attempts to automatically infer the data type of the columns. Importing CSV data \u00b6 Delimiters \u00b6 Fields in the CSV data may be delimited by any of the following characters: Name Character Notes Comma , A traditional CSV file (a \u201c C omma S eparated V alue\u201d document) Tab (not printable) This is sometimes referred to as a TSV file (a \u201c T ab S eparated V alue\u201d document) Semicolon ; Colon : Pipe | Header rows \u00b6 By default, Mathesar will use the first row of CSV data to name the columns. If you un-check \u201cUse first row as header\u201d , then Mathesar will generate default names for the columns which you can edit later. Importing JSON data \u00b6 The JSON data must be structured in one of the following ways: An array of objects Each object produces one row in the table, and the object keys become column names. If a key is present is only one object, then the values for that column will be NULL in all other rows. [ { \"first_name\" : \"Matt\" , \"last_name\" : \"Murdock\" , \"gender\" : \"Male\" , \"friends\" : [ \"Stick\" , \"Foggy\" ] }, { \"first_name\" : \"John\" , \"last_name\" : \"Doe\" , \"email\" : \"jd@example.org\" , \"gender\" : \"Male\" } ] A single object This is similar to above but produces a table with only one row. { \"name\" : \"John\" , \"age\" : 21 , \"friends\" : [ \"Bob\" , \"Mary\" ] } Our goal is to support whatever pandas.json_normalize supports.","title":"Importing data"},{"location":"user-guide/importing-data/#importing-data-into-mathesar","text":"Mathesar allows importing data in CSV and JSON format. It also attempts to automatically infer the data type of the columns.","title":"Importing data into Mathesar"},{"location":"user-guide/importing-data/#csv","text":"","title":"Importing CSV data"},{"location":"user-guide/importing-data/#delimiters","text":"Fields in the CSV data may be delimited by any of the following characters: Name Character Notes Comma , A traditional CSV file (a \u201c C omma S eparated V alue\u201d document) Tab (not printable) This is sometimes referred to as a TSV file (a \u201c T ab S eparated V alue\u201d document) Semicolon ; Colon : Pipe |","title":"Delimiters"},{"location":"user-guide/importing-data/#header-rows","text":"By default, Mathesar will use the first row of CSV data to name the columns. If you un-check \u201cUse first row as header\u201d , then Mathesar will generate default names for the columns which you can edit later.","title":"Header rows"},{"location":"user-guide/importing-data/#json","text":"The JSON data must be structured in one of the following ways: An array of objects Each object produces one row in the table, and the object keys become column names. If a key is present is only one object, then the values for that column will be NULL in all other rows. [ { \"first_name\" : \"Matt\" , \"last_name\" : \"Murdock\" , \"gender\" : \"Male\" , \"friends\" : [ \"Stick\" , \"Foggy\" ] }, { \"first_name\" : \"John\" , \"last_name\" : \"Doe\" , \"email\" : \"jd@example.org\" , \"gender\" : \"Male\" } ] A single object This is similar to above but produces a table with only one row. { \"name\" : \"John\" , \"age\" : 21 , \"friends\" : [ \"Bob\" , \"Mary\" ] } Our goal is to support whatever pandas.json_normalize supports.","title":"Importing JSON data"},{"location":"user-guide/permissions/","text":"Mathesar\u2019s Role-Based Permissions \u00b6 Mathesar uses PostgreSQL roles to manage permissions on your data. These roles define the actions users can perform, allowing fine-grained control over access. Roles vs Users \u00b6 Each Mathesar user accesses a database through one PostgreSQL role \u2014 and the user\u2019s permissions are determined by the role\u2019s permissions within PostgreSQL. You can read more about how users and roles work together . The Database \u201cSettings\u201d tab \u00b6 Each database has its own page within Mathesar. And on that page you\u2019ll find a \u201cSettings\u201d tab where you can manage roles and collaborators. In Mathesar: Role Configuration \u00b6 Use this section to manage the credentials (i.e. passwords) for roles that you\u2019d like to assign to collaborators within Mathesar. Mathesar will display all LOGIN roles that exist on the server. Click Configure in Mathesar to store the role\u2019s password in Mathesar and allow the role to be associated with collaborators. Click Configure Password to update the password of an already configured role. Click Remove to remove Mathesar\u2019s stored password for a role. The role will remain on the server. In Mathesar: Collaborators \u00b6 A \u201ccollaborator\u201d is a Mathesar user who has access to a database through a specific PostgreSQL role. The Collaborators section allows you to add and remove collaborators and edit their corresponding PostgreSQL roles. Keep in mind You\u2019ll only be able to choose roles that have been \u201cconfigured\u201d in the above section \u2014 roles for which Mathesar has passwords stored. Removing a collaborator revokes that user\u2019s access to the database but : If the user is a Mathesar admin , they\u2019ll be able to gain access again. The user will still remain in Mathesar, potentially with access to other Databases. The role (and it\u2019s corresponding password) will still remain configured in Mathesar. The role will still remain on the PostgreSQL server. On the Server: Roles \u00b6 Here you can manage roles available on the server, defining their inheritance, creating new roles, or deleting existing ones. Any changes here will be reflected for all connected databases which share this server. Create Roles : You can create new server-level roles from this section. You can configure these roles in two ways: With login capability and a password, which you can assign to collaborators. Without login capability, to be used exclusively as a parent role to group permissions that can be inherited by other roles. You cannot assign these non-login roles to collaborators directly. Define Child Roles : PostgreSQL has a mechanism for Role Membership wherein any role can be \u201cgranted\u201d to any other role to form simple hierarchies or complex graph-based inheritance structures. For any role you\u2019ve configured within Mathesar, you can use Mathesar to grant the role to other \u201cchild roles\u201d. Drop Roles : You can drop server-level roles that are no longer needed. This action removes the role from the server, however if the role is configured in Mathesar, it will still be displayed. Exercise caution when dropping roles, as it may affect collaborators using the dropped role in Mathesar. Note Server roles, once added, must be configured in Mathesar under the Role Configuration section before they can be assigned to collaborators. PostgreSQL objects \u00b6 In PostgreSQL, an \u201cobject\u201d is a thing like: a database, a schema, a table, (and some other things too, which we won\u2019t cover here) . Privileges and ownership \u00b6 Privileges: Specific privileges on an object can be granted to specific roles. Example A role can be granted the CREATE privilege on a schema. This allows the role to create new tables within the schema. Ownership : Every PostgreSQL object has one and only one role said to be its \u201cowner\u201d. The owner generally can do anything directly to the object, but not necessarily other objects contained within it. By default the owner is set to the role which created the object. Shared ownership: While PostgreSQL has a variety of granular privileges for different actions, there are still certain actions which remain restricted to object owners. For example only the owner of a table can add new columns to it. While this behavior may seem limiting, it\u2019s still possible configure multiple roles to effectively \u201cown\u201d a single object by leveraging PostgreSQL\u2019s powerful role inheritance functionality: We can create a third role to directly own the object and act as a sort of proxy \u201cgroup\u201d. (The group role doesn\u2019t need to be a LOGIN role and thus doesn\u2019t require a password to be configured.) Then we can grant that group role to any other roles we\u2019d like. Those child roles will then have permission do things as if they were the owner themselves . You can use the Mathesar UI to configure an arrangement like the above, though it will require many steps. Database Permissions \u00b6 The \u201cDatabase Permissions\u201d modal is accessible via a button at the top right of the database page and allows you to configure the owner and granted privileges for a database. Owner : Each database has an owner who has administrative control over the database itself, including managing database-level permissions and transferring ownership. Ownership does not automatically extend to the objects within the database (such as schemas and tables), which may have their own separate ownership and permission settings. Granted Access : Specific permissions can be granted to roles for various actions within the database. Transfer Ownership : The current owner can transfer ownership to another role, granting them administrative control. For each database, the following permission levels can be granted: Connect : Allows the role to access and connect to the database. Create : Includes Connect permissions and allows the role to create new schemas within the database. Custom : Enables the granular setting of permissions beyond the predefined options. Schema Permissions \u00b6 The \u201cSchema Permissions\u201d modal is accessible via a button at the top right of the schema page and allows you to configure the owner and granted privileges for a schema. Owner : Each schema has an owner who has administrative control over the schema itself, including managing schema-level permissions and transferring ownership. Ownership does not automatically extend to the objects within the schema (such as tables), which may have their own separate ownership and permission settings. Granted Access : Specific permissions can be granted to roles for various actions within the schema. Transfer Ownership : The current owner can transfer ownership to another role, granting them administrative control over the schema. For each schema, the following permission levels can be granted: Read : Allows the role to access the schema and view its objects. Create : Includes Read permissions and allows the role to create new tables within the schema. Custom : Enables the granular setting of permissions beyond the predefined options. Table Permissions \u00b6 The Table Permissions modal is accessible via a button from within the right-side inspector panel for each table and allows you to configure the owner and granted privileges for a table. Owner : Each table has an owner who has administrative control over the table itself, including managing table-level permissions, transferring ownership, and modifying the table\u2019s structure (such as adding, removing, or altering columns). Granted Access : Specific permissions can be granted to roles for various actions on the table. Transfer Ownership : The current owner can transfer ownership to another role, granting them administrative control over the table. For each table, the following permission levels can be granted: Read : Allows the role to access the table and read records. Write : Includes Read permissions and allows the role to insert, update, and delete records in the table. Custom : Enables the granular setting of permissions beyond the predefined options. You can read more about the specific privileges that can be granted in the PostgreSQL documentation on Privileges .","title":"Permissions"},{"location":"user-guide/permissions/#mathesars-role-based-permissions","text":"Mathesar uses PostgreSQL roles to manage permissions on your data. These roles define the actions users can perform, allowing fine-grained control over access.","title":"Mathesar's Role-Based Permissions"},{"location":"user-guide/permissions/#roles-vs-users","text":"Each Mathesar user accesses a database through one PostgreSQL role \u2014 and the user\u2019s permissions are determined by the role\u2019s permissions within PostgreSQL. You can read more about how users and roles work together .","title":"Roles vs Users"},{"location":"user-guide/permissions/#database_settings","text":"Each database has its own page within Mathesar. And on that page you\u2019ll find a \u201cSettings\u201d tab where you can manage roles and collaborators.","title":"The Database \"Settings\" tab"},{"location":"user-guide/permissions/#role_configuration","text":"Use this section to manage the credentials (i.e. passwords) for roles that you\u2019d like to assign to collaborators within Mathesar. Mathesar will display all LOGIN roles that exist on the server. Click Configure in Mathesar to store the role\u2019s password in Mathesar and allow the role to be associated with collaborators. Click Configure Password to update the password of an already configured role. Click Remove to remove Mathesar\u2019s stored password for a role. The role will remain on the server.","title":"In Mathesar: Role Configuration"},{"location":"user-guide/permissions/#collaborators","text":"A \u201ccollaborator\u201d is a Mathesar user who has access to a database through a specific PostgreSQL role. The Collaborators section allows you to add and remove collaborators and edit their corresponding PostgreSQL roles. Keep in mind You\u2019ll only be able to choose roles that have been \u201cconfigured\u201d in the above section \u2014 roles for which Mathesar has passwords stored. Removing a collaborator revokes that user\u2019s access to the database but : If the user is a Mathesar admin , they\u2019ll be able to gain access again. The user will still remain in Mathesar, potentially with access to other Databases. The role (and it\u2019s corresponding password) will still remain configured in Mathesar. The role will still remain on the PostgreSQL server.","title":"In Mathesar: Collaborators"},{"location":"user-guide/permissions/#roles","text":"Here you can manage roles available on the server, defining their inheritance, creating new roles, or deleting existing ones. Any changes here will be reflected for all connected databases which share this server. Create Roles : You can create new server-level roles from this section. You can configure these roles in two ways: With login capability and a password, which you can assign to collaborators. Without login capability, to be used exclusively as a parent role to group permissions that can be inherited by other roles. You cannot assign these non-login roles to collaborators directly. Define Child Roles : PostgreSQL has a mechanism for Role Membership wherein any role can be \u201cgranted\u201d to any other role to form simple hierarchies or complex graph-based inheritance structures. For any role you\u2019ve configured within Mathesar, you can use Mathesar to grant the role to other \u201cchild roles\u201d. Drop Roles : You can drop server-level roles that are no longer needed. This action removes the role from the server, however if the role is configured in Mathesar, it will still be displayed. Exercise caution when dropping roles, as it may affect collaborators using the dropped role in Mathesar. Note Server roles, once added, must be configured in Mathesar under the Role Configuration section before they can be assigned to collaborators.","title":"On the Server: Roles"},{"location":"user-guide/permissions/#objects","text":"In PostgreSQL, an \u201cobject\u201d is a thing like: a database, a schema, a table, (and some other things too, which we won\u2019t cover here) .","title":"PostgreSQL objects"},{"location":"user-guide/permissions/#privileges-and-ownership","text":"Privileges: Specific privileges on an object can be granted to specific roles. Example A role can be granted the CREATE privilege on a schema. This allows the role to create new tables within the schema. Ownership : Every PostgreSQL object has one and only one role said to be its \u201cowner\u201d. The owner generally can do anything directly to the object, but not necessarily other objects contained within it. By default the owner is set to the role which created the object. Shared ownership: While PostgreSQL has a variety of granular privileges for different actions, there are still certain actions which remain restricted to object owners. For example only the owner of a table can add new columns to it. While this behavior may seem limiting, it\u2019s still possible configure multiple roles to effectively \u201cown\u201d a single object by leveraging PostgreSQL\u2019s powerful role inheritance functionality: We can create a third role to directly own the object and act as a sort of proxy \u201cgroup\u201d. (The group role doesn\u2019t need to be a LOGIN role and thus doesn\u2019t require a password to be configured.) Then we can grant that group role to any other roles we\u2019d like. Those child roles will then have permission do things as if they were the owner themselves . You can use the Mathesar UI to configure an arrangement like the above, though it will require many steps.","title":"Privileges and ownership"},{"location":"user-guide/permissions/#database-permissions","text":"The \u201cDatabase Permissions\u201d modal is accessible via a button at the top right of the database page and allows you to configure the owner and granted privileges for a database. Owner : Each database has an owner who has administrative control over the database itself, including managing database-level permissions and transferring ownership. Ownership does not automatically extend to the objects within the database (such as schemas and tables), which may have their own separate ownership and permission settings. Granted Access : Specific permissions can be granted to roles for various actions within the database. Transfer Ownership : The current owner can transfer ownership to another role, granting them administrative control. For each database, the following permission levels can be granted: Connect : Allows the role to access and connect to the database. Create : Includes Connect permissions and allows the role to create new schemas within the database. Custom : Enables the granular setting of permissions beyond the predefined options.","title":"Database Permissions"},{"location":"user-guide/permissions/#schema-permissions","text":"The \u201cSchema Permissions\u201d modal is accessible via a button at the top right of the schema page and allows you to configure the owner and granted privileges for a schema. Owner : Each schema has an owner who has administrative control over the schema itself, including managing schema-level permissions and transferring ownership. Ownership does not automatically extend to the objects within the schema (such as tables), which may have their own separate ownership and permission settings. Granted Access : Specific permissions can be granted to roles for various actions within the schema. Transfer Ownership : The current owner can transfer ownership to another role, granting them administrative control over the schema. For each schema, the following permission levels can be granted: Read : Allows the role to access the schema and view its objects. Create : Includes Read permissions and allows the role to create new tables within the schema. Custom : Enables the granular setting of permissions beyond the predefined options.","title":"Schema Permissions"},{"location":"user-guide/permissions/#table-permissions","text":"The Table Permissions modal is accessible via a button from within the right-side inspector panel for each table and allows you to configure the owner and granted privileges for a table. Owner : Each table has an owner who has administrative control over the table itself, including managing table-level permissions, transferring ownership, and modifying the table\u2019s structure (such as adding, removing, or altering columns). Granted Access : Specific permissions can be granted to roles for various actions on the table. Transfer Ownership : The current owner can transfer ownership to another role, granting them administrative control over the table. For each table, the following permission levels can be granted: Read : Allows the role to access the table and read records. Write : Includes Read permissions and allows the role to insert, update, and delete records in the table. Custom : Enables the granular setting of permissions beyond the predefined options. You can read more about the specific privileges that can be granted in the PostgreSQL documentation on Privileges .","title":"Table Permissions"},{"location":"user-guide/users/","text":"Users \u00b6 Mathesar allows multiple users to collaborate on the same data using a role-based permissioning system. Managing Users \u00b6 Click on the gear icon on the top right of the application and select Administration . In the left sidebar, click on Users . Admin-assigned passwords Any user with an admin-assigned password (new or edited) will be prompted to change their password after logging in. Admin vs Standard users \u00b6 Each Mathesar user is either Admin or Standard . Admin users have the following capabilities which Standard users do not: Admins can can manage other Mathesar users (view, add, edit, delete). Admins can add and remove Databases . Admins can manage Collaborators . This allows an Admin user to grant any Mathesar user access to a database through a PostgreSQL role that the Admin specifies. Upon installing Mathesar, your first user will be an Admin user. Users vs Roles \u00b6 A \u201cuser\u201d is a Mathesar construct. Each Mathesar installation has multiple users. A \u201crole\u201d is a PostgreSQL construct ( docs ). Each PostgreSQL server has multiple roles and multiple databases. Why this distinction is important Outside of Mathesar, it\u2019s not uncommon for people to say user when referring to a PostgreSQL role . However, within the context of Mathesar users and roles are different things! Our documentation maintains this distinction pedantically. How users and roles work together: To access a database, each Mathesar user must be assigned a PostgreSQL role to be used for that database. The user\u2019s permissions on actual data (in the user database ) are determined by the corresponding role\u2019s permissions within PostgreSQL. Admin doesn\u2019t matter here The user\u2019s \u201cadmin\u201d status with Mathesar has no effect on the user\u2019s ability to do things with the data in a database! The admin status only affects operations on Mathesar\u2019s internal database such as managing collaborators and their corresponding roles. You can configure separate Mathesar users to share the same PostgreSQL role if you like. This is a good option if you want those users to have the same permissions on the data. Or you can use separate PostgreSQL roles for different users. This is necessary any time you want different users to have different permissions on the data. You cannot configure one Mathesar user with two PostgreSQL role simultaneously \u2014 though you can save multiple PostgreSQL roles in Mathesar and manually switch between them if necessary. See Permissions for more information on managing roles. Limitations \u00b6 Mathesar does not send invitation emails to new users (yet). You\u2019ll need to send the user their username and password yourself. Nor is there yet an email-based password recovery mechanism. If you are locked out of your Mathesar installation\u2019s web interface, your system administrator can still use the command line reset any user\u2019s password .","title":"Users"},{"location":"user-guide/users/#users","text":"Mathesar allows multiple users to collaborate on the same data using a role-based permissioning system.","title":"Users"},{"location":"user-guide/users/#managing-users","text":"Click on the gear icon on the top right of the application and select Administration . In the left sidebar, click on Users . Admin-assigned passwords Any user with an admin-assigned password (new or edited) will be prompted to change their password after logging in.","title":"Managing Users"},{"location":"user-guide/users/#admin-vs-standard-users","text":"Each Mathesar user is either Admin or Standard . Admin users have the following capabilities which Standard users do not: Admins can can manage other Mathesar users (view, add, edit, delete). Admins can add and remove Databases . Admins can manage Collaborators . This allows an Admin user to grant any Mathesar user access to a database through a PostgreSQL role that the Admin specifies. Upon installing Mathesar, your first user will be an Admin user.","title":"Admin vs Standard users"},{"location":"user-guide/users/#users-vs-roles","text":"A \u201cuser\u201d is a Mathesar construct. Each Mathesar installation has multiple users. A \u201crole\u201d is a PostgreSQL construct ( docs ). Each PostgreSQL server has multiple roles and multiple databases. Why this distinction is important Outside of Mathesar, it\u2019s not uncommon for people to say user when referring to a PostgreSQL role . However, within the context of Mathesar users and roles are different things! Our documentation maintains this distinction pedantically. How users and roles work together: To access a database, each Mathesar user must be assigned a PostgreSQL role to be used for that database. The user\u2019s permissions on actual data (in the user database ) are determined by the corresponding role\u2019s permissions within PostgreSQL. Admin doesn\u2019t matter here The user\u2019s \u201cadmin\u201d status with Mathesar has no effect on the user\u2019s ability to do things with the data in a database! The admin status only affects operations on Mathesar\u2019s internal database such as managing collaborators and their corresponding roles. You can configure separate Mathesar users to share the same PostgreSQL role if you like. This is a good option if you want those users to have the same permissions on the data. Or you can use separate PostgreSQL roles for different users. This is necessary any time you want different users to have different permissions on the data. You cannot configure one Mathesar user with two PostgreSQL role simultaneously \u2014 though you can save multiple PostgreSQL roles in Mathesar and manually switch between them if necessary. See Permissions for more information on managing roles.","title":"Users vs Roles"},{"location":"user-guide/users/#limitations","text":"Mathesar does not send invitation emails to new users (yet). You\u2019ll need to send the user their username and password yourself. Nor is there yet an email-based password recovery mechanism. If you are locked out of your Mathesar installation\u2019s web interface, your system administrator can still use the command line reset any user\u2019s password .","title":"Limitations"}]}